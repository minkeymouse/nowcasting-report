\section{데이터 및 방법론}

\subsection{데이터}

\subsubsection{데이터셋 개요}
본 연구는 한국은행 경제통계시스템(ECOS)에서 수집한 한국 거시경제 시계열 데이터를 활용함. 데이터 기간은 1985년 4월부터 2025년 11월까지이며, 총 2,538개의 관측치와 101개의 시계열 변수로 구성되어 있음. dfm-python의 clock 프레임워크는 월간('m') 빈도를 사용하므로, clock 빈도보다 빠른 주간 변수는 실험에서 제외됨. 따라서 실제 실험에는 월간 변수 87개와 분기별 변수 8개만 사용됨. 

데이터는 혼합 빈도(mixed-frequency) 구조를 가지고 있으며, 월간 변수 87개, 분기별 변수 8개, 주간 변수 6개로 구성되어 있음. 변수들은 다음과 같은 카테고리로 분류됨:
\begin{itemize}
    \item 생산(Production) 20개
    \item 기업 설문(Survey, Bsnss) 16개
    \item 금융(Finance) 11개
    \item 소비자 설문(Survey, Cnsmr) 10개
    \item 무역(Int. trade) 8개
    \item 거시경제(Macro) 8개
    \item 노동(Labor) 7개
    \item 투자(Investment) 7개
    \item 소비(Consumption) 6개
    \item 물가(Price) 5개 등
\end{itemize}

\subsubsection{목표 변수}
본 연구의 예측 대상은 다음과 같은 3개의 분기별 거시경제 변수임:

\begin{itemize}
    \item \textbf{KOGDP\_\_\_D}: 국내총생산(GDP), 실질 기준, 사슬 연결 가중치(Chained W, Billions). 분기별 빈도를 가지며, 총 162개의 관측치가 있음.
    \item \textbf{KOCNPER\_D}: 민간 소비(Consumption, Private), 실질 기준, 사슬 연결 가중치. 분기별 빈도를 가지며, 총 162개의 관측치가 있음.
    \item \textbf{KOGFCF\_\_D}: 총고정자본형성(Gross Capital Formation, Fixed), 실질 기준, 사슬 연결 가중치. 분기별 빈도를 가지며, 총 162개의 관측치가 있으며, 세 목표 변수 중 가장 큰 변동성을 보이는 것으로 알려져 있음.
\end{itemize}

이러한 목표 변수들은 분기별로 발표되며, 해당 분기 종료 후 약 25일 정도의 시차를 가지고 있음. 따라서 nowcasting을 통해 공식 발표 전에 현재 분기의 값을 추정하는 것이 가능함.

\subsubsection{설명 변수}
설명 변수들은 목표 변수와 관련된 다양한 경제 지표들로 구성되어 있음. 주요 변수 그룹은 다음과 같음:

\begin{itemize}
    \item \textbf{생산 지표}: 전산업 생산지수, 제조업 생산지수, 서비스업 생산지수 등
    \item \textbf{소비 관련 지표}: 소비자 심리지수, 소매판매액, 신용카드 거래액 등
    \item \textbf{투자 관련 지표}: 설비투자, 건설 착공, 기계류 투자 등
    \item \textbf{금융 지표}: 기준금리, 대출금리, 주가지수 등
    \item \textbf{무역 지표}: 수출입액, 수출입 물가 등
    \item \textbf{설문 지표}: 기업경기실사지수(BSI), 소비자동향지수(CSI) 등
\end{itemize}

대부분의 변수들은 월간 빈도를 가지며, 일부 변수는 주간 또는 분기별 빈도를 가짐. 또한 많은 변수들이 결측치를 포함하고 있어, 적절한 전처리 과정이 필요함.

\subsection{전처리 방법}

\subsubsection{본 연구에서는 sktime 라이브러리를 활용한 전처리 파이프라인을 구축함}
\begin{itemize}
    \item 각 시계열 변수는 메타데이터에 명시된 변환 방법(chg: 변화율, cha: 사슬 연결, lin: 선형)에 따라 전처리됨
    \item 모든 변수는 표준화를 통해 평균 0, 표준편차 1로 변환됨
    \item 결측치는 선형 보간 또는 전방 채우기(forward fill) 방법을 사용하여 처리함. 전방 채우기는 시계열 데이터의 시간적 순서를 보존하면서 결측치를 처리하는 방법으로, 이전 관측치의 값을 사용하여 결측치를 채움. 선형 보간은 연속적인 결측치가 많은 경우에 사용되며, 이전과 이후 관측치 사이를 선형적으로 보간함. 본 연구에서는 대부분의 변수에 대해 전방 채우기를 사용하였으며, 이는 시계열 데이터의 특성상 이전 값이 미래 값에 영향을 미치기 때문임.
\end{itemize}

\subsection{dfm-python 패키지 개요}

dfm-python은 고차원 시계열 데이터의 nowcasting과 예측을 위한 동적 요인 모형(Dynamic Factor Model, DFM)의 포괄적인 Python 구현체임. 본 연구에서는 dfm-python 패키지를 활용하여 DFM과 DDFM(Deep Dynamic Factor Model) 모형을 사용함.

\subsubsection{dfm-python의 핵심 기능}
dfm-python 패키지는 다음과 같은 핵심 기능을 제공함:
\begin{itemize}
    \item \textbf{혼합 빈도 데이터 처리}: 월간, 분기별, 반기별, 연간 등 서로 다른 빈도의 시계열 데이터를 하나의 모형에서 처리할 수 있음
    \item \textbf{Clock 기반 프레임워크}: 모든 잠재 요인(global factor와 block-level factor)이 공통의 "clock" 빈도에서 진화하도록 동기화함. Clock 빈도는 일간('d'), 주간('w'), 월간('m'), 분기별('q'), 반기별('sa'), 연간('a') 중에서 선택 가능함
    \item \textbf{텐트 커널 집계}: 낮은 빈도의 관측 변수를 높은 빈도의 잠재 상태로 매핑하기 위해 결정론적 텐트 커널(tent kernel)을 사용함. 예를 들어, 분기별 GDP를 월간 잠재 요인으로부터 모델링할 수 있음
    \item \textbf{블록 구조}: 유연한 요인 조직화를 지원함. 전역 공통 요인(global common factor)과 부문별 요인(sector-specific factors)을 블록으로 구성할 수 있음
    \item \textbf{결측치 처리}: 전처리 단계에서 전방 채우기(Forward Fill)와 후방 채우기(Backward Fill)를 사용하여 결측치를 처리하며, Kalman 필터가 결측치를 자연스럽게 처리할 수 있음
    \item \textbf{News decomposition}: 특정 데이터 발표가 예측 변화에 미치는 기여도를 분석할 수 있는 기능을 제공함
    \item \textbf{nowcasting 및 예측}: 모든 예측 기간에 대한 예측을 생성할 수 있음
    \item \textbf{Deep Dynamic Factor Models (DDFM)}: 비선형 인코더를 사용하여 복잡한 요인 구조를 포착하는 DDFM을 지원함 (PyTorch 필요)
\end{itemize}

\subsubsection{dfm-python의 기술적 특징}
dfm-python 패키지는 다음과 같은 기술적 특징을 가짐:
\begin{itemize}
    \item \textbf{다양한 설정 방법}: YAML 파일, CSV 스펙, Python 딕셔너리, 또는 Hydra를 통한 설정을 지원함. 본 연구에서는 Hydra 기반 YAML 설정 파일을 사용함
    \item \textbf{수치적 안정성}: 
    \begin{itemize}
        \item 조건이 나쁜 행렬에 대한 적응형 릿지 정규화
        \item Q 행렬 바닥값(요인에 대해 0.01) 설정으로 스케일 문제 방지
        \item C 행렬 정규화(||C[:,j]|| = 1)로 clock 빈도 요인 정규화
        \item 스펙트럼 반경 제한(< 0.99)으로 정상성 보장
        \item 모든 공분산 행렬에 대한 분산 바닥값 설정
    \end{itemize}
    \item \textbf{PyTorch Lightning 기반}: 표준화된 Lightning 패턴을 따르는 모듈화된 API를 제공함. DFMDataModule, DFMTrainer, DDFMTrainer 등의 클래스를 통해 일관된 인터페이스를 제공함
    \item \textbf{전처리 데이터 기대}: 패키지는 사용자로부터 전처리된 데이터를 기대하며, 사용자는 sktime 또는 다른 도구를 사용하여 모든 전처리(보간, 스케일링, 특징 공학)를 처리함
    \item \textbf{프로덕션 준비}: 포괄적인 오류 처리, 광범위한 테스트, 잘 문서화된 코드로 구성됨
\end{itemize}

\subsubsection{dfm-python의 아키텍처}
dfm-python 패키지는 다음과 같은 주요 모듈로 구성됨:
\begin{itemize}
    \item \textbf{config 모듈}: 설정 데이터 클래스(DFMConfig, SeriesConfig, BlockConfig) 및 설정 어댑터(YAML/Dict/CSV/Hydra)
    \item \textbf{models 모듈}: 핵심 추정 클래스(DFM, DDFM) 및 베이스 클래스(BaseFactorModel)
    \item \textbf{core 모듈}: EM 알고리즘 구현, 수치 유틸리티, 헬퍼 함수, 타임스탬프 유틸리티
    \item \textbf{kalman 모듈}: Kalman 필터 및 스무더 구현
    \item \textbf{lightning 모듈}: PyTorch Lightning 기반 데이터 모듈 및 트레이너
    \item \textbf{nowcast 모듈}: nowcasting 기능 및 News decomposition
    \item \textbf{utils 모듈}: 혼합 빈도 유틸리티(텐트 가중치, 집계 구조, idio 체인 길이, 빈도 헬퍼)
\end{itemize}

\subsection{예측 모형}

\subsubsection{본 연구에서는 총 4개의 예측 모형을 비교 분석함}
\begin{itemize}
    \item 전통적 통계 모형으로는 ARIMA, VAR을 사용함
    \item 동적 요인 모형으로는 dfm-python 패키지를 활용하여 DFM과 DDFM을 사용함
\end{itemize}

\subsubsection{dfm-python을 활용한 DFM 구현}
dfm-python 패키지는 PyTorch Lightning 패턴을 따르는 표준화된 인터페이스를 제공함. DFM 모형의 사용은 다음과 같은 단계로 구성됨:

\begin{enumerate}
    \item \textbf{데이터 모듈 생성}: DFMDataModule을 사용하여 데이터를 로드하고 전처리함. 데이터는 이미 전처리된 상태여야 하며, 메타데이터(빈도, 변환 방법 등)를 포함해야 함.
    \item \textbf{모형 초기화}: DFM 클래스를 인스턴스화하고, YAML 설정 파일을 통해 모형 구조를 정의함. 설정 파일에는 요인 개수, AR 차수, 블록 구조 등이 포함됨.
    \item \textbf{학습}: DFMTrainer를 사용하여 EM 알고리즘을 통해 모형 파라미터를 추정함. 수렴 기준(threshold)과 최대 반복 횟수(max\_iter)를 설정할 수 있음.
    \item \textbf{예측}: 학습된 모형의 predict 메서드를 호출하여 미래 시점의 값을 예측함. 예측 기간(horizon)을 지정할 수 있음.
\end{enumerate}

본 연구에서는 clock 빈도를 월간('m')으로 설정하여 모든 잠재 요인이 월간 빈도에서 진화하도록 함. 분기별 목표 변수는 텐트 커널(tent kernel)을 통해 월간 요인으로부터 집계됨. 텐트 커널은 분기 내 각 월의 기여도를 시간 가중치로 부여하여, 분기의 중간 시점이 더 큰 가중치를 갖도록 함.

\subsubsection{dfm-python을 활용한 DDFM 구현}
DDFM은 DFM의 비선형 확장으로, 자기인코더(autoencoder)를 사용하여 잠재 상태를 생성하고 비선형 요인 구조를 학습함 \cite{andreini2020deep}. dfm-python의 DDFM 구현은 다음과 같은 특징을 가짐:

\begin{itemize}
    \item \textbf{인코더 구조}: 다층 퍼셉트론(MLP) 기반의 인코더를 사용하여 관측 시계열을 잠재 요인 공간으로 매핑함. 인코더 레이어 수와 각 레이어의 크기를 설정할 수 있음.
    \item \textbf{학습 방법}: 배치 기반 학습을 통해 신경망 파라미터를 최적화함. 학습률, 배치 크기, 에폭 수 등을 설정할 수 있음.
    \item \textbf{요인 동학}: 학습된 요인은 DFM과 동일하게 AR(1) 과정을 따르며, Kalman 필터를 통해 추정됨.
\end{itemize}

본 연구에서는 DDFM의 인코더 구조를 [64, 32]로 설정하였으며, 요인 개수는 목표 변수에 따라 2-4개로 조정함. 학습률은 0.005로 설정하고, 배치 크기는 100으로 설정함. 활성화 함수는 ReLU를 사용하며, 학습률은 지수 감쇠 스케줄러(exponential decay scheduler, gamma=0.96)를 통해 점진적으로 감소함. DDFM은 DFM과 동일한 clock 프레임워크를 사용하여 혼합 빈도 데이터를 처리함.

\subsection{실험 설계}

\subsubsection{데이터 분할 및 평가 절차}
본 연구에서는 시계열 데이터의 특성을 고려하여 시간 순서를 유지하는 단일 분할(single split) 방식을 사용함. 전체 데이터를 훈련 세트와 테스트 세트로 80:20 비율로 분할하며, 분할 시점은 전체 데이터 길이의 80\% 지점으로 설정함. 이는 시계열 데이터의 시간적 순서를 보존하면서 미래 시점에 대한 예측 성능을 평가하기 위함임.

평가 절차는 다음과 같이 수행됨:
\begin{enumerate}
    \item \textbf{모형 학습}: 전체 데이터의 처음 80\%를 훈련 세트로 사용하여 모형을 학습시킴
    \item \textbf{예측 생성}: 학습된 모형을 사용하여 훈련 세트의 마지막 시점부터 테스트 세트의 각 시점까지 예측을 생성함. 예측 기간(horizon)은 1일, 7일, 28일로 설정함
    \item \textbf{성능 평가}: 예측값과 실제값을 비교하여 표준화된 평가 지표(sMSE, sMAE, sRMSE)를 계산함. 표준화는 훈련 데이터의 표준편차($\sigma_{train}$)로 나누어 수행되며, 이를 통해 서로 다른 스케일의 변수 간 공정한 비교가 가능함
    \item \textbf{유효성 검증}: 각 예측 기간에 대해 유효한 예측값의 개수(n\_valid)를 확인함. 테스트 세트 크기가 예측 기간보다 작은 경우(예: 28일 예측의 경우 테스트 세트가 28개 미만), 해당 예측 기간에 대한 평가는 수행하지 않음
\end{enumerate}

\textbf{28일 예측 기간 평가 불가능 사유}: 본 연구의 목표 변수는 분기별 빈도를 가지며, 총 162개의 관측치를 가짐. 80:20 분할 시 테스트 세트는 약 32개 관측치를 포함함. 그러나 28일 예측은 테스트 세트의 각 시점에서 28일 이후의 값을 예측하는 것으로, 테스트 세트의 마지막 시점에서 28일 이후의 값이 존재하지 않으므로 평가가 불가능함. 구체적으로, 테스트 세트의 크기가 32개인 경우, 28일 예측을 위해서는 최소 28개의 미래 시점이 필요하나, 테스트 세트 내에서 28일 이후의 시점은 존재하지 않음. 따라서 DFM과 DDFM의 28일 예측은 평가 불가능함.

\subsubsection{평가 지표}
본 연구에서는 세 가지 예측 기간(1일, 7일, 28일)에 대해 모형 성능을 평가함. 모든 모형의 성능은 표준화된 평가 지표를 통해 비교되며, 각 지표는 다음과 같이 계산됨:
\begin{itemize}
    \item \textbf{표준화된 MSE (sMSE)}: $sMSE = \frac{1}{T} \sum_{t=1}^T \frac{(y_t - \hat{y}_t)^2}{\sigma_{train}^2}$
    \item \textbf{표준화된 MAE (sMAE)}: $sMAE = \frac{1}{T} \sum_{t=1}^T \frac{|y_t - \hat{y}_t|}{\sigma_{train}}$
    \item \textbf{표준화된 RMSE (sRMSE)}: $sRMSE = \sqrt{\frac{1}{T} \sum_{t=1}^T \frac{(y_t - \hat{y}_t)^2}{\sigma_{train}^2}}$
\end{itemize}
여기서 $T$는 테스트 세트의 크기, $y_t$는 실제값, $\hat{y}_t$는 예측값, $\sigma_{train}$은 훈련 데이터의 표준편차임. 표준화를 통해 서로 다른 스케일의 변수 간 공정한 비교가 가능하며, 값이 낮을수록 우수한 성능을 나타냄.

\subsubsection{dfm-python을 활용한 DFM/DDFM 실험 설정}
dfm-python 패키지를 사용하여 DFM과 DDFM 모형을 학습하고 예측을 수행함. 실험 설정은 다음과 같음:

\begin{itemize}
    \item \textbf{DFM 설정}: 요인 개수는 목표 변수에 따라 2-4개로 설정하고, AR 차수는 1로 설정함. EM 알고리즘의 수렴 기준은 1e-5로 설정하고, 최대 반복 횟수는 5000으로 설정함. 수렴 기준을 1e-5로 낮게 설정한 이유는 EM 알고리즘이 느리게 수렴하는 경우가 많으며, 더 엄격한 수렴 기준이 필요하기 때문임. 최대 반복 횟수를 5000으로 충분히 크게 설정한 이유는 복잡한 요인 구조에서 EM 알고리즘이 수렴하는 데 많은 반복이 필요할 수 있기 때문임. clock 빈도는 월간('m')으로 설정하여 모든 잠재 요인이 월간 빈도에서 진화하도록 함. 정규화 파라미터(regularization\_scale=1e-5)는 수치적 안정성을 위해 설정되었으며, 특히 조건수가 높은 행렬에서 중요함.
    \item \textbf{DDFM 설정}: 인코더 구조는 [64, 32]로 설정하고, 요인 개수는 DFM과 동일하게 2-4개로 설정함. 학습률은 0.005로 설정하고, 배치 크기는 100으로 설정함. 학습률 0.005는 원본 DDFM 구현과 일치하며, 너무 높으면 학습이 불안정하고 너무 낮으면 수렴이 느려질 수 있어 실험적으로 결정됨. 배치 크기 100은 메모리 제약과 학습 안정성 사이의 균형을 고려하여 선택됨. 에폭 수는 100으로 설정하고, 학습률은 지수 감쇠 스케줄러(exponential decay scheduler, gamma=0.96)를 통해 점진적으로 감소함. 이는 학습 초기에는 빠르게 학습하고 후기에는 미세 조정을 위해 학습률을 낮추는 일반적인 딥러닝 기법임. 활성화 함수는 ReLU를 사용함. ReLU는 비선형성을 도입하면서도 그래디언트 소실 문제를 완화하는 효과가 있음.
    \item \textbf{블록 구조}: 목표 변수와 관련된 변수들을 블록으로 그룹화함. GDP 예측을 위한 Block\_Production, 민간 소비 예측을 위한 Block\_Consumption, 총고정자본형성 예측을 위한 Block\_Investment 블록을 구성함. 블록 구조는 경제적 의미를 반영하여 관련 변수들을 그룹화함으로써 요인 해석 가능성을 향상시킴.
\end{itemize}

dfm-python의 nowcasting 기능을 활용하여 마스킹된 데이터를 통한 백테스팅을 수행할 수 있도록 구현함. 각 시점에서 목표 변수의 최근 관측치를 마스킹하고, 사용 가능한 고빈도 데이터만을 활용하여 예측을 수행하도록 함.

\textbf{DFM KOCNPER.D 수치적 불안정성 원인}: DFM의 EM 알고리즘이 KOCNPER.D(민간 소비)에서 수치적 불안정성을 보이는 기술적 원인은 다음과 같음. (1) \textbf{공선성 문제}: 소비 관련 변수들(소비자 심리지수, 소매판매액, 신용카드 거래액 등)이 유사한 패턴을 보여 요인 추출 시 공선성(collinearity)이 발생함. 이로 인해 관측 방정식의 행렬 C가 특이하거나 조건이 나쁜 행렬(ill-conditioned matrix)이 됨. (2) \textbf{Kalman 필터 공분산 행렬의 불안정성}: Kalman 필터의 공분산 행렬 V에서 Inf 값이 발생함(약 5476개의 Inf 값이 t=30+ 시점에서 관찰됨). 이는 EM 알고리즘의 M-step에서 행렬 역행렬 계산 시 수치적 오버플로우를 초래함. (3) \textbf{행렬 조건수}: C 행렬의 조건수(condition number)가 매우 높아져 정규화 조치(regularization\_scale=1e-5, Q 행렬 바닥값, C 행렬 정규화, 스펙트럼 반경 제한)로도 수치적 안정성을 확보하지 못함. 이러한 문제는 민간 소비 변수의 복잡한 비선형 관계와 변수 간 높은 상관관계에서 기인하며, 선형 요인 모델의 근본적 한계임.
