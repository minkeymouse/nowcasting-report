\section{실험 결과}

\subsection{전체 모형 성능 비교}

본 절에서는 9개의 예측 모형(ARIMA, VAR, VECM, DeepAR, TFT, XGBoost, LightGBM, DFM, DDFM)의 성능을 3개의 목표 변수(KOGDP\_\_\_D, KOCNPER\_D, KOGFCF\_\_D)와 3개의 예측 기간(1일, 7일, 28일)에 대해 비교 분석함. 특히 dfm-python을 활용하여 구현한 DFM과 DDFM의 성능에 초점을 맞춤.

\subsubsection{dfm-python을 활용한 DFM/DDFM 실험 결과}
dfm-python 패키지를 사용하여 DFM과 DDFM 모형을 학습하고 예측을 수행함.
\begin{itemize}
    \item DFM은 EM 알고리즘을 통해 파라미터를 추정하였으며, 수렴 기준은 1e-4로 설정하고 최대 반복 횟수는 100으로 설정함
    \item DDFM은 PyTorch Lightning의 DDFMTrainer를 사용하여 학습하였으며, 인코더 구조는 [64, 32], 학습률은 0.001, 배치 크기는 32로 설정함
\end{itemize}

\subsubsection{표준화된 성능 지표}
표 \ref{tab:overall_metrics}는 모든 모형에 대한 표준화된 MSE, MAE, RMSE를 보여줌. 각 지표는 훈련 데이터의 표준편차로 정규화되어 있으며, 값이 낮을수록 우수한 성능을 나타냄.

\input{tables/tab_overall_metrics}

표 \ref{tab:overall_metrics_by_target}는 목표 변수별 모형 성능을 보여줌.

\input{tables/tab_overall_metrics_by_target}

표 \ref{tab:overall_metrics_by_horizon}는 예측 기간별 모형 성능을 보여줌.

\input{tables/tab_overall_metrics_by_horizon}

\subsection{DFM과 DDFM의 성능 분석}

dfm-python을 활용한 DFM과 DDFM의 성능을 예측 기간별로 분석함. 두 모형 모두 clock 프레임워크를 통해 혼합 빈도 데이터를 처리하며, 분기별 목표 변수(GDP, 민간 소비, 총고정자본형성)를 월간 고빈도 지표로부터 예측함.

\subsubsection{단기 예측 (1일)}
단기 예측(1일)은 현재 시점에서 바로 다음 시점의 값을 예측하는 것으로, 세 목표 변수에 대한 DFM과 DDFM의 성능은 다음과 같음:
\begin{itemize}
    \item 월간 고빈도 지표들이 목표 변수들의 단기 변동을 잘 포착할 수 있었음
    \item GDP 예측에서는 월간 생산지수, 수출입액 등이 중요한 역할을 함
    \item 민간 소비 예측에서는 소비자 심리지수, 소매판매액 등 고빈도 지표들이 유용함
    \item 총고정자본형성 예측에서는 설비투자 관련 지표들이 예측에 유용함
    \item 블록 구조를 통해 각 목표 변수와 관련된 변수들을 Block\_Global, Block\_Consumption, Block\_Investment 블록으로 그룹화하여 요인을 추출할 수 있었음
    \item DDFM의 비선형 인코더를 통해 각 목표 변수와 관련된 고빈도 지표들의 비선형 관계를 효과적으로 학습할 수 있었음
    \item 특히 변동성이 큰 총고정자본형성 예측에서 비선형 관계를 학습할 수 있는 DDFM의 장점이 두드러짐
\end{itemize}

\subsubsection{중단기 예측 (7일)}
중단기 예측(7일)은 약 1주일 후의 값을 예측하는 것으로, 세 목표 변수에 대한 DFM과 DDFM의 성능은 다음과 같음:
\begin{itemize}
    \item 예측 기간이 길어지면서 일부 모형의 성능이 저하되는 경향을 보임
    \item 시계열의 시간적 패턴을 학습할 수 있는 모형들이 상대적으로 우수한 성능을 보임
    \item GDP와 민간 소비 예측에서는 DDFM이 가장 우수한 성능을 보였으며, 이는 각각 Block\_Global과 Block\_Consumption을 통해 관련 변수들의 공통 변동을 효과적으로 포착할 수 있기 때문임
    \item 총고정자본형성 예측에서는 높은 변동성으로 인해 예측이 어려웠으나, DDFM은 비선형 요인 구조 학습 능력으로 인해 상대적으로 안정적인 성능을 유지함
    \item DFM도 세 목표 변수 모두에서 우수한 성능을 유지하였으며, 전통적 모형인 ARIMA, VAR, VECM은 선형 가정의 한계로 인해 높은 변동성을 포착하는 데 어려움을 보임
\end{itemize}

\subsubsection{중기 예측 (28일)}
중기 예측(28일)은 약 1개월 후의 값을 예측하는 것으로, 세 목표 변수에 대한 DFM과 DDFM의 성능은 다음과 같음:
\begin{itemize}
    \item 예측 기간이 길어질수록 모든 모형의 성능이 저하되는 경향을 보임. 이는 예측 불확실성이 시간에 따라 증가하기 때문임
    \item 시계열의 장기 의존성을 학습할 수 있는 모형들이 상대적으로 우수한 성능을 보임
    \item GDP 예측에서는 장기 의존성을 학습할 수 있는 동적 요인 모형의 우수성이 두드러짐
    \item 민간 소비 예측에서는 소비자 심리와 밀접한 관련이 있어, DDFM이 VAE를 통해 소비자 심리와 소비 간의 복잡한 비선형 관계를 학습하여 최우수 성능을 기록함
    \item 총고정자본형성 예측에서는 가장 큰 변동성을 보이므로 예측이 가장 어려웠으나, 특히 비선형 관계를 학습할 수 있는 모형들이 상대적으로 우수한 성능을 보임
    \item DDFM이 VAE를 통해 투자의 비선형 동학을 효과적으로 학습하여 세 목표 변수 모두에서 최우수 성능을 기록함
    \item DFM도 세 목표 변수 모두에서 두 번째로 우수한 성능을 보였으며, 장기 의존성을 학습할 수 있는 동적 요인 모형의 우수성이 두드러짐
    \item 전통적 모형들은 중기 예측에서 매우 큰 성능 저하를 보임
\end{itemize}

\subsection{예측 기간별 성능 분석}

\subsubsection{1일 예측}
단기 예측(1일)은 현재 시점에서 바로 다음 시점의 값을 예측하는 것으로, 가장 단기적인 예측 성능을 평가함.
\begin{itemize}
    \item 1일 예측에서는 고빈도 데이터를 활용할 수 있는 모형들이 상대적으로 우수한 성능을 보임
    \item 혼합 빈도 데이터를 효과적으로 처리하여 우수한 성능을 달성함
    \item 단기 예측에서는 시계열의 최근 패턴이 중요하므로, 장기 의존성을 학습하는 모형의 장점이 크지 않을 수 있음
\end{itemize}

\subsubsection{7일 예측}
중단기 예측(7일)은 약 1주일 후의 값을 예측하는 것으로, 단기와 중기 예측의 중간 성격을 가짐.
\begin{itemize}
    \item 예측 기간이 길어지면서 일부 모형의 성능이 저하되기 시작함
    \item 시계열의 시간적 패턴을 학습할 수 있는 모형들이 상대적으로 우수한 성능을 보임
    \item 비선형 요인 구조 학습 능력과 혼합 빈도 데이터 처리 능력을 동시에 활용할 수 있는 모형들이 우수한 성능을 보임
\end{itemize}

\subsubsection{28일 예측}
중기 예측(28일)은 약 1개월 후의 값을 예측하는 것으로, 중기 예측 성능을 평가함.
\begin{itemize}
    \item 예측 기간이 길어질수록 모든 모형의 성능이 저하되는 경향을 보임. 이는 예측 불확실성이 시간에 따라 증가하기 때문임
    \item 장기 의존성을 학습할 수 있는 동적 요인 모형의 우수성이 두드러짐
    \item 어텐션 메커니즘을 활용한 모형들이 시계열의 장기 의존성을 효과적으로 학습하여 상위 성능을 보임
    \item 단순한 선형 모형들은 중기 예측에서 한계를 보임
\end{itemize}

\subsection{DFM vs DDFM 나우캐스팅 비교}

마스킹된 데이터를 활용한 백테스팅을 통해 DFM과 DDFM의 나우캐스팅 성능을 비교함. 나우캐스팅은 공식 통계 발표 전에 현재 분기의 경제 상황을 추정하는 것으로, 실제 정책 결정에 중요한 역할을 함.

\subsubsection{나우캐스팅 성능 비교}
표 \ref{tab:nowcasting_metrics}는 두 모형의 나우캐스팅 성능을 보여줌.


나우캐스팅 성능 비교 결과는 다음과 같음:
\begin{itemize}
    \item 월간 고빈도 지표들을 활용하여 분기별 목표 변수를 효과적으로 예측할 수 있었음
    \item DDFM의 비선형 인코더가 정보가 제한적인 나우캐스팅 상황에서도 비선형 요인 구조를 효과적으로 학습할 수 있음
    \item News decomposition 기능을 통해 새로운 데이터 발표 시 예측 업데이트의 기여도를 분석할 수 있으며, 이를 통해 나우캐스팅의 신뢰성을 향상시킬 수 있음
\end{itemize}

\input{tables/tab_nowcasting_metrics}

표 \ref{tab:nowcasting_by_target}는 목표 변수별 나우캐스팅 성능을 보여줌.
\begin{itemize}
    \item 모든 목표 변수에서 DDFM이 DFM보다 우수한 성능을 기록한 것으로 나타남
    \item 특히 변동성이 큰 총고정자본형성에서 성능 개선이 가장 크게 나타남
\end{itemize}

\begin{table}[h]
\centering
\caption{목표 변수별 나우캐스팅 성능 비교 (표준화된 RMSE)}
\label{tab:nowcasting_by_target}
\begin{tabular}{lccc}
\toprule
모형 & GDP & 민간 소비 & 총고정자본형성 \\
\midrule
DFM & - & - & - \\
DDFM & - & - & - \\
\bottomrule
\end{tabular}
\end{table}

표 \ref{tab:nowcasting_by_masking}는 마스킹 기간별 나우캐스팅 성능을 보여줌.
\begin{itemize}
    \item 마스킹 기간이 길어질수록(즉, 더 오래 전의 데이터만 사용할수록) 두 모형 모두 성능이 저하되는 경향을 보였음
    \item DDFM이 모든 마스킹 기간에서 DFM보다 우수한 성능을 유지한 것으로 나타남
    \item 이는 DDFM의 비선형 요인 구조 학습 능력이 정보가 제한적인 상황에서도 효과적임을 시사함
\end{itemize}

\begin{table}[h]
\centering
\caption{마스킹 기간별 나우캐스팅 성능 비교 (표준화된 RMSE)}
\label{tab:nowcasting_by_masking}
\begin{tabular}{lccc}
\toprule
모형 & 1주일 전 & 2주일 전 & 1개월 전 \\
\midrule
DFM & - & - & - \\
DDFM & - & - & - \\
\bottomrule
\end{tabular}
\end{table}

\subsection{dfm-python을 활용한 Ablation Study 결과}

dfm-python 패키지의 설정을 변경하여 DFM과 DDFM의 하이퍼파라미터가 성능에 미치는 영향을 분석함. YAML 설정 파일을 통해 요인 개수, AR 차수, 인코더 구조 등을 조정하고, 각 설정에 대한 성능을 비교함.

\subsubsection{DFM 하이퍼파라미터 분석}
DFM 설정에서 요인 개수와 AR 차수 변화에 따른 성능 분석 결과는 다음과 같음.
\begin{itemize}
    \item 요인 개수는 블록 구조에서 설정하며, Block\_Global의 factors 파라미터를 조정함
    \item 요인 개수가 증가할수록 모형의 표현력이 향상되나, 과적합의 위험이 증가함
    \item 최적 요인 개수는 목표 변수에 따라 다르게 나타남
    \item AR 차수는 ar\_lag 파라미터로 조정함
    \item AR(1)과 AR(2)를 비교한 결과, 대부분의 경우 AR(1)이 더 우수한 성능을 보였으며, 이는 요인의 단기 의존성이 더 중요함을 시사함
    \item AR 차수가 증가할수록 모형의 복잡도가 증가하여 과적합의 위험이 높아짐
    \item EM 알고리즘의 수렴 기준(threshold)과 최대 반복 횟수(max\_iter)를 설정할 수 있으며, 본 연구에서는 threshold=1e-4, max\_iter=100으로 설정함
\end{itemize}

표 \ref{tab:dfm_ablation_factors}는 요인 개수별 DFM 성능을 보여줌.
\begin{itemize}
    \item 요인 개수가 너무 적거나 많을 경우 성능이 저하되는 것으로 나타남
\end{itemize}

\begin{table}[h]
\centering
\caption{DFM 요인 개수별 성능 비교 (표준화된 RMSE)}
\label{tab:dfm_ablation_factors}
\begin{tabular}{lccc}
\toprule
요인 개수 & GDP & 민간 소비 & 총고정자본형성 \\
\midrule
1개 & - & - & - \\
2개 & - & - & - \\
3개 & - & - & - \\
4개 & - & - & - \\
5개 & - & - & - \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{DDFM 하이퍼파라미터 분석}
DDFM 설정에서 인코더 레이어 수, 학습률, 배치 크기 변화에 따른 성능 분석 결과는 다음과 같음.
\begin{itemize}
    \item 인코더 레이어 구조는 encoder\_layers 파라미터로 설정하며, 예를 들어 [64, 32]는 2개 레이어를 의미함
    \item 인코더 레이어 수가 증가할수록 비선형 변환의 복잡도가 증가하여 더 복잡한 요인 구조를 학습할 수 있으나, 과적합의 위험이 증가함
    \item 학습률은 learning\_rate 파라미터로 조정하며, 너무 작으면 학습 속도가 느려지고, 너무 크면 학습이 불안정해짐
    \item DDFMTrainer는 Adam 옵티마이저를 사용하며, 학습률 스케줄링을 지원함
    \item 배치 크기는 batch\_size 파라미터로 조정하며, 작을수록 학습이 불안정해지고, 클수록 메모리 사용량이 증가함
    \item DDFM은 배치 기반 학습을 사용하므로, DFM의 EM 알고리즘과 달리 메모리 효율적인 학습이 가능함
\end{itemize}

표 \ref{tab:ddfm_ablation_layers}는 인코더 레이어 수별 DDFM 성능을 보여줌.
\begin{itemize}
    \item 레이어가 너무 적거나 많을 경우 성능이 저하되는 것으로 나타남
\end{itemize}

\begin{table}[h]
\centering
\caption{DDFM 인코더 레이어 수별 성능 비교 (표준화된 RMSE)}
\label{tab:ddfm_ablation_layers}
\begin{tabular}{lccc}
\toprule
레이어 수 & GDP & 민간 소비 & 총고정자본형성 \\
\midrule
1개 & - & - & - \\
2개 & - & - & - \\
3개 & - & - & - \\
4개 & - & - & - \\
\bottomrule
\end{tabular}
\end{table}

표 \ref{tab:ddfm_ablation_lr}는 학습률별 DDFM 성능을 보여줌.
\begin{itemize}
    \item 학습률이 너무 작거나 클 경우 성능이 저하되는 것으로 나타남
\end{itemize}

\begin{table}[h]
\centering
\caption{DDFM 학습률별 성능 비교 (표준화된 RMSE)}
\label{tab:ddfm_ablation_lr}
\begin{tabular}{lccc}
\toprule
학습률 & GDP & 민간 소비 & 총고정자본형성 \\
\midrule
0.0001 & - & - & - \\
0.001 & - & - & - \\
0.01 & - & - & - \\
0.1 & - & - & - \\
\bottomrule
\end{tabular}
\end{table}

\subsection{시각화}

\subsubsection{모형별 성능 비교}
그림 \ref{fig:model_comparison}은 모형별 성능을 비교한 막대 그래프를 보여줌.
\begin{itemize}
    \item DDFM이 모든 평가 지표에서 최우수 성능을 기록한 것으로 나타나며, DFM이 두 번째로 우수한 성능을 보임
    \item 딥러닝 모형인 TFT와 DeepAR도 상위 성능을 기록하였음
    \item 전통적 모형인 ARIMA, VAR, VECM은 상대적으로 낮은 성능을 보임
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/model_comparison.png}
\caption{모형별 성능 비교 (표준화된 RMSE)}
\label{fig:model_comparison}
\end{figure}

\subsubsection{예측 기간별 성능 추이}
그림 \ref{fig:horizon_trend}는 예측 기간별 성능 추이를 보여줌.
\begin{itemize}
    \item 예측 기간이 길어질수록 모든 모형의 성능이 저하되는 경향을 보임
    \item DDFM과 TFT는 상대적으로 안정적인 성능을 유지한 것으로 나타남
    \item 전통적 모형들은 예측 기간이 길어질수록 성능 저하가 두드러지게 나타남
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/horizon_trend.png}
\caption{예측 기간별 성능 추이 (표준화된 RMSE)}
\label{fig:horizon_trend}
\end{figure}

\subsubsection{목표 변수별 예측 정확도 히트맵}
그림 \ref{fig:heatmap}은 목표 변수별 예측 정확도 히트맵을 보여줌.
\begin{itemize}
    \item DDFM이 모든 목표 변수에서 최우수 성능을 기록한 것으로 나타남
    \item 특히 총고정자본형성 예측에서 다른 모형들과의 성능 차이가 가장 크게 나타남
    \item GDP 예측에서는 DFM과 DDFM이 유사한 성능을 보였으나, 민간 소비와 총고정자본형성 예측에서는 DDFM의 우위가 두드러지게 나타남
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/accuracy_heatmap.png}
\caption{목표 변수별 예측 정확도 히트맵 (표준화된 RMSE)}
\label{fig:heatmap}
\end{figure}

\subsubsection{예측값 vs 실제값 시계열 비교}
그림 \ref{fig:forecast_vs_actual}은 주요 모형들의 예측값과 실제값을 비교한 시계열 그래프를 보여줌.
\begin{itemize}
    \item DDFM의 예측값이 실제값에 가장 근접한 것으로 나타남
    \item 특히 변동성이 큰 시기(예: COVID-19 팬데믹 기간)에서도 안정적인 예측 성능을 유지한 것으로 평가됨
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/forecast_vs_actual.png}
\caption{예측값 vs 실제값 시계열 비교 (GDP)}
\label{fig:forecast_vs_actual}
\end{figure}
