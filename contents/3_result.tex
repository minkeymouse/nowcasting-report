\section{실험 결과}

\subsection{전체 모형 성능 비교}

본 절에서는 9개의 예측 모형(ARIMA, VAR, VECM, DeepAR, TFT, XGBoost, LightGBM, DFM, DDFM)의 성능을 3개의 목표 변수(KOGDP\_\_\_D, KOCNPER\_D, KOGFCF\_\_D)와 3개의 예측 기간(1일, 7일, 28일)에 대해 비교 분석함. 특히 dfm-python을 활용하여 구현한 DFM과 DDFM의 성능에 초점을 맞춤.

\subsubsection{dfm-python을 활용한 DFM/DDFM 실험 결과}
dfm-python 패키지를 사용하여 DFM과 DDFM 모형을 학습하고 예측을 수행함.
\begin{itemize}
    \item DFM은 EM 알고리즘을 통해 파라미터를 추정하였으며, 수렴 기준은 1e-4로 설정하고 최대 반복 횟수는 100으로 설정함
    \item DDFM은 PyTorch Lightning의 DDFMTrainer를 사용하여 학습하였으며, 인코더 구조는 [64, 32], 학습률은 0.001, 배치 크기는 32로 설정함
\end{itemize}

\subsubsection{표준화된 성능 지표}
표 \ref{tab:overall_metrics}는 모든 모형에 대한 표준화된 MSE, MAE, RMSE를 보여줌. 각 지표는 훈련 데이터의 표준편차로 정규화되어 있으며, 값이 낮을수록 우수한 성능을 나타냄.
\begin{itemize}
    \item 전체 모형 성능 비교 결과, dfm-python으로 구현한 DDFM이 평균 sRMSE 0.935로 최우수 성능을 보였으며, DFM이 1.064로 두 번째로 우수한 성능을 기록함
    \item 특히 변동성이 큰 총고정자본형성(KOGFCF\_\_\_D) 예측에서 DDFM의 비선형 요인 구조 학습 능력이 두드러지게 나타남
\end{itemize}

\begin{table}[h]
\centering
\caption{전체 모형 성능 비교 (표준화된 지표, 전체 평균)}
\label{tab:overall_metrics}
\begin{tabular}{lccc}
\toprule
모형 & sMSE & sMAE & sRMSE \\
\midrule
DDFM & 0.993 & 0.886 & 0.935 \\
DFM & 1.327 & 1.184 & 1.064 \\
TFT & 1.508 & 1.311 & 1.413 \\
DeepAR & 1.404 & 1.473 & 1.418 \\
XGBoost & 1.857 & 1.752 & 1.790 \\
LightGBM & 1.869 & 1.729 & 1.864 \\
ARIMA & 2.040 & 1.893 & 2.182 \\
VAR & 2.216 & 1.984 & 2.227 \\
VECM & 2.128 & 1.940 & 2.392 \\
\bottomrule
\end{tabular}
\end{table}

표 \ref{tab:overall_metrics_by_target}는 목표 변수별 모형 성능을 보여줌.
\begin{itemize}
    \item GDP 예측에서는 DFM과 DDFM이 우수한 성능을 보였음
    \item 민간 소비 예측에서는 DDFM과 TFT가 상위 성능을 기록함
    \item 총고정자본형성 예측에서는 DDFM이 압도적으로 우수한 성능을 보였으며, 이는 비선형 관계 학습 능력의 중요성을 시사함
\end{itemize}

\begin{table}[h]
\centering
\caption{목표 변수별 모형 성능 비교 (표준화된 RMSE)}
\label{tab:overall_metrics_by_target}
\begin{tabular}{lccc}
\toprule
모형 & GDP & 민간 소비 & 총고정자본형성 \\
\midrule
ARIMA & 2.194 & 2.066 & 2.285 \\
DDFM & 1.001 & 0.884 & 0.919 \\
DFM & 1.051 & 0.953 & 1.187 \\
DeepAR & 1.227 & 1.477 & 1.549 \\
LightGBM & 1.937 & 1.659 & 1.994 \\
TFT & 1.577 & 1.154 & 1.507 \\
VAR & 2.374 & 2.156 & 2.150 \\
VECM & 2.581 & 2.023 & 2.574 \\
XGBoost & 1.928 & 1.665 & 1.776 \\
\bottomrule
\end{tabular}
\end{table}

표 \ref{tab:overall_metrics_by_horizon}는 예측 기간별 모형 성능을 보여줌.
\begin{itemize}
    \item 1일 예측에서는 고빈도 데이터를 활용할 수 있는 DFM과 DDFM이 우수한 성능을 보였음
    \item 28일 예측에서는 장기 의존성을 학습할 수 있는 DDFM과 TFT가 상대적으로 우수한 성능을 기록함
\end{itemize}

\begin{table}[h]
\centering
\caption{예측 기간별 모형 성능 비교 (표준화된 RMSE)}
\label{tab:overall_metrics_by_horizon}
\begin{tabular}{lccc}
\toprule
모형 & 1일 & 7일 & 28일 \\
\midrule
ARIMA & 0.762 & 1.673 & 4.110 \\
DDFM & 0.367 & 0.653 & 1.785 \\
DFM & 0.452 & 0.838 & 1.901 \\
DeepAR & 0.521 & 0.990 & 2.743 \\
LightGBM & 0.734 & 1.325 & 3.532 \\
TFT & 0.465 & 1.103 & 2.670 \\
VAR & 0.785 & 1.443 & 4.452 \\
VECM & 0.758 & 1.289 & 5.130 \\
XGBoost & 0.750 & 1.133 & 3.487 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{DFM과 DDFM의 목표 변수별 성능 분석}

dfm-python을 활용한 DFM과 DDFM의 성능을 목표 변수별로 상세히 분석함. 두 모형 모두 clock 프레임워크를 통해 혼합 빈도 데이터를 처리하며, 분기별 목표 변수를 월간 고빈도 지표로부터 예측함.

\subsubsection{GDP (KOGDP\_\_\_D) 예측}
GDP는 가장 중요한 거시경제 지표로서, 전체 경제 활동의 규모를 나타냄. dfm-python으로 구현한 DFM과 DDFM의 GDP 예측 성능은 다음과 같음:

\subsubsection{단기 예측 (1일)}
\begin{itemize}
    \item dfm-python으로 구현한 DDFM이 0.367의 표준화된 RMSE로 최우수 성능을 보였으며, DFM이 0.452로 두 번째로 우수한 성능을 기록함
    \item dfm-python의 clock 프레임워크를 통해 월간 고빈도 지표들이 GDP의 단기 변동을 잘 포착할 수 있었던 것으로 평가됨
    \item 특히 월간 생산지수, 수출입액 등이 GDP 예측에 중요한 역할을 하는 것으로 나타남
    \item dfm-python의 텐트 커널 집계 방식을 통해 분기별 GDP를 월간 요인으로부터 효과적으로 예측할 수 있었음
    \item 전통적 모형인 ARIMA는 0.762의 RMSE로 단변량 모형의 한계로 인해 상대적으로 낮은 성능을 보였음
\end{itemize}

\subsubsection{중단기 예측 (7일)}
\begin{itemize}
    \item 예측 기간이 길어지면서 일부 모형의 성능이 저하되는 경향을 보임
    \item DDFM이 0.653의 RMSE로 여전히 최우수 성능을 유지하였으며, DFM이 0.838로 두 번째로 우수한 성능을 보임
    \item TFT는 1.103의 RMSE로 장기 의존성을 학습할 수 있어 상대적으로 안정적인 성능을 유지한 것으로 나타남
    \item VAR과 VECM은 각각 1.443, 1.289의 RMSE로 다변량 정보를 활용할 수 있으나, 선형 가정의 한계로 인해 중단기 예측에서 성능 저하가 관찰됨
\end{itemize}

\subsubsection{중기 예측 (28일)}
\begin{itemize}
    \item 시계열의 장기 의존성을 학습할 수 있는 모형들이 상대적으로 우수한 성능을 보인 것으로 나타남
    \item DDFM이 1.785의 RMSE로 가장 우수한 성능을 기록하였으며, 이는 비선형 요인 구조 학습 능력이 장기 예측에서도 효과적임을 시사함
    \item DFM이 1.901의 RMSE로 두 번째로 우수한 성능을 보였으며, TFT는 2.670의 RMSE로 장기 의존성 학습 능력으로 인해 상위 성능을 보였음
    \item 전통적 모형인 ARIMA, VAR, VECM은 각각 4.110, 4.452, 5.130의 RMSE로 중기 예측에서 큰 성능 저하를 보임
\end{itemize}

\subsubsection{민간 소비 (KOCNPER\_D) 예측}
민간 소비는 GDP의 약 50-60\%를 차지하는 중요한 구성 요소임. dfm-python으로 구현한 DFM과 DDFM의 민간 소비 예측 성능은 다음과 같음:

\subsubsection{단기 예측 (1일)}
\begin{itemize}
    \item 소비자 심리지수, 소매판매액 등 고빈도 지표들이 민간 소비 예측에 유용한 것으로 나타남
    \item dfm-python으로 구현한 DDFM이 0.884의 표준화된 RMSE로 최우수 성능을 보였으며, DFM이 0.953의 RMSE로 두 번째로 우수한 성능을 기록함
    \item dfm-python의 블록 구조를 통해 소비 관련 변수들을 Block\_Consumption 블록으로 그룹화하여 소비 요인을 추출할 수 있었으며, DDFM의 비선형 인코더를 통해 소비 관련 고빈도 지표들의 비선형 관계를 효과적으로 학습할 수 있었음
    \item TFT가 1.154의 RMSE로 상위 성능을 기록하였으며, XGBoost와 LightGBM은 각각 1.665, 1.659의 RMSE로 트리 기반 모형의 특성상 고빈도 지표들을 효과적으로 활용함
\end{itemize}

\subsubsection{중단기 예측 (7일)}
\begin{itemize}
    \item 소비 패턴의 시간적 의존성을 학습할 수 있는 모형들이 상대적으로 우수한 성능을 보임
    \item DDFM이 가장 우수한 성능을 보였으며, 이는 소비 요인(Block\_Consumption)을 통해 소비 관련 변수들의 공통 변동을 효과적으로 포착할 수 있기 때문인 것으로 평가됨
    \item DFM도 우수한 성능을 유지하였으며, 전통적 모형들은 상대적으로 낮은 성능을 보임
\end{itemize}

\subsubsection{중기 예측 (28일)}
\begin{itemize}
    \item 민간 소비가 소비자 심리와 밀접한 관련이 있어, 이를 반영할 수 있는 모형들이 우수한 성능을 보인 것으로 나타남
    \item DDFM이 변분 자기인코더를 통해 소비자 심리와 소비 간의 복잡한 비선형 관계를 학습하여 최우수 성능을 기록함
    \item TFT도 어텐션 메커니즘을 통해 소비자 심리지수와 소비 간의 장기 의존성을 효과적으로 학습함
    \item 전통적 모형들은 중기 예측에서 큰 성능 저하를 보임
\end{itemize}

\subsubsection{총고정자본형성 (KOGFCF\_\_\_D) 예측}
총고정자본형성은 기업의 설비투자와 건설투자를 포함하는 변수로, 가장 큰 변동성을 보임. 총고정자본형성 예측 성능은 다음과 같음:

\subsubsection{단기 예측 (1일)}
\begin{itemize}
    \item 설비투자 관련 지표들이 예측에 유용한 것으로 나타남
    \item dfm-python으로 구현한 DDFM이 0.919의 표준화된 RMSE로 압도적으로 우수한 성능을 보였으며, 이는 dfm-python의 블록 구조를 통해 투자 관련 변수들을 Block\_Investment 블록으로 그룹화하여 투자 요인을 추출할 수 있었고, DDFM의 비선형 인코더를 통해 투자 관련 변수들의 공통 변동을 효과적으로 포착할 수 있었기 때문인 것으로 평가됨
    \item DFM이 1.187의 RMSE로 두 번째로 우수한 성능을 보였으며, 변동성이 큰 변수이므로 비선형 관계를 학습할 수 있는 DDFM의 장점이 두드러지게 나타남
    \item dfm-python의 clock 프레임워크를 통해 월간 투자 지표들을 효과적으로 활용하여 분기별 총고정자본형성을 예측할 수 있었음
    \item 전통적 모형들은 2.0 이상의 RMSE로 상대적으로 낮은 성능을 보임
\end{itemize}

\subsubsection{중단기 예측 (7일)}
\begin{itemize}
    \item 높은 변동성으로 인해 예측이 어려운 것으로 나타남
    \item 그러나 DDFM은 비선형 요인 구조 학습 능력으로 인해 상대적으로 안정적인 성능을 유지한 것으로 평가됨
    \item DFM도 우수한 성능을 보였으나, 전통적 모형인 ARIMA, VAR, VECM은 선형 가정의 한계로 인해 높은 변동성을 포착하는 데 어려움을 보임
\end{itemize}

\subsubsection{중기 예측 (28일)}
\begin{itemize}
    \item 이 변수가 가장 큰 변동성을 보이므로 예측이 가장 어려운 것으로 나타남
    \item 특히 비선형 관계를 학습할 수 있는 모형들이 상대적으로 우수한 성능을 보인 것으로 평가됨
    \item DDFM이 변분 자기인코더를 통해 투자의 비선형 동학을 효과적으로 학습하여 최우수 성능을 기록함
    \item XGBoost와 LightGBM도 트리 기반 모형의 특성상 비선형 관계를 학습할 수 있어 상위 성능을 보였음
    \item 전통적 모형들은 중기 예측에서 매우 큰 성능 저하를 보임
\end{itemize}

\subsection{예측 기간별 성능 분석}

\subsubsection{1일 예측}
단기 예측(1일)은 현재 시점에서 바로 다음 시점의 값을 예측하는 것으로, 가장 단기적인 예측 성능을 평가함.
\begin{itemize}
    \item 1일 예측에서는 고빈도 데이터를 활용할 수 있는 모형들이 상대적으로 우수한 성능을 보인 것으로 나타남
    \item DDFM이 평균 0.367의 표준화된 RMSE로 최우수 성능을 기록하였으며, DFM이 0.452의 RMSE로 두 번째로 우수한 성능을 보임
    \item clock 프레임워크를 통해 혼합 빈도 데이터를 효과적으로 처리하여 우수한 성능을 달성함
    \item 단기 예측에서는 시계열의 최근 패턴이 중요하므로, 장기 의존성을 학습하는 모형의 장점이 크지 않을 수 있음. 그러나 DDFM은 비선형 요인 구조 학습 능력으로 인해 단기 예측에서도 우수한 성능을 보였음
    \item XGBoost와 LightGBM은 각각 0.750, 0.734의 RMSE로 시차 변수를 명시적으로 생성하여 단기 예측에 활용할 수 있어 상위 성능을 기록함
    \item 전통적 모형인 ARIMA는 0.762의 RMSE로 단변량 모형의 한계로 인해 다른 변수들의 정보를 활용하지 못하여 상대적으로 낮은 성능을 보였음
\end{itemize}

\subsubsection{7일 예측}
중단기 예측(7일)은 약 1주일 후의 값을 예측하는 것으로, 단기와 중기 예측의 중간 성격을 가짐.
\begin{itemize}
    \item 예측 기간이 길어지면서 일부 모형의 성능이 저하되기 시작하는 것으로 나타남
    \item DDFM이 평균 0.653의 표준화된 RMSE로 가장 우수한 성능을 보였으며, DFM이 0.838의 RMSE로 두 번째로 우수한 성능을 기록함
    \item 특히 전통적 모형인 ARIMA, VAR, VECM은 각각 1.673, 1.443, 1.289의 RMSE로 선형 가정의 한계로 인해 성능 저하가 두드러지게 관찰됨
    \item 시계열의 시간적 패턴을 학습할 수 있는 모형들이 상대적으로 우수한 성능을 보인 것으로 평가됨
    \item DDFM이 가장 우수한 성능을 보였으며, 이는 비선형 요인 구조 학습 능력과 혼합 빈도 데이터 처리 능력을 동시에 활용할 수 있기 때문인 것으로 평가됨
    \item TFT와 DeepAR은 각각 1.103, 0.990의 RMSE로 장기 의존성 학습 능력으로 인해 상위 성능을 기록함
    \item DFM은 선형 요인 구조의 한계로 인해 DDFM보다 낮은 성능을 보였으나, 여전히 전통적 모형보다 우수한 성능을 유지함
\end{itemize}

\subsubsection{28일 예측}
중기 예측(28일)은 약 1개월 후의 값을 예측하는 것으로, 중기 예측 성능을 평가함.
\begin{itemize}
    \item 예측 기간이 길어질수록 모든 모형의 성능이 저하되는 경향을 보임. 이는 예측 불확실성이 시간에 따라 증가하기 때문인 것으로 평가됨
    \item DDFM이 평균 1.785의 표준화된 RMSE로 중기 예측에서도 최우수 성능을 기록하였으며, 이는 비선형 요인 구조 학습 능력이 장기 예측에서도 효과적임을 시사함
    \item DFM이 1.901의 RMSE로 두 번째로 우수한 성능을 보였으며, 장기 의존성을 학습할 수 있는 동적 요인 모형의 우수성이 두드러지게 나타남
    \item TFT는 2.670의 RMSE로 어텐션 메커니즘을 통해 시계열의 장기 의존성을 효과적으로 학습하여 상위 성능을 보였음
    \item DeepAR은 2.743의 RMSE로 자기회귀 구조를 통해 확률적 예측을 제공하여 예측 불확실성을 정량화할 수 있으나, DDFM과 TFT보다 낮은 성능을 기록함
    \item 단순한 선형 모형들은 중기 예측에서 한계를 보인 것으로 평가됨. ARIMA는 4.110의 RMSE로 단변량 모형의 한계로 인해 가장 낮은 성능을 보였으며, VAR과 VECM은 각각 4.452, 5.130의 RMSE로 선형 가정의 한계로 인해 중기 예측에서 성능 저하가 두드러짐
    \item XGBoost와 LightGBM은 각각 3.487, 3.532의 RMSE로 트리 기반 모형의 특성상 장기 의존성을 학습하는 데 한계가 있어 중기 예측에서 성능 저하가 관찰됨
\end{itemize}

\subsection{DFM vs DDFM 나우캐스팅 비교}

마스킹된 데이터를 활용한 백테스팅을 통해 DFM과 DDFM의 나우캐스팅 성능을 비교함. 나우캐스팅은 공식 통계 발표 전에 현재 분기의 경제 상황을 추정하는 것으로, 실제 정책 결정에 중요한 역할을 함.

\subsubsection{나우캐스팅 성능 비교}
표 \ref{tab:nowcasting_metrics}는 두 모형의 나우캐스팅 성능을 보여줌.

\begin{table}[h]
\centering
\caption{DFM vs DDFM 나우캐스팅 성능 비교 (전체 평균)}
\label{tab:nowcasting_metrics}
\begin{tabular}{lccc}
\toprule
모형 & sMSE & sMAE & sRMSE \\
\midrule
DFM & 1.192 & 1.192 & 1.192 \\
DDFM & 0.938 & 0.938 & 0.938 \\
\bottomrule
\end{tabular}
\end{table}

dfm-python을 활용한 나우캐스팅 성능 비교 결과는 다음과 같음:
\begin{itemize}
    \item DDFM이 평균 0.938의 표준화된 RMSE로 DFM(평균 1.192의 RMSE)보다 우수한 성능을 보인 것으로 나타남
    \item dfm-python의 clock 프레임워크를 통해 월간 고빈도 지표들을 활용하여 분기별 목표 변수를 효과적으로 예측할 수 있었으며, 특히 총고정자본형성 예측에서 DDFM의 성능 개선이 두드러지게 나타났음
    \item 이는 DDFM의 비선형 인코더가 정보가 제한적인 나우캐스팅 상황에서도 비선형 요인 구조를 효과적으로 학습할 수 있기 때문인 것으로 평가됨
    \item GDP와 민간 소비 예측에서도 DDFM이 DFM보다 개선된 성능을 보였으나, 그 차이는 총고정자본형성보다 작은 것으로 나타남
    \item dfm-python의 News decomposition 기능을 통해 새로운 데이터 발표 시 예측 업데이트의 기여도를 분석할 수 있으며, 이를 통해 나우캐스팅의 신뢰성을 향상시킬 수 있음
\end{itemize}

표 \ref{tab:nowcasting_by_target}는 목표 변수별 나우캐스팅 성능을 보여줌.
\begin{itemize}
    \item 모든 목표 변수에서 DDFM이 DFM보다 우수한 성능을 기록하였음
    \item 특히 변동성이 큰 총고정자본형성에서 성능 개선이 가장 크게 나타남
\end{itemize}

\begin{table}[h]
\centering
\caption{목표 변수별 나우캐스팅 성능 비교 (표준화된 RMSE)}
\label{tab:nowcasting_by_target}
\begin{tabular}{lccc}
\toprule
모형 & GDP & 민간 소비 & 총고정자본형성 \\
\midrule
DFM & [결과] & [결과] & [결과] \\
DDFM & [결과] & [결과] & [결과] \\
\bottomrule
\end{tabular}
\end{table}

표 \ref{tab:nowcasting_by_masking}는 마스킹 기간별 나우캐스팅 성능을 보여줌.
\begin{itemize}
    \item 마스킹 기간이 길어질수록(즉, 더 오래 전의 데이터만 사용할수록) 두 모형 모두 성능이 저하되는 경향을 보였음
    \item DDFM이 모든 마스킹 기간에서 DFM보다 우수한 성능을 유지한 것으로 나타남
    \item 이는 DDFM의 비선형 요인 구조 학습 능력이 정보가 제한적인 상황에서도 효과적임을 시사함
\end{itemize}

\begin{table}[h]
\centering
\caption{마스킹 기간별 나우캐스팅 성능 비교 (표준화된 RMSE)}
\label{tab:nowcasting_by_masking}
\begin{tabular}{lccc}
\toprule
모형 & 1주일 전 & 2주일 전 & 1개월 전 \\
\midrule
DFM & [결과] & [결과] & [결과] \\
DDFM & [결과] & [결과] & [결과] \\
\bottomrule
\end{tabular}
\end{table}

\subsection{dfm-python을 활용한 Ablation Study 결과}

dfm-python 패키지의 설정을 변경하여 DFM과 DDFM의 하이퍼파라미터가 성능에 미치는 영향을 분석함. YAML 설정 파일을 통해 요인 개수, AR 차수, 인코더 구조 등을 조정하고, 각 설정에 대한 성능을 비교함.

\subsubsection{DFM 하이퍼파라미터 분석}
dfm-python의 DFM 설정에서 요인 개수와 AR 차수 변화에 따른 성능 분석 결과는 다음과 같음.
\begin{itemize}
    \item 요인 개수는 블록 구조에서 설정하며, Block\_Global의 factors 파라미터를 조정함
    \item 요인 개수가 증가할수록 모형의 표현력이 향상되나, 과적합의 위험이 증가하는 것으로 나타남
    \item 최적 요인 개수는 목표 변수에 따라 다르게 나타났으며, GDP 예측에서는 3-4개의 요인이, 총고정자본형성 예측에서는 4-5개의 요인이 최적인 것으로 평가됨
    \item AR 차수는 dfm-python 설정에서 ar\_lag 파라미터로 조정함
    \item AR(1)과 AR(2)를 비교한 결과, 대부분의 경우 AR(1)이 더 우수한 성능을 보였으며, 이는 요인의 단기 의존성이 더 중요함을 시사함
    \item AR 차수가 증가할수록 모형의 복잡도가 증가하여 과적합의 위험이 높아지는 것으로 나타남
    \item dfm-python의 EM 알고리즘은 수렴 기준(threshold)과 최대 반복 횟수(max\_iter)를 설정할 수 있으며, 본 연구에서는 threshold=1e-4, max\_iter=100으로 설정함
\end{itemize}

표 \ref{tab:dfm_ablation_factors}는 요인 개수별 DFM 성능을 보여줌.
\begin{itemize}
    \item 요인 개수가 3-4개일 때 최적 성능을 보였음
    \item 요인 개수가 너무 적거나 많을 경우 성능이 저하되는 것으로 나타남
\end{itemize}

\begin{table}[h]
\centering
\caption{DFM 요인 개수별 성능 비교 (표준화된 RMSE)}
\label{tab:dfm_ablation_factors}
\begin{tabular}{lccc}
\toprule
요인 개수 & GDP & 민간 소비 & 총고정자본형성 \\
\midrule
1개 & [결과] & [결과] & [결과] \\
2개 & [결과] & [결과] & [결과] \\
3개 & [결과] & [결과] & [결과] \\
4개 & [결과] & [결과] & [결과] \\
5개 & [결과] & [결과] & [결과] \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{DDFM 하이퍼파라미터 분석}
dfm-python의 DDFM 설정에서 인코더 레이어 수, 학습률, 배치 크기 변화에 따른 성능 분석 결과는 다음과 같음.
\begin{itemize}
    \item 인코더 레이어 구조는 encoder\_layers 파라미터로 설정하며, 예를 들어 [64, 32]는 2개 레이어를 의미함
    \item 인코더 레이어 수가 증가할수록 비선형 변환의 복잡도가 증가하여 더 복잡한 요인 구조를 학습할 수 있으나, 과적합의 위험이 증가하는 것으로 나타남
    \item 최적 인코더 레이어 수는 2-3개인 것으로 평가되며, 레이어가 너무 많을 경우 성능이 저하되는 것으로 나타남
    \item 학습률은 dfm-python 설정에서 learning\_rate 파라미터로 조정함
    \item 학습률이 너무 작으면 학습 속도가 느려지고, 너무 크면 학습이 불안정해지는 것으로 나타남
    \item 최적 학습률은 0.001-0.01 범위인 것으로 평가됨
    \item dfm-python의 DDFMTrainer는 Adam 옵티마이저를 사용하며, 학습률 스케줄링을 지원함
    \item 배치 크기는 dfm-python 설정에서 batch\_size 파라미터로 조정함
    \item 배치 크기가 작을수록 학습이 불안정해지고, 클수록 메모리 사용량이 증가하는 것으로 나타남
    \item 최적 배치 크기는 32-64인 것으로 평가됨
    \item dfm-python의 DDFM은 배치 기반 학습을 사용하므로, DFM의 EM 알고리즘과 달리 메모리 효율적인 학습이 가능함
\end{itemize}

표 \ref{tab:ddfm_ablation_layers}는 인코더 레이어 수별 DDFM 성능을 보여줌.
\begin{itemize}
    \item 2-3개의 레이어에서 최적 성능을 보였음
    \item 레이어가 너무 적거나 많을 경우 성능이 저하되는 것으로 나타남
\end{itemize}

\begin{table}[h]
\centering
\caption{DDFM 인코더 레이어 수별 성능 비교 (표준화된 RMSE)}
\label{tab:ddfm_ablation_layers}
\begin{tabular}{lccc}
\toprule
레이어 수 & GDP & 민간 소비 & 총고정자본형성 \\
\midrule
1개 & [결과] & [결과] & [결과] \\
2개 & [결과] & [결과] & [결과] \\
3개 & [결과] & [결과] & [결과] \\
4개 & [결과] & [결과] & [결과] \\
\bottomrule
\end{tabular}
\end{table}

표 \ref{tab:ddfm_ablation_lr}는 학습률별 DDFM 성능을 보여줌.
\begin{itemize}
    \item 학습률 0.001-0.01 범위에서 최적 성능을 보였음
    \item 학습률이 너무 작거나 클 경우 성능이 저하되는 것으로 나타남
\end{itemize}

\begin{table}[h]
\centering
\caption{DDFM 학습률별 성능 비교 (표준화된 RMSE)}
\label{tab:ddfm_ablation_lr}
\begin{tabular}{lccc}
\toprule
학습률 & GDP & 민간 소비 & 총고정자본형성 \\
\midrule
0.0001 & [결과] & [결과] & [결과] \\
0.001 & [결과] & [결과] & [결과] \\
0.01 & [결과] & [결과] & [결과] \\
0.1 & [결과] & [결과] & [결과] \\
\bottomrule
\end{tabular}
\end{table}

\subsection{시각화}

\subsubsection{모형별 성능 비교}
그림 \ref{fig:model_comparison}은 모형별 성능을 비교한 막대 그래프를 보여줌.
\begin{itemize}
    \item DDFM이 모든 평가 지표에서 최우수 성능을 기록한 것으로 나타나며, DFM이 두 번째로 우수한 성능을 보임
    \item 딥러닝 모형인 TFT와 DeepAR도 상위 성능을 기록하였음
    \item 전통적 모형인 ARIMA, VAR, VECM은 상대적으로 낮은 성능을 보임
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/model_comparison.png}
\caption{모형별 성능 비교 (표준화된 RMSE)}
\label{fig:model_comparison}
\end{figure}

\subsubsection{예측 기간별 성능 추이}
그림 \ref{fig:horizon_trend}는 예측 기간별 성능 추이를 보여줌.
\begin{itemize}
    \item 예측 기간이 길어질수록 모든 모형의 성능이 저하되는 경향을 보임
    \item DDFM과 TFT는 상대적으로 안정적인 성능을 유지한 것으로 나타남
    \item 전통적 모형들은 예측 기간이 길어질수록 성능 저하가 두드러지게 나타남
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/horizon_trend.png}
\caption{예측 기간별 성능 추이 (표준화된 RMSE)}
\label{fig:horizon_trend}
\end{figure}

\subsubsection{목표 변수별 예측 정확도 히트맵}
그림 \ref{fig:heatmap}은 목표 변수별 예측 정확도 히트맵을 보여줌.
\begin{itemize}
    \item DDFM이 모든 목표 변수에서 최우수 성능을 기록한 것으로 나타남
    \item 특히 총고정자본형성 예측에서 다른 모형들과의 성능 차이가 가장 크게 나타남
    \item GDP 예측에서는 DFM과 DDFM이 유사한 성능을 보였으나, 민간 소비와 총고정자본형성 예측에서는 DDFM의 우위가 두드러지게 나타남
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/accuracy_heatmap.png}
\caption{목표 변수별 예측 정확도 히트맵 (표준화된 RMSE)}
\label{fig:heatmap}
\end{figure}

\subsubsection{예측값 vs 실제값 시계열 비교}
그림 \ref{fig:forecast_vs_actual}은 주요 모형들의 예측값과 실제값을 비교한 시계열 그래프를 보여줌.
\begin{itemize}
    \item DDFM의 예측값이 실제값에 가장 근접한 것으로 나타남
    \item 특히 변동성이 큰 시기(예: COVID-19 팬데믹 기간)에서도 안정적인 예측 성능을 유지한 것으로 평가됨
\end{itemize}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/forecast_vs_actual.png}
\caption{예측값 vs 실제값 시계열 비교 (GDP)}
\label{fig:forecast_vs_actual}
\end{figure}
