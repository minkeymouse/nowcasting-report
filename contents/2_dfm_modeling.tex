\section{동적 요인 모델을 활용한 소비, 투자, 생산 관련 시계열 모델링 및 예측}
\label{sec:dfm_modeling}

\subsection{동적 요인 모형의 이론적 배경}
\label{sec:dfm_theory}

\subsubsection{상태 공간 모형의 기초}
동적 요인 모형(Dynamic Factor Model, DFM)은 상태 공간 모형(state-space model)의 특수한 형태이다. 상태 공간 모형은 관측 가능한 데이터 $y_t$가 관측 불가능한 잠재 상태(latent state) $x_t$에 의존하는 시스템을 모델링하는 수학적 프레임워크이다.

상태 공간 모형은 두 개의 방정식으로 구성된다:

\begin{align}
x_t &= F_t x_{t-1} + G_t u_t + w_t, \quad w_t \sim \mathcal{N}(0, Q_t) \label{eq:state_transition} \\
y_t &= H_t x_t + v_t, \quad v_t \sim \mathcal{N}(0, R_t) \label{eq:observation}
\end{align}

여기서 첫 번째 방정식은 전이 방정식(transition equation)으로, 잠재 상태가 시간에 따라 어떻게 진화하는지를 나타낸다. 두 번째 방정식은 관측 방정식(observation equation)으로, 잠재 상태가 관측 가능한 데이터와 어떻게 연결되는지를 나타낸다.

상태 공간 모형의 핵심은 Markov 성질(Markov property)이다. 이는 미래 상태가 현재 상태에만 의존하고 과거 상태에는 직접적으로 의존하지 않는다는 가정이다:

\begin{equation}
p(x_t | x_{1:t-1}) = p(x_t | x_{t-1})
\end{equation}

이러한 가정은 계산적 효율성을 제공하며, Kalman 필터를 통한 재귀적 상태 추정을 가능하게 한다.

\subsubsection{동적 요인 모형의 기본 구조}
동적 요인 모형은 상태 공간 모형의 특수한 형태로, 많은 시계열에서 공통 요인(common factors)을 추출하여 차원을 축소하고, 혼합 빈도 데이터를 효과적으로 처리할 수 있는 모형이다. DFM은 다음과 같이 정의된다:

\begin{align}
x_t &= C z_t + \varepsilon_t, \quad \varepsilon_t \sim \mathcal{N}(0, R) \label{eq:dfm_obs} \\
z_t &= A z_{t-1} + \eta_t, \quad \eta_t \sim \mathcal{N}(0, Q) \label{eq:dfm_state}
\end{align}

여기서 $x_t \in \mathbb{R}^N$는 $N$개의 관측 시계열, $z_t \in \mathbb{R}^r$는 $r$개의 공통 요인, $C \in \mathbb{R}^{N \times r}$는 요인 적재 행렬(factor loading matrix), $A \in \mathbb{R}^{r \times r}$는 요인의 전이 행렬(transition matrix)이다. $\varepsilon_t$와 $\eta_t$는 각각 관측 오차와 상태 오차로, 정규분포를 따른다.

DFM의 핵심 아이디어는 많은 시계열이 소수의 공통 요인에 의해 설명될 수 있다는 것이다. 이를 통해 고차원 시계열 데이터의 차원을 효과적으로 축소할 수 있으며, 과적합 문제를 완화할 수 있다. 예를 들어, 100개의 시계열이 3-5개의 공통 요인으로 설명될 수 있다면, 모형의 복잡도는 크게 감소한다.

요인 적재 행렬 $C$의 각 원소 $C_{ij}$는 시계열 $i$가 요인 $j$에 얼마나 민감한지를 나타낸다. 전이 행렬 $A$는 요인이 시간에 따라 어떻게 진화하는지를 결정하며, $A$의 고유값(eigenvalue)이 1보다 작으면 요인은 정상 과정(stationary process)을 따른다.

\subsubsection{혼합 빈도 데이터 처리: clock 프레임워크}
DFM의 가장 큰 장점 중 하나는 혼합 빈도(mixed-frequency) 데이터를 자연스럽게 처리할 수 있다는 점이다. 본 연구에서는 분기별 목표 변수(GDP, 소비, 투자)를 월간 또는 주간 고빈도 지표로부터 예측한다.

dfm-python 패키지는 clock 프레임워크(clock-based framework)를 사용하여 혼합 빈도 데이터를 처리한다. 이 프레임워크의 핵심 아이디어는 모든 잠재 요인이 공통의 clock 빈도(예: 월간)에서 진화하지만, 관측 시계열은 서로 다른 빈도(월간, 분기별 등)를 가질 수 있다는 것이다.

clock 빈도는 일간('d'), 주간('w'), 월간('m'), 분기별('q'), 반기별('sa'), 연간('a') 중에서 선택할 수 있으며, 본 연구에서는 월간('m')을 clock 빈도로 사용한다. 이는 대부분의 설명 변수가 월간 빈도를 가지기 때문이다.

\paragraph{텐트 커널 집계}
저빈도 시계열(예: 분기별 GDP)을 고빈도 요인(예: 월간 요인)으로부터 생성하기 위해 텐트 커널(tent kernel) 집계 방식을 사용한다. 텐트 커널은 시간 가중치를 부여하여, 분기 내 각 월의 기여도를 다르게 설정한다.

구체적으로, 분기별 목표 변수 $y_t^q$는 다음과 같이 모델링된다:

\begin{equation}
y_t^q = \sum_{s \in S_t} w_s z_s^m + \varepsilon_t^q
\end{equation}

여기서 $z_s^m$는 월간 요인, $S_t$는 분기 $t$에 해당하는 월간 시점들의 집합, $w_s$는 텐트 커널 가중치이다. 텐트 커널 가중치는 분기의 시작과 끝에서 작고, 중간에서 크게 설정되어, 분기의 중간 시점이 더 큰 가중치를 갖도록 한다.

텐트 커널의 수학적 정의는 다음과 같다:
\begin{equation}
w_s = \begin{cases}
\frac{s - s_{\text{start}}}{s_{\text{mid}} - s_{\text{start}}} & \text{if } s \leq s_{\text{mid}} \\
\frac{s_{\text{end}} - s}{s_{\text{end}} - s_{\text{mid}}} & \text{if } s > s_{\text{mid}}
\end{cases}
\end{equation}

여기서 $s_{\text{start}}$, $s_{\text{mid}}$, $s_{\text{end}}$는 각각 분기의 시작, 중간, 끝 시점이다.

\paragraph{특이 성분(Idiosyncratic Components)}
각 시계열은 공통 요인 외에도 시계열별 특이 성분(idiosyncratic component)을 가질 수 있다. 특이 성분은 해당 시계열에만 특화된 변동을 나타내며, AR(1) 과정으로 모델링된다:

\begin{equation}
u_{i,t} = \rho_i u_{i,t-1} + \xi_{i,t}, \quad \xi_{i,t} \sim \mathcal{N}(0, \sigma_i^2)
\end{equation}

저빈도 시계열의 경우, 텐트 길이 체인(tent-length chain)을 사용하여 특이 성분을 모델링한다. 이를 통해 저빈도 시계열의 특이 변동을 더 정확하게 포착할 수 있다.

\subsection{데이터 및 전처리}
\label{sec:dfm_data}

\subsubsection{데이터셋 개요}
본 연구는 한국은행 경제통계시스템(ECOS)에서 수집한 한국 거시경제 시계열 데이터를 활용한다. 데이터 기간은 1985년 4월부터 2025년 11월까지이며, 총 2,538개의 관측치와 101개의 시계열 변수로 구성되어 있다.

데이터는 혼합 빈도 구조를 가지고 있으며, 월간 변수 87개, 분기별 변수 8개, 주간 변수 6개로 구성되어 있다. 변수들은 다음과 같은 카테고리로 분류된다: 생산(Production) 20개, 기업 설문(Survey, Bsnss) 16개, 금융(Finance) 11개, 소비자 설문(Survey, Cnsmr) 10개, 무역(Int. trade) 8개, 거시경제(Macro) 8개, 노동(Labor) 7개, 투자(Investment) 7개, 소비(Consumption) 6개, 물가(Price) 5개 등이다.

\subsubsection{목표 변수}
본 연구의 예측 대상은 다음과 같은 3개의 분기별 거시경제 변수이다:

\begin{itemize}
    \item \textbf{KOGDP\_\_\_D}: 국내총생산(GDP), 실질 기준, 사슬 연결 가중치(Chained W, Billions). 총 162개의 관측치가 있으며, 평균 변화율은 5.16\%, 표준편차는 5.80\%이다.
    \item \textbf{KOCNPER\_D}: 민간 소비(Consumption, Private), 실질 기준, 사슬 연결 가중치. 총 162개의 관측치가 있으며, 평균 변화율은 4.39\%, 표준편차는 7.22\%이다.
    \item \textbf{KOGFCF\_\_\_D}: 총고정자본형성(Gross Capital Formation, Fixed), 실질 기준, 사슬 연결 가중치. 총 162개의 관측치가 있으며, 평균 변화율은 5.01\%, 표준편차는 11.86\%로 가장 큰 변동성을 보인다.
\end{itemize}

이러한 목표 변수들은 분기별로 발표되며, 해당 분기 종료 후 약 25일 정도의 시차를 가지고 있다. 따라서 나우캐스팅을 통해 공식 발표 전에 현재 분기의 값을 추정하는 것이 가능하다.

\subsubsection{전처리 방법}
본 연구에서는 sktime 라이브러리를 활용한 전처리 파이프라인을 구축하였다. dfm-python 패키지는 TransformerPipeline을 사용하여 원시 데이터를 자동으로 전처리할 수 있도록 지원한다.

\paragraph{변환(Transformation)}
각 시계열 변수는 메타데이터에 명시된 변환 방법에 따라 전처리된다:

\begin{itemize}
    \item \textbf{chg (Change)}: 전년 동기 대비 변화율 계산. 시계열의 성장률을 나타내며, 추세를 제거하여 정상성을 향상시킨다.
    \item \textbf{cha (Chained)}: 사슬 연결 가중치 적용. 물가 변동을 고려한 실질 가치를 나타낸다.
    \item \textbf{lin (Linear)}: 선형 변환 없음. 원시 데이터를 그대로 사용한다.
\end{itemize}

\paragraph{표준화(Standardization)}
모든 변수는 표준화(standardization)를 통해 평균 0, 표준편차 1로 변환된다. dfm-python에서는 통합 표준화(unified scaling)를 사용하며, 이는 모든 시계열에 동일한 StandardScaler를 적용하는 것을 의미한다. 이는 요인 모형에서 모든 시계열이 요인 추출에 비례적으로 기여하도록 보장하며, 척도에 의한 지배를 방지한다.

\paragraph{결측치 처리}
결측치는 두 단계로 처리된다:
\begin{enumerate}
    \item \textbf{전방 채우기(Forward Fill)}: 결측치를 이전 값으로 채운다.
    \item \textbf{후방 채우기(Backward Fill)}: 전방 채우기 후에도 결측치가 남아있으면 다음 값으로 채운다.
\end{enumerate}

이러한 방식은 시계열의 시간적 연속성을 유지하면서 결측치를 처리한다. dfm-python의 Kalman 필터는 결측치를 자연스럽게 처리할 수 있지만, 전처리 단계에서 결측치를 최소화하는 것이 모형 성능에 도움이 된다.

\paragraph{전처리 파이프라인}
전처리 파이프라인은 다음과 같이 구성된다:

\begin{verbatim}
TransformerPipeline(
    steps=[
        ('impute_ffill', Imputer(method="ffill")),
        ('impute_bfill', Imputer(method="bfill")),
        ('scaler', StandardScaler())
    ]
)
\end{verbatim}

이 파이프라인은 DFMDataModule의 setup() 메서드에서 자동으로 적용되며, 원시 데이터를 모형 학습에 적합한 형태로 변환한다.

\subsection{DFM 모형의 구현 및 적합}
\label{sec:dfm_implementation}

\subsubsection{dfm-python 패키지 활용}
본 연구에서는 dfm-python 패키지를 활용하여 DFM을 구현한다. dfm-python은 혼합 빈도 데이터를 처리할 수 있는 동적 요인 모형의 Python 구현체로, 다음과 같은 특징을 가진다:

\begin{itemize}
    \item \textbf{혼합 빈도 데이터 처리}: 일간, 주간, 월간, 분기별, 반기별, 연간 데이터를 하나의 모형에서 처리할 수 있다.
    \item \textbf{clock 프레임워크}: 모든 요인이 공통의 clock 빈도에서 진화하지만, 관측 시계열은 서로 다른 빈도를 가질 수 있다.
    \item \textbf{텐트 커널 집계}: 저빈도 시계열을 고빈도 요인으로부터 생성하기 위한 텐트 커널 방식을 제공한다.
    \item \textbf{Kalman 필터 및 스무더}: 요인과 관측치를 효율적으로 추정하기 위한 Kalman 필터와 스무더를 구현한다.
    \item \textbf{EM 알고리즘}: 파라미터 추정을 위한 EM 알고리즘을 구현하며, PCA 기반 초기화를 제공한다.
    \item \textbf{블록 구조}: 전역 요인과 섹터별 요인을 모델링할 수 있는 유연한 블록 구조를 지원한다.
    \item \textbf{특이 성분}: 각 시계열의 특이 변동을 모델링하기 위한 특이 성분(idiosyncratic components)을 지원한다.
    \item \textbf{Hydra 기반 설정 관리}: YAML 파일을 통한 설정 관리와 명령줄 오버라이드를 지원한다.
    \item \textbf{수치적 안정성}: 적응형 릿지 정규화, Q 행렬 플로어, C 행렬 정규화, 스펙트럼 반경 제한 등을 통한 수치적 안정성을 보장한다.
\end{itemize}

dfm-python 패키지는 사용자가 전처리된 데이터를 제공하거나, sktime의 TransformerPipeline을 사용하여 원시 데이터를 전처리할 수 있도록 지원한다. 본 연구에서는 TransformerPipeline을 사용하여 결측치 보간, 표준화 등을 자동으로 수행한다.

\subsubsection{요인 구조 설정: 블록 구조}
DFM의 요인 구조는 블록 구조(block structure)를 사용하여 설정된다. 블록 구조는 계층적 요인 모델링을 가능하게 하며, 전역 요인과 섹터별 요인을 동시에 모델링할 수 있다.

본 연구에서는 다음과 같은 블록 구조를 사용한다:

\begin{itemize}
    \item \textbf{Block\_Global}: 전체 시계열에 공통으로 영향을 미치는 전역 요인. 이는 전체 경제 활동의 공통 변동을 나타내며, GDP와 높은 상관관계를 가질 것으로 예상된다.
    \item \textbf{Block\_Consumption}: 소비 관련 변수들에 영향을 미치는 소비 요인. 소비자 심리지수, 소매판매액 등 소비 관련 변수들의 공통 변동을 포착한다.
    \item \textbf{Block\_Investment}: 투자 관련 변수들에 영향을 미치는 투자 요인. 설비투자, 건설 착공 등 투자 관련 변수들의 공통 변동을 포착한다.
    \item \textbf{Block\_Export}: 수출 관련 변수들에 영향을 미치는 수출 요인. 수출액, 수출 물가 등 수출 관련 변수들의 공통 변동을 포착한다.
    \item \textbf{Block\_Nominal}: 명목 변수들에 영향을 미치는 명목 요인. 물가, 명목 금리 등 명목 변수들의 공통 변동을 포착한다.
    \item \textbf{Block\_Labor}: 노동 관련 변수들에 영향을 미치는 노동 요인. 고용, 실업률 등 노동 관련 변수들의 공통 변동을 포착한다.
\end{itemize}

각 블록은 독립적인 요인 개수와 AR 차수를 가질 수 있다. 예를 들어, Block\_Global은 2개의 요인과 AR(1) 차수를 가질 수 있고, Block\_Consumption은 1개의 요인과 AR(1) 차수를 가질 수 있다. 각 블록의 요인 개수와 AR 차수는 정보 기준(AIC, BIC) 또는 교차 검증을 통해 선택된다.

블록 구조의 장점은 다음과 같다:
\begin{itemize}
    \item \textbf{해석가능성}: 각 블록의 요인은 명확한 경제적 의미를 가진다.
    \item \textbf{유연성}: 각 섹터별로 다른 요인 구조를 설정할 수 있다.
    \item \textbf{확장성}: 새로운 섹터를 추가하거나 기존 섹터를 수정하기 쉽다.
\end{itemize}

\subsubsection{Kalman 필터와 스무더}
DFM에서 요인을 추정하기 위해 Kalman 필터(Kalman filter)와 Kalman 스무더(Kalman smoother)를 사용한다. Kalman 필터는 재귀적으로 상태를 추정하는 알고리즘으로, 새로운 관측치가 도착할 때마다 상태 추정을 업데이트한다.

\paragraph{Kalman 필터의 직관}
Kalman 필터는 베이즈 정리를 기반으로 하며, 예측(사전 분포)과 관측(가능도)을 결합하여 사후 분포를 계산한다. 사후 분포는 다음과 같이 표현된다:

\begin{equation}
p(z_t | x_{1:t}) \propto p(x_t | z_t) p(z_t | x_{1:t-1})
\end{equation}

선형-가우시안 시스템에서 사전 분포와 가능도가 모두 가우시안이므로, 사후 분포도 가우시안이 된다. 이는 계산을 크게 단순화한다.

Kalman 필터는 두 단계로 구성된다:
\begin{enumerate}
    \item \textbf{예측 단계(Prediction)}: 이전 시점의 상태 추정을 바탕으로 현재 시점의 상태를 예측한다.
    \begin{align}
    z_{t|t-1} &= A z_{t-1|t-1} \\
    P_{t|t-1} &= A P_{t-1|t-1} A^T + Q
    \end{align}
    여기서 $z_{t|t-1}$는 $t-1$ 시점까지의 정보를 바탕으로 한 $t$ 시점의 상태 예측, $P_{t|t-1}$는 예측 오차 공분산이다. 전이 행렬 $A$는 요인의 동학을 반영하며, 공분산 $Q$는 요인 혁신의 불확실성을 나타낸다.
    
    \item \textbf{업데이트 단계(Update)}: 새로운 관측치를 사용하여 상태 추정을 업데이트한다.
    \begin{align}
    K_t &= P_{t|t-1} C^T (C P_{t|t-1} C^T + R)^{-1} \\
    z_{t|t} &= z_{t|t-1} + K_t (x_t - C z_{t|t-1}) \\
    P_{t|t} &= (I - K_t C) P_{t|t-1}
    \end{align}
    여기서 $K_t$는 Kalman 이득(Kalman gain)으로, 관측치의 신뢰도와 예측의 신뢰도를 균형있게 조절한다. 혁신(innovation) $x_t - C z_{t|t-1}$는 예측 오차를 나타내며, Kalman 이득은 이 오차를 얼마나 반영할지를 결정한다.
    
    Kalman 이득의 직관적 의미는 다음과 같다:
    \begin{itemize}
        \item 관측 오차 $R$이 크면(관측치가 불신뢰할수록) $K_t \to 0$이 되어 예측에 더 의존한다.
        \item 예측 오차 $P_{t|t-1}$가 크면(예측이 불확실할수록) $K_t$가 커져 관측치에 더 의존한다.
    \end{itemize}
\end{enumerate}

\paragraph{Kalman 스무더}
Kalman 스무더는 모든 관측치를 사용하여 과거 시점의 상태를 재추정한다. 이는 Kalman 필터가 각 시점에서만 사용 가능한 정보를 활용하는 것과 달리, 전체 시계열 정보를 활용하여 더 정확한 상태 추정을 제공한다.

스무더는 역방향으로 실행되며, Rauch-Tung-Striebel (RTS) 스무더 방정식을 사용한다:

\begin{align}
J_t &= P_{t|t} A^T P_{t+1|t}^{-1} \\
z_{t|T} &= z_{t|t} + J_t (z_{t+1|T} - z_{t+1|t}) \\
P_{t|T} &= P_{t|t} + J_t (P_{t+1|T} - P_{t+1|t}) J_t^T
\end{align}

여기서 $J_t$는 스무더 이득(smoother gain)으로, 미래 정보를 과거로 전파한다. 스무더 추정 $\hat{z}_{t|T}$는 필터 추정 $\hat{z}_{t|t}$에 보정 항을 더한 것으로, 미래 정보를 활용하여 과거 추정을 개선한다.

스무더는 EM 알고리즘의 E-step에서 필수적이다. EM 알고리즘은 전체 시계열에 대한 요인 추정 $E[z_t | x_{1:T}]$와 $E[z_t z_{t-1}^T | x_{1:T}]$가 필요하므로, 필터만으로는 부족하고 스무더가 필요하다.

\subsubsection{EM 알고리즘을 통한 파라미터 추정}
\subsubsection{주성분 분석 기반 초기화}
EM 알고리즘의 성공적인 수렴을 위해 좋은 초기값이 중요하다. 본 연구에서는 주성분 분석(Principal Component Analysis, PCA)을 사용하여 초기 파라미터를 설정한다 \cite{stock2002forecasting}.

PCA는 선형 차원 축소 방법으로, 관측 데이터의 공분산 행렬을 고유값 분해하여 주성분을 추출한다. 첫 $k$개의 주성분 벡터는 요인 적재 행렬의 초기값으로 사용되며, 주성분 점수는 요인의 초기 추정값으로 사용된다. 전이 행렬 $A$는 요인의 자기회귀 회귀를 통해 초기화된다.

PCA 초기화의 장점은 다음과 같다:
\begin{itemize}
    \item \textbf{계산 효율성}: 고유값 분해는 빠르게 수행할 수 있다.
    \item \textbf{합리적인 시작점}: PCA는 데이터의 주요 변동 방향을 포착하므로, EM 알고리즘이 좋은 지역 최적해로 수렴할 가능성이 높다.
    \item \textbf{수렴 안정성}: 나쁜 초기값은 수렴 실패나 지역 최적해로의 수렴을 야기할 수 있으나, PCA 초기화는 이를 방지한다.
\end{itemize}

\subsubsection{EM 알고리즘을 통한 파라미터 추정}
DFM의 파라미터(요인 적재 행렬 $C$, 전이 행렬 $A$, 공분산 행렬 $Q$와 $R$)는 기대값 최대화(Expectation-Maximization, EM) 알고리즘을 통해 추정된다. EM 알고리즘은 잠재 변수(요인)와 파라미터를 동시에 추정하는 반복적 최적화 방법이다.

EM 알고리즘은 다음과 같은 단계로 구성된다:

\begin{enumerate}
    \item \textbf{초기화}: 주성분 분석(PCA)을 사용하여 초기 파라미터를 설정한다. 첫 $k$개의 주성분을 요인으로 사용하고, 요인 적재 행렬은 주성분 벡터로 초기화한다. 전이 행렬은 요인의 자기회귀 회귀를 통해 초기화한다.
    
    \item \textbf{E-step (Expectation)}: 현재 파라미터 추정값을 사용하여 Kalman 필터와 스무더를 실행하여 요인의 조건부 기대값과 공분산을 계산한다. 
    
    Kalman 필터는 순방향으로 실행되어 각 시점에서의 요인 추정 $\hat{z}_{t|t}$와 공분산 $P_{t|t}$를 계산한다. Kalman 스무더는 역방향으로 실행되어 모든 관측치를 사용한 요인 추정 $\hat{z}_{t|T}$와 공분산 $P_{t|T}$를 계산한다.
    
    \begin{align}
    \hat{z}_t &= \mathbb{E}[z_t | x_{1:T}, \theta^{(k)}] = \hat{z}_{t|T} \\
    P_t &= \text{Cov}[z_t | x_{1:T}, \theta^{(k)}] = P_{t|T} \\
    P_{t,t-1} &= \text{Cov}[z_t, z_{t-1} | x_{1:T}, \theta^{(k)}]
    \end{align}
    여기서 $\theta^{(k)}$는 $k$번째 반복에서의 파라미터 추정값이다. 스무더는 필터 추정을 미래 정보로 보정하여 더 정확한 추정을 제공한다.
    
    \item \textbf{M-step (Maximization)}: 계산된 기대값을 사용하여 파라미터를 최대우도 추정한다. 각 파라미터는 다음과 같이 업데이트된다:
    \begin{align}
    A^{(k+1)} &= \left(\sum_{t=2}^T P_{t,t-1}\right) \left(\sum_{t=2}^T P_{t-1}\right)^{-1} \\
    C^{(k+1)} &= \left(\sum_{t=1}^T x_t \hat{z}_t^T\right) \left(\sum_{t=1}^T P_t + \hat{z}_t \hat{z}_t^T\right)^{-1} \\
    Q^{(k+1)} &= \frac{1}{T-1} \sum_{t=2}^T \left(P_t - A^{(k+1)} P_{t,t-1}^T - P_{t,t-1} (A^{(k+1)})^T + A^{(k+1)} P_{t-1} (A^{(k+1)})^T\right) \\
    R^{(k+1)} &= \frac{1}{T} \sum_{t=1}^T \left((x_t - C^{(k+1)} \hat{z}_t)(x_t - C^{(k+1)} \hat{z}_t)^T + C^{(k+1)} P_t (C^{(k+1)})^T\right)
    \end{align}
    
    \item \textbf{수렴 확인}: 로그 가능도의 변화량이 임계값보다 작으면 수렴한 것으로 판단하고 알고리즘을 종료한다. 그렇지 않으면 E-step으로 돌아가 반복한다.
    \begin{equation}
    |\ell(\theta^{(k+1)}) - \ell(\theta^{(k)})| < \epsilon
    \end{equation}
    여기서 $\ell(\theta)$는 로그 가능도 함수이다.
\end{enumerate}

본 연구에서는 최대 반복 횟수를 5,000회로 설정하고, 수렴 임계값을 $10^{-5}$로 설정하였다. EM 알고리즘은 일반적으로 50-200회 반복 내에 수렴하며, 초기화가 중요하다. 나쁜 초기값은 수렴 실패나 지역 최적해로의 수렴을 야기할 수 있다.

\subsection{DFM 예측 결과}
\label{sec:dfm_results}

\subsubsection{예측 성능 평가}
DFM 모형의 예측 성능은 3개의 목표 변수와 3개의 예측 기간(1일, 7일, 28일)에 대해 평가된다. 평가 지표는 표준화된 MSE, MAE, RMSE를 사용하며, 각 지표는 훈련 데이터의 표준편차로 정규화된다.

\begin{center}[아직 실험 미진행]\end{center}

\subsubsection{요인 해석}
DFM에서 추출된 요인들은 경제적 의미를 가질 수 있다. 예를 들어, 전역 요인(Block\_Global)은 전체 경제 활동의 공통 변동을 나타내며, 이는 GDP와 높은 상관관계를 가질 것으로 예상된다. 소비 요인(Block\_Consumption)은 소비 관련 변수들의 공통 변동을 나타내며, 민간 소비 예측에 중요한 역할을 할 수 있다.

\begin{center}[아직 실험 미진행]\end{center}

\subsubsection{나우캐스팅 성능}
DFM의 나우캐스팅 성능은 마스킹된 데이터를 활용한 백테스팅을 통해 평가된다. 구체적으로, 과거 시점에서 최근 관측치를 마스킹하여 실제 나우캐스팅 상황을 시뮬레이션한다.

\begin{center}[아직 실험 미진행]\end{center}

