\section{Methodology}
\label{sec:methodology}

\subsection{Forecasting Models}

This study compares four forecasting models: ARIMA, VAR, DFM, and DDFM. Each model is evaluated on three target variables (KOEQUIPTE, KOWRCCNSE, KOIPALL.G) across three forecast horizons (1, 7, and 28 days). Dataset details and model parameters are summarized in Table~\ref{tab:dataset_params}.

\subsubsection{ARIMA Model}

The ARIMA (AutoRegressive Integrated Moving Average) model is a univariate time series forecasting method that captures autoregressive and moving average components with differencing for stationarity. The model order is determined through standard time series analysis procedures.

\subsubsection{VAR Model}

The Vector Autoregression (VAR) model extends ARIMA to multivariate settings, capturing dynamic relationships between multiple time series. The lag order is selected based on information criteria.

\subsubsection{Dynamic Factor Model (DFM)}

The Dynamic Factor Model (DFM) extracts common factors from many time series to reduce dimensionality and effectively handle mixed-frequency data \cite{stock2002forecasting}. The DFM is defined as:

\begin{align}
x_t &= C z_t + \varepsilon_t, \quad \varepsilon_t \sim \mathcal{N}(0, R) \\
z_t &= A z_{t-1} + \eta_t, \quad \eta_t \sim \mathcal{N}(0, Q)
\end{align}

where $x_t$ is the observed time series, $z_t$ is the common factor, $C$ is the factor loading matrix, and $A$ is the transition matrix. Parameters are estimated via the EM algorithm, and factors are estimated using Kalman filter and smoother.

\subsubsection{Deep Dynamic Factor Model (DDFM)}

The Deep Dynamic Factor Model (DDFM) uses an autoencoder-based architecture to learn complex factor structures \cite{andreini2020deep}. The nonlinear encoder enables learning of sophisticated factor relationships and is implemented using PyTorch Lightning.

\subsection{Mixed-Frequency Aggregation}

For handling mixed-frequency data, we use the tent kernel aggregation approach \cite{mariano2003new}. This method assigns greater weights to observations near the middle of the aggregation period, allowing effective combination of data at different frequencies.

\subsection{Evaluation Metrics}

Nowcasting performance is evaluated using standardized metrics to enable fair comparison across different series and scales. We report standardized Mean Squared Error (sMSE), standardized Mean Absolute Error (sMAE), and standardized Root Mean Squared Error (sRMSE), where standardization is performed using the standard deviation of the training data.

\subsection{Evaluation Design}

The evaluation uses a single-step forecast design, where each forecast horizon (1, 7, and 28 days) is evaluated using a single test point. This design choice limits statistical reliability but provides a focused assessment of model performance at each horizon. The train-test split uses 80\% of the data for training and 20\% for testing, which results in insufficient test data for evaluating 28-day forecasts for DFM and DDFM models (n\_valid = 0 for these combinations). This limitation is acknowledged in the results and conclusion sections.

