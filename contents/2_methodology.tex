\section{방법론}
\label{sec:methodology}

\subsection{실험 설계}
\label{subsec:experimental_design}

\subsubsection{실험 셋업}

\begin{itemize}
    \item \textbf{대상 변수:} KOEQUIPTE, KOWRCCNSE, KOIPALL.G (3개)
    \item \textbf{모형:} ARIMA, VAR, DFM, DDFM (4개)
    \item \textbf{평가:} 22개 예측 기간(1--22개월), 모형-대상 조합별 평균 계산
\end{itemize}

\input{tables/tab_dataset_params}

\subsubsection{데이터 전처리}

\begin{itemize}
    \item \textbf{주간-월간 집계:} 주간 변수(7--10개)는 월말 평균으로 집계하여 월간 데이터로 변환함. 집계된 변수는 \texttt{\_agg} 접미사를 붙여 구분함 (예: A001 $\to$ A001\_agg). 이를 통해 모든 변수가 월간 주기로 통일됨.
    \item \textbf{변환:} 시계열별 변환 유형('lin', 'log', 'chg' 등) 적용
    \item \textbf{결측치 처리:} forward-fill $\to$ backward-fill $\to$ naive forecaster 순차 적용
    \item \textbf{표준화:}
    \begin{itemize}
        \item ARIMA/VAR: 원본 스케일 유지
        \item DFM/DDFM: StandardScaler 적용 (평균 0, 표준편차 1)
    \end{itemize}
\end{itemize}

\subsubsection{데이터 품질 문제 및 시리즈 제거}

데이터 품질 개선을 위해 다음 시리즈를 제거:
\begin{itemize}
    \item 높은 상관관계(> 0.95) 시리즈
    \item 극단적 결측치(91.3\%) 시리즈 (pmiall, pmiout)
    \item 블록 구조 단일 글로벌 블록으로 단순화, 요인 수 3개 통일
\end{itemize}

\subsubsection{예측 모형}

\textbf{ARIMA:} 자기회귀 및 이동평균 성분 포착, 정상성을 위해 차분 사용, 단변량 시계열 예측. 차수 (1,1,1) 사용.

\textbf{VAR:} ARIMA를 다변량으로 확장, 여러 시계열 간 동적 관계 포착. 시차 1 사용. 장기 예측에서 수치적 불안정성 발생 가능.

\textbf{DFM:} 많은 시계열에서 공통 요인 추출, 차원 축소, 혼합주기 데이터 처리 \cite{stock2002forecasting, banbura2012nowcasting}. DFM은 state-space 형태로 표현되며, measurement equation과 transition equation으로 구성됨. EM 알고리즘으로 파라미터 추정, 칼만 필터와 스무더로 요인 추정 \cite{bok2019frbny}. 칼만 필터는 실시간 데이터 흐름을 재귀적으로 처리하여 각 시점의 예측을 업데이트하며, 데이터의 품질과 시의성을 기반으로 가중치를 부여함. 이는 nowcasting에 특히 유용한 특성으로, 비동기적 데이터 발표와 결측치를 자연스럽게 처리할 수 있음 \cite{banbura2012nowcasting}.

\textbf{DDFM:} 오토인코더 기반 아키텍처로 비선형 요인 관계 학습 \cite{andreini2020deep}. DDFM은 인코더를 통해 관측 변수에서 잠재 요인을 추출하고, 디코더를 통해 요인에서 관측 변수로 재구성함. 이 과정에서 선형 DFM의 제약을 완화하여 더 복잡한 요인 구조를 학습할 수 있음. 대규모 데이터셋에서도 효과적으로 작동하며, 전통적인 DFM의 계산적 한계를 극복함.

본 연구에서는 DDFM의 성능 개선을 위해 다음과 같은 개선 사항을 적용함:
\begin{itemize}
    \item \textbf{대상 변수별 인코더 아키텍처:} KOEQUIPTE 대상 변수에 대해서는 기본 인코더 구조([16, 4]) 대신 더 깊은 인코더 구조([64, 32, 16])를 자동으로 사용하도록 구현함. 이는 KOEQUIPTE에서 DDFM이 DFM과 동일한 성능(sMAE=1.14)을 보이는 문제를 해결하기 위한 것으로, 더 복잡한 비선형 관계를 포착하기 위한 용량을 제공함. 또한 더 깊은 인코더에 대해서는 훈련 에포크를 100에서 150으로 증가시켜 충분한 학습을 보장함. 이는 \texttt{src/train.py}에서 대상 변수별로 자동으로 적용되며, KOEQUIPTE에 대해서만 특별한 설정이 사용됨.
    \item \textbf{활성화 함수 선택:} KOEQUIPTE 대상 변수에 대해서는 기본 ReLU 활성화 함수 대신 tanh 활성화 함수를 자동으로 사용하도록 구현함. ReLU는 음의 값을 0으로 만드는 특성으로 인해 음의 상관관계를 포착하기 어려울 수 있음. 반면 tanh는 대칭적인 출력 범위(-1, 1)를 가지므로 음의 요인 부하(negative factor loadings)를 학습할 수 있어, KOEQUIPTE와 같은 시계열에서 음의 상관관계가 중요한 경우 더 적합함. 기본값은 ReLU이며, tanh는 KOEQUIPTE에 대해서만 자동으로 적용됨. 이는 \texttt{src/models/models\_forecasters.py}와 \texttt{dfm-python/src/dfm\_python/models/ddfm.py}에서 구현됨.
    \item \textbf{Huber 손실 함수 지원:} 기본 MSE 손실 함수 외에 Huber 손실 함수를 선택적으로 사용할 수 있도록 구현함. Huber 손실은 이상치(outlier)에 대해 더 강건하며, 변동성이 큰 시계열에서 예측 성능을 개선할 수 있음. Huber 손실의 전환점(transition point)은 \texttt{huber\_delta} 파라미터로 조정 가능하며, 기본값은 1.0임. 이는 \texttt{dfm-python/src/dfm\_python/models/ddfm.py}와 \texttt{src/models/models\_forecasters.py}에서 구현됨.
    \item \textbf{가중치 감쇠 (L2 정규화):} KOEQUIPTE 대상 변수에 대해서는 가중치 감쇠(weight decay, L2 정규화)를 자동으로 적용함(\texttt{weight\_decay=1e-4}). L2 정규화는 인코더가 선형 PCA와 유사한 해에 과적합되는 것을 방지하고, 다양한 비선형 특징을 학습하도록 장려함. 이는 인코더가 선형 변환에 가까운 가중치를 학습하여 DFM과 동일한 성능을 보이는 문제를 완화하기 위한 것으로, 모든 옵티마이저 인스턴스에 적용됨.
    \item \textbf{그래디언트 클리핑:} 훈련 안정성을 향상시키기 위해 그래디언트 클리핑을 지원함. \texttt{grad\_clip\_val} 파라미터로 클리핑 값을 조정할 수 있으며, 기본값은 1.0임. 그래디언트 폭발을 방지하여 NaN 값이나 선형 붕괴를 유발할 수 있는 훈련 불안정성을 완화함. 이는 pre-training, MCMC 훈련, 그리고 Lightning training step에 모두 적용됨.
    \item \textbf{향상된 가중치 초기화:} 인코더 레이어에 대해 활성화 함수에 따라 적절한 가중치 초기화 방법을 적용함. ReLU 활성화 함수의 경우 Kaiming 초기화를 사용하여 ReLU 네트워크에 최적화된 초기화를 제공함. tanh나 sigmoid와 같은 대칭 활성화 함수의 경우 Xavier 초기화를 사용하여 대칭 활성화 함수에 더 적합한 초기화를 제공함. 출력 레이어는 더 작은 초기화(gain=0.1)를 사용하여 초기 요인 값이 과도하게 크지 않도록 함. 이러한 개선은 특히 더 깊은 네트워크에서 훈련 안정성과 수렴 속도를 향상시킴.
    \item \textbf{요인 차수 설정:} 요인 동역학에 대한 VAR 차수를 설정할 수 있도록 \texttt{factor\_order} 파라미터를 추가함. 기본값은 1(VAR(1))이며, 2(VAR(2))로 설정할 수 있음. VAR(2)는 더 긴 기간의 의존성을 포착할 수 있으나 더 많은 데이터가 필요함. 일부 대상 변수는 복잡한 다기간 동역학을 가지므로 VAR(2)가 도움이 될 수 있음.
    \item \textbf{향상된 훈련 안정성:} 더 깊은 네트워크(레이어 수 > 2)에 대해서는 입력 클리핑 범위를 더 엄격하게 설정하여 극단값에 대한 민감도를 줄임. 또한 훈련 단계에서 수치적 안정성 처리를 개선하여 더 깊은 아키텍처에서의 훈련 안정성을 향상시킴.
    \item \textbf{증가된 사전 훈련:} KOEQUIPTE 대상 변수에 대해서는 사전 훈련 에포크 배수를 1에서 2로 증가시킴(\texttt{mult\_epoch\_pretrain=2}). 사전 훈련은 MCMC 훈련이 시작되기 전에 인코더가 비선형 특징을 학습하는 데 도움을 줌. 더 많은 사전 훈련 에포크는 인코더가 MCMC 반복 전에 비선형 특징을 학습할 시간을 더 제공하여, 인코더가 선형 동작으로 붕괴되는 것을 방지하는 데 도움이 됨.
    \item \textbf{배치 크기 최적화:} KOEQUIPTE 대상 변수에 대해서는 기본 배치 크기(100) 대신 더 작은 배치 크기(64)를 자동으로 사용하도록 구현함. 더 작은 배치 크기는 에포크당 더 다양한 그래디언트를 제공하여 인코더가 선형 PCA와 유사한 해에 수렴하는 것을 방지하고, 비선형 특징을 학습하도록 도울 수 있음.
    \item \textbf{향상된 훈련 설정:} 손실 함수, 활성화 함수, Huber delta, 가중치 감쇠, 그래디언트 클리핑, 요인 차수, 사전 훈련 배수, 배치 크기를 모델 파라미터를 통해 설정할 수 있으며, 대상 변수별 하이퍼파라미터 조정이 가능함. 또한 손실 함수, 활성화 함수, 아키텍처 선택에 대한 로깅을 강화하여 실험 추적성을 향상시킴.
    \item \textbf{DDFM 선형성 자동 감지:} 결과 집계 시 DDFM과 DFM의 성능 메트릭을 자동으로 비교하여 DDFM이 선형 관계만 학습하는지 감지하는 기능을 구현함. 선형성 점수가 0.95 이상인 경우 경고를 생성하고 개선 권장사항을 제공함.
    \item \textbf{DDFM 예측 품질 분석:} 결과 집계 시 DDFM의 시점별 성능 패턴, 불안정한 시점 식별, 예측 안정성 메트릭, 그리고 DFM 기준선과의 비교를 자동으로 수행하는 기능을 구현함. 향상된 진단 메트릭으로는 예측 안정성 메트릭(계수 of variation, CV), 단기 vs 장기 성능 분석(1-6개월 vs 13-22개월), 일관성 메트릭(시점 간 개선의 일관성), 최고/최악 시점 식별(개선 비율 기준), 선형 붕괴 위험 평가, 시점별 성능 저하 감지 등이 포함됨. 각 대상 변수에 대한 구체적인 개선 권장사항을 생성하여 DDFM의 성능 특성을 체계적으로 분석함. 이러한 개선 사항의 효과를 검증하기 위해서는 추가 실험 재실행이 필요함.
    \item \textbf{향상된 오차 분포 메트릭:} DDFM의 예측 오차 분포를 더 자세히 분석하기 위해 각 시점별로 오차 분포 분석 메트릭을 계산함. 이러한 메트릭들은 \texttt{src/evaluation/evaluation_metrics.py}의 \texttt{calculate\_standardized\_metrics()} 함수에서 계산되며, 오차 왜도(비대칭성), 오차 첨도(꼬리 두께), 오차 편향 제곱(체계적 편향), 오차 분산(예측 불안정성), 오차 집중도(오차 분포 균등성)를 포함함. 이러한 메트릭들을 통해 예측 오차의 원인을 더 정확히 파악하고, 편향과 분산 중 어느 쪽을 개선해야 하는지 결정할 수 있음.
    \item \textbf{시점 간 오차 상관관계 분석:} DDFM의 오차 패턴이 시점 간에 어떻게 상관관계를 가지는지 분석하는 기능을 구현함. \texttt{analyze\_horizon\_error\_correlation()} 함수는 서로 다른 예측 시점 간의 오차 유사성을 계산하여 체계적 문제(예: 선형 붕괴)와 시점별 문제를 구분함. 체계적 패턴 점수(0-1)를 통해 인코더 아키텍처 문제(체계적)와 시점별 튜닝 필요성(시점별)을 구분하며, 각 대상 변수에 대한 구체적인 개선 권장사항을 제공함.
    \item \textbf{시점 가중 메트릭:} 실용적 예측 관점에서 단기 예측이 장기 예측보다 중요하다는 점을 반영하여 시점별 가중 평균 메트릭을 계산하는 기능을 구현함. \texttt{calculate\_horizon\_weighted\_metrics()} 함수는 시점을 단기(1-6개월, 가중치 2.0), 중기(7-12개월, 가중치 1.0), 장기(13-22개월, 가중치 0.5)로 분류하여 가중 평균을 계산함. 이를 통해 단기 예측 성능을 더 강조한 평가가 가능하며, DDFM 예측 품질 분석에 통합되어 시점별 가중 개선 비율을 제공함. 이 메트릭은 실용적 예측 관점에서 모델 성능을 평가하는 데 유용함.
    \item \textbf{훈련 정렬 메트릭:} 모델이 훈련 중 최적화한 손실 함수와 일치하는 평가 메트릭을 계산하는 기능을 구현함. \texttt{calculate\_training\_aligned\_metrics()} 함수는 모델이 MSE 손실로 훈련되었으면 MSE 기반 메트릭을, Huber 손실로 훈련되었으면 Huber 기반 메트릭을 계산함. 이를 통해 평가 메트릭이 훈련 목표와 일치하도록 보장하여, 모델이 실제로 최적화한 목표에 대한 성능을 정확히 측정할 수 있음. 이 메트릭은 Huber 손실을 사용한 모델의 경우 특히 유용하며, 이상치에 대한 강건성을 평가하는 데 도움을 줌.
    \item \textbf{상관관계 구조 분석 (Phase 0):} 모델 훈련 전에 수행 가능한 사전 분석 기능을 구현함. \texttt{analyze\_correlation\_structure()} 함수는 대상 변수와 모든 입력 시계열 간의 상관관계 패턴을 분석하여 DDFM의 선형적 특성을 이해하는 데 도움을 줌. 주요 분석 지표는 음의 상관관계 비율, 강한 음의 상관관계 개수(절댓값 > 0.3), 평균 상관관계, 상관관계 분포 등임. 이 분석은 활성화 함수 선택(tanh vs ReLU) 및 인코더 아키텍처 결정에 대한 가설을 수립하는 데 활용되며, 모델 훈련 없이도 수행 가능함. 분석 결과는 JSON 형식으로 저장되며, 세 대상 변수 간 비교를 통해 구조적 차이를 식별할 수 있음.
    \item \textbf{상대 오차 안정성 메트릭:} DDFM과 DFM 간의 상대적 성능이 시점에 따라 어떻게 변화하는지 분석하는 기능을 구현함. \texttt{calculate\_relative\_error\_stability()} 함수는 안정성 점수(0-1), 변동 계수(CV), 그리고 추세 분석(개선/저하/안정)을 계산하여 DDFM의 상대적 성능이 일관적인지 평가함. 이 메트릭은 \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합되어 자동으로 분석됨.
    \item \textbf{개선 지속성 메트릭:} DDFM의 개선이 지속적인(일관된) 개선인지, 아니면 일시적인(노이즈) 개선인지 감지하는 기능을 구현함. \texttt{calculate\_improvement\_persistence()} 함수는 지속성 점수(0-1), 개선 비율, 연속 개선 구간, 그리고 개선 클러스터를 계산하여 DDFM이 DFM 대비 체계적으로 개선되는지 평가함. 이 메트릭은 \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합되어 자동으로 분석됨.
    \item \textbf{시간적 일관성 메트릭:} 연속된 시점 간 예측값의 급격한 변화(점프)를 감지하는 기능을 구현함. \texttt{calculate\_temporal\_consistency\_metrics()} 함수는 시간적 일관성 점수(0-1), 점프 개수, 점프 비율, 그리고 점프 크기를 계산하여 모델의 예측이 시간적으로 일관적인지 평가함. 이 메트릭은 평가 파이프라인에서 사용 가능하며, 필요에 따라 분석 함수에 통합할 수 있음.
    \item \textbf{강건 통계 기반 메트릭:} 평균 기반 메트릭은 이상치(outlier)에 민감하므로, 중앙값(median)과 사분위수 범위(IQR)를 사용한 강건한 대안 메트릭을 추가함. \texttt{calculate\_robust\_metrics()} 함수는 중앙값 기반의 sMAE, sMSE, sRMSE를 계산하며, IQR 기반 메트릭과 이상치 비율을 제공함. 이는 특정 시점에서의 수치적 불안정성이나 극단적 오차로 인한 왜곡을 줄이며, DDFM 성능 평가의 신뢰성을 향상시킴. 특히 일부 시점에서 극단적 오차가 발생하는 경우 평균 기반 메트릭이 왜곡될 수 있으므로, 강건 통계는 더 신뢰할 수 있는 성능 평가를 제공함.
    \item \textbf{부트스트랩 신뢰구간:} 부트스트랩 재표본 추출을 통해 메트릭의 불확실성을 정량화하는 신뢰구간을 계산하는 기능을 구현함. \texttt{calculate\_bootstrap\_confidence\_intervals()} 함수는 기본적으로 1000회 재표본 추출을 수행하여 95\% 신뢰구간을 제공함. 이를 통해 DDFM 성능 평가의 통계적 신뢰성을 향상시키고, 메트릭 간 비교 시 불확실성을 고려할 수 있음. 이는 특히 표본 크기가 작거나 특정 시점에서의 오차 변동성이 큰 경우 유용하며, DDFM과 DFM 간의 성능 차이를 통계적으로 검증하는 데 도움을 줌.
    \item \textbf{강건한 시점별 집계:} 여러 시점에 걸친 메트릭 집계 시 평균 대신 중앙값을 사용하는 옵션을 제공함. \texttt{aggregate\_robust\_metrics\_across\_horizons()} 함수는 중앙값 기반 집계와 IQR 통계를 제공하여, 특정 문제가 있는 시점의 극단적 오차가 전체 성능 평가를 왜곡하는 것을 방지함. 이는 DDFM 성능 평가의 신뢰성을 향상시키며, 특히 일부 시점에서 수치적 불안정성이 발생하는 경우 유용함.
    \item \textbf{요인 동역학 안정성 추론:} VAR 요인 동역학의 안정성을 예측 패턴으로부터 추론하는 기능을 구현함. \texttt{calculate\_factor\_dynamics\_stability()} 함수는 시점별 예측값을 분석하여 요인 동역학의 안정성을 평가함. 이 함수는 다음을 감지함:
    \begin{itemize}
        \item \textbf{진동(oscillation):} 예측값이 고저를 반복하는 패턴을 감지하여 VAR 전이 행렬의 복소 고유값으로 인한 진동 행동을 식별함.
        \item \textbf{지수적 성장/감쇠:} 예측값의 지수적 증가 또는 감소를 감지하여 VAR 전이 행렬의 고유값이 단위원 밖에 있어 불안정한 경우를 식별함.
        \item \textbf{예측 평활도:} 2차 도함수의 분산을 계산하여 예측값의 평활도를 측정함. 낮은 평활도는 요인 동역학의 불안정성을 시사함.
        \item \textbf{발산/수렴:} 예측값이 시점에 따라 발산하거나 수렴하는 패턴을 감지하여 요인 동역학의 수치적 불안정성을 식별함.
    \end{itemize}
    이 메트릭은 VAR 전이 행렬에 직접 접근할 수 없는 평가 파이프라인에서도 요인 동역학의 안정성을 간접적으로 평가할 수 있게 해주며, DDFM의 수치적 불안정성 문제를 조기에 감지하는 데 도움을 줌.
    \item \textbf{예측 기술 점수 (Forecast Skill Score):} DDFM의 성능을 단순 기준선(naive baseline)과 비교하여 정량화하는 기능을 구현함. \texttt{calculate\_forecast\_skill\_score()} 함수는 무작위 보행(random walk/persistence) 또는 평균 예측(mean forecast) 기준선 대비 DDFM의 개선 정도를 측정함. 기술 점수는 -inf에서 1.0 범위의 값을 가지며, 1.0은 완벽한 예측, 0.0은 기준선과 동일, 음수는 기준선보다 나쁨을 의미함. MSE, MAE, RMSE에 대해 각각 기술 점수를 계산하며, 기준선 대비 개선 비율을 백분율로 제공함. 이를 통해 DDFM 성능을 더 해석 가능한 방식으로 평가할 수 있으며, 단순 기준선 대비 예측 개선 정도를 정량화함.
    \item \textbf{정보 획득 메트릭 (Information Gain):} DDFM이 DFM 대비 제공하는 추가 정보의 양을 측정하는 기능을 구현함. \texttt{calculate\_information\_gain()} 함수는 두 가지 방법을 사용함:
    \begin{itemize}
        \item \textbf{KL 발산 방법:} DDFM과 DFM의 오차 분포 간 KL 발산을 계산하여 두 모형의 오차 패턴 차이를 정량화함.
        \item \textbf{상호 정보량 방법:} 예측값과 실제값 간의 상호 정보량을 계산하여 DDFM이 DFM 대비 얼마나 많은 정보를 제공하는지 측정함.
    \end{itemize}
    정보 획득 메트릭은 DDFM 인코더가 학습한 비선형 특징의 가치를 정량화하며, DDFM이 DFM과 다른 패턴을 학습하고 있는지 식별하는 데 도움을 줌. 높은 정보 획득 값은 DDFM이 DFM 대비 더 많은 정보를 제공하며 비선형 특징을 효과적으로 학습하고 있음을 시사함.
    \item \textbf{향상된 시점별 개선 추적:} DDFM의 시점별 개선 정도를 분류하여 추적하는 기능을 구현함. \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합된 시점 분류 기능은 각 시점을 개선 수준에 따라 분류함: 유의미한 개선(>10\%), 중간 개선(5-10\%), 경미한 개선(0-5\%), 개선 없음, 성능 저하. 각 카테고리별 비율과 개수를 계산하여 DDFM이 어떤 시점에서 가장 큰 이점을 제공하는지 파악할 수 있음. 이를 통해 DDFM 개선 전략을 시점별로 최적화할 수 있으며, 각 대상 변수에 대한 구체적인 개선 권장사항을 생성함.
    \item \textbf{비선형성 점수:} DDFM 예측이 얼마나 비선형적인지를 정량화하는 메트릭을 추가함. \texttt{calculate\_nonlinearity\_score()} 함수는 패턴 발산도, 오차 비선형성, 시점 상호작용 효과를 종합하여 비선형성 점수(0-1, 높을수록 비선형)를 계산함. 이 메트릭은 선형성 감지의 보완적 메트릭으로, DDFM이 DFM과 다른 비선형 패턴을 학습하고 있는지 긍정적으로 측정함. 점수 < 0.2는 선형 붕괴 가능성을, 점수 > 0.7은 높은 비선형성을 의미함.
    \item \textbf{분위수 기반 오차 메트릭:} 평균 기반 메트릭이 이상치에 민감한 문제를 해결하기 위해 분위수 기반 강건 메트릭을 추가함. \texttt{calculate\_quantile\_based\_metrics()} 함수는 여러 분위수(0.1, 0.25, 0.5, 0.75, 0.9)에서 sMAE와 sMSE를 계산하며, IQR sMAE와 꼬리 비율을 제공함. 이 메트릭은 변동성이 큰 시점이나 왜도가 있는 오차 분포에서 더 신뢰할 수 있는 성능 평가를 제공함.
    \item \textbf{요인 부하 비교:} DFM과 DDFM이 학습한 요인 부하를 비교하여 선형 붕괴를 감지하는 기능을 추가함. \texttt{compare\_factor\_loadings()} 함수는 두 모형의 요인 부하 간 유사성을 계산하며, 높은 유사성은 DDFM 인코더가 선형 특징만 학습하고 있음을 시사함. 이 메트릭은 모델 내부에 접근할 수 있을 때 사용 가능하며, 선형 붕괴 위험 평가에 활용됨.
    \item \textbf{상대적 기술 평가 (Relative Skill Assessment):} 실제 예측값이 없는 경우에도 오차 메트릭을 사용하여 기술 점수와 유사한 평가를 제공하는 기능을 추가함. \texttt{calculate\_relative\_skill\_assessment()} 함수는 DDFM의 성능을 DFM 및 기준 모형(VAR)과 비교하여 기술 점수와 유사한 평가를 제공함. 이 메트릭은 DDFM vs DFM, DDFM vs VAR의 개선 정도를 백분율로 계산하며, 기술 일관성(시점 간 기술 점수의 일관성)과 시점별 기술 평가를 제공함. 기술 수준은 HIGH(>10\% 개선), MODERATE(5-10\% 개선), LOW(유사), NEGATIVE(저하)로 분류되며, DDFM의 상대적 성능을 더 해석하기 쉽게 평가할 수 있게 함. 이 메트릭은 \texttt{forecast\_skill\_score()}를 보완하여, 예측값이 \texttt{aggregated\_results.csv}에 저장되지 않은 경우에도 오차 메트릭을 사용하여 기술 점수와 유사한 평가를 제공함.
    \item \textbf{근선형 붕괴 감지 (Near-Linear Collapse Detection):} DDFM과 DFM의 오차가 수치적 정밀도 범위 내(< 0.01 절대 차이, < 0.1\% 상대 차이)에 있는 경우를 특별히 감지하는 기능을 추가함. \texttt{calculate\_near\_linear\_collapse\_detection()} 함수는 선형성 감지보다 더 강한 신호를 제공하며, KOEQUIPTE와 같이 모든 시점에서 DDFM과 DFM의 오차가 거의 동일한 경우를 조기에 감지함. 이 메트릭은 절대 차이 분석, 상대 차이 분석, 근붕괴 비율(근붕괴를 보이는 시점의 비율), 근붕괴 점수(0-1, 높을수록 근붕괴 가능성)를 계산하며, 시점별 근붕괴 감지를 제공함. 이 메트릭은 유사성 메트릭만으로는 감지하기 어려운 수치적 정밀도 수준의 선형 붕괴를 조기에 발견하는 데 도움을 줌.
    \item \textbf{오차 패턴 평활도 (Error Pattern Smoothness):} DDFM의 오차 패턴이 시점 간에 얼마나 일관적이고 평활한지를 측정하는 메트릭을 추가함. \texttt{calculate\_error\_pattern\_smoothness()} 함수는 변동 계수(CV), 1차 차분, 2차 차분, 자기상관을 사용하여 오차 패턴의 평활도를 계산함. 평활도 점수(0-1, 높을수록 평활)는 인코더가 잘 학습된 경우 비선형 특징이 시점 간 일관된 성능을 제공하므로 더 평활한 오차 패턴을 보일 것으로 기대됨. 이 메트릭은 DDFM의 예측 안정성을 평가하고, 시점별 변동성이 큰 문제를 식별하는 데 도움을 줌.
    \item \textbf{개선 통계적 유의성 검정 (Improvement Significance Testing):} DDFM의 개선이 통계적으로 유의한지를 부트스트랩 재표본 추출을 통해 검정하는 기능을 추가함. \texttt{calculate\_improvement\_significance()} 함수는 기본적으로 1000회 부트스트랩 재표본 추출을 수행하여 개선 비율의 신뢰구간을 계산하고, 개선이 통계적으로 유의한지(신뢰구간이 0을 포함하지 않음)를 판단함. 이 메트릭은 p-value, 유의한 시점 목록, 시점별 유의성 분석을 제공하여 DDFM 개선이 실제 개선인지 랜덤 변동인지 구분하는 데 도움을 줌.
    \item \textbf{대상 변수 간 패턴 비교 (Cross-Target Pattern Comparison):} 세 대상 변수 간의 DDFM 성능 패턴을 비교하여 공통 패턴과 이상치를 식별하는 기능을 추가함. \texttt{calculate\_cross\_target\_pattern\_comparison()} 함수는 대상 변수 간 개선 비율, 일관성, 선형 붕괴 위험을 비교하여 어떤 대상 변수가 다른 패턴을 보이는지 식별함. 이를 통해 KOEQUIPTE와 같이 선형 붕괴를 보이는 대상 변수를 조기에 발견하고, 다른 대상 변수에서 성공한 전략을 적용할 수 있음.
    \item \textbf{체계적 편향 감지 (Systematic Bias Detection):} DDFM이 DFM보다 일관되게 나쁜 성능을 보이는 경우를 감지하는 메트릭을 추가함. \texttt{analyze\_ddfm\_prediction\_quality()} 함수는 다음 세 가지 메트릭을 계산함:
    \begin{itemize}
        \item \textbf{체계적 편향 점수 (systematic\_bias\_score):} 0-1 범위의 점수로, 높을수록 DDFM이 DFM보다 일관되게 나쁨을 의미함. DDFM이 더 나쁜 시점의 비율이 50\% 이상이거나, 근선형 붕괴 비율이 80\% 이상인 경우 높은 점수를 받음.
        \item \textbf{근선형 붕괴 비율 (near\_linear\_fraction):} 근선형 붕괴를 보이는 시점의 비율. 이 비율이 높으면 DDFM 인코더가 선형 특징만 학습하고 있음을 시사함.
        \item \textbf{DDFM 저하 비율 (ddfm\_worse\_fraction):} DDFM이 DFM보다 나쁜 성능을 보이는 시점의 비율. 이 비율이 높으면 DDFM이 체계적으로 DFM보다 나쁨을 의미함.
    \end{itemize}
    이러한 메트릭들은 KOEQUIPTE와 같이 DDFM이 DFM과 거의 동일한 성능을 보이는 경우를 정량적으로 진단하는 데 도움을 줌.
    \item \textbf{오차 자기상관 분석 (Error Autocorrelation Analysis):} 연속된 시점 간 오차의 상관관계를 분석하여 체계적 편향 패턴을 감지하는 메트릭을 추가함. \texttt{calculate\_error\_autocorrelation\_analysis()} 함수는 여러 시차(lag)에 대해 DDFM과 DFM의 오차 자기상관을 계산함. 높은 자기상관(> 0.5)은 오차가 시점 간에 지속되는 체계적 편향을 나타내며, 낮은 자기상관(< 0.2)은 오차가 상대적으로 독립적임을 의미함. 이 메트릭은 DDFM 인코더가 학습한 패턴이 시점 간에 체계적으로 지속되는지, 아니면 더 랜덤한 오차를 생성하는지를 구분하는 데 도움을 줌. DDFM이 DFM보다 높은 자기상관을 보이면 인코더가 체계적 패턴을 학습하고 있음을 시사하며, 이는 선형 붕괴의 조기 신호일 수 있음.
    \item \textbf{개선 안정성 메트릭 (Improvement Stability Metrics):} DDFM 개선이 시점 간에 얼마나 일관적인지를 측정하는 메트릭을 추가함. \texttt{calculate\_improvement\_stability()} 함수는 개선 비율의 분산, 변동 계수, 범위, 사분위수 범위를 계산하여 개선의 안정성을 평가함. 높은 안정성 점수(> 0.8)는 시점 간 일관된 개선을 의미하며, 낮은 안정성(< 0.4)은 개선이 시점별로 크게 다름을 나타냄. 이 메트릭은 DDFM 인코더가 일반화 가능한 특징을 학습했는지(일관된 개선), 아니면 특정 시점에 과적합했는지(변동적인 개선)를 구분하는 데 도움을 줌. 또한 양수 개선과 음수 개선의 개수를 추적하여 DDFM이 일관되게 개선하는지, 아니면 일부 시점에서 성능이 저하되는지를 정량화함.
\end{itemize}

\subsubsection{Forecasting과 Nowcasting}

\textbf{Forecasting:} 과거 데이터로 미래 값 예측. 각 모형 훈련 후 1--22개월에 대해 예측 생성.

\textbf{재귀적 예측 (ARIMA, VAR):} ARIMA와 VAR은 재귀적(recursive) 방식으로 다단계 예측을 수행함. 1-step ahead 예측값을 다음 단계의 입력으로 사용하여 순차적으로 예측을 생성하므로, 예측 오차가 누적되어 장기 예측에서 불안정성이 증가함.

\textbf{상태 업데이트 예측 (DFM, DDFM):} DFM과 DDFM은 state-space 구조를 활용하여 잠재 요인 상태를 업데이트한 후 직접 다단계 예측을 생성함 \cite{bok2019frbny}. 칼만 필터가 데이터를 재귀적으로 처리하여 예측을 업데이트하되, 각 예측 시점에서 요인의 품질과 시의성에 기반한 가중치를 부여하므로 오차 누적이 완화됨 \cite{banbura2012nowcasting}. 이러한 구조적 특성으로 인해 DFM/DDFM은 장기 예측에서 더 안정적인 성능을 보일 수 있음.

\textbf{Nowcasting:} 공식 통계 발표 전 현재 시점 거시경제 변수 추정 \cite{banbura2012nowcasting}. 각 목표 월에 대해 4주 전, 1주 전 시점에서 예측을 수행하며, 시리즈별 발표 시차(publication lag)를 기준으로 미발표 데이터를 마스킹함.
