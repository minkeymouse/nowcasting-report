\section{이론적 배경}

\subsection{동적 요인 모형의 이론적 기초}

\subsubsection{동적 요인 모형의 기본 구조}
동적 요인 모형(Dynamic Factor Model, DFM)은 상태 공간 모형(state-space model)의 특수한 형태로, 관측된 많은 시계열 변수들이 소수의 공통 요인에 의해 설명된다는 가정에 기반함.
\begin{itemize}
    \item 관측 방정식(observation equation): $X_t = C Z_t + \epsilon_t$
    \begin{itemize}
        \item $X_t$는 $N \times 1$ 벡터로, $N$개의 관측 시계열 변수를 나타냄
        \item $Z_t$는 $m \times 1$ 벡터로, $m$개의 공통 요인을 나타냄 (일반적으로 $m << N$)
        \item $C$는 $N \times m$ 행렬로, 요인 부하(factor loadings)를 나타냄
        \item $\epsilon_t$는 $N \times 1$ 벡터로, 각 시계열의 고유 오차(idiosyncratic error)를 나타냄
    \end{itemize}
    \item 상태 방정식(state equation): $Z_t = A Z_{t-1} + \eta_t$
    \begin{itemize}
        \item $A$는 $m \times m$ 행렬로, 요인의 동학(dynamics)을 나타냄
        \item $\eta_t$는 $m \times 1$ 벡터로, 요인의 혁신(innovation)을 나타냄
        \item 일반적으로 $A$는 AR(1) 또는 AR(2) 과정을 따름
    \end{itemize}
    \item 오차 항은 정규분포를 따르며, 서로 독립적이라고 가정함:
    \begin{itemize}
        \item $\epsilon_t \sim N(0, R)$: 관측 오차의 공분산 행렬
        \item $\eta_t \sim N(0, Q)$: 요인 혁신의 공분산 행렬
    \end{itemize}
\end{itemize}

\subsubsection{요인 추출 방법}
DFM에서 요인을 추출하는 방법은 크게 두 가지로 구분됨:
\begin{itemize}
    \item \textbf{주성분 분석(Principal Component Analysis)}: Stock과 Watson (2002)이 제안한 방법으로, 관측 시계열의 공분산 행렬의 고유벡터를 사용하여 요인을 추출함 \cite{stock2002forecasting}
    \begin{itemize}
        \item 이 방법은 계산이 효율적이며, 대규모 데이터셋에 적용하기 용이함
        \item 요인의 개수는 고유값의 크기나 정보 기준(information criterion)을 통해 결정됨
    \end{itemize}
    \item \textbf{최우추정법(Maximum Likelihood Estimation)}: 관측 방정식과 상태 방정식의 파라미터를 동시에 추정하는 방법임
    \begin{itemize}
        \item Expectation-Maximization (EM) 알고리즘을 통해 파라미터를 추정함
        \item Kalman 필터와 Kalman 스무더를 사용하여 요인을 추정함
        \item 이 방법은 주성분 분석보다 계산 비용이 크지만, 더 정확한 추정을 제공할 수 있음
    \end{itemize}
\end{itemize}

\subsubsection{Kalman 필터와 스무더}
DFM에서 요인을 추정하기 위해 Kalman 필터와 스무더가 사용됨.
\begin{itemize}
    \item \textbf{Kalman 필터}: 과거 정보를 사용하여 현재 시점의 요인을 추정함
    \begin{itemize}
        \item 예측 단계(prediction step): $Z_{t|t-1} = A Z_{t-1|t-1}$, $P_{t|t-1} = A P_{t-1|t-1} A' + Q$
        \item 업데이트 단계(update step): $Z_{t|t} = Z_{t|t-1} + K_t (X_t - C Z_{t|t-1})$, $P_{t|t} = (I - K_t C) P_{t|t-1}$
        \item 여기서 $K_t$는 Kalman gain으로, $K_t = P_{t|t-1} C' (C P_{t|t-1} C' + R)^{-1}$
    \end{itemize}
    \item \textbf{Kalman 스무더}: 전체 시계열 정보를 사용하여 각 시점의 요인을 재추정함
    \begin{itemize}
        \item 스무더는 필터보다 더 정확한 추정을 제공하며, 특히 중간 시점의 요인 추정에 유용함
        \item Fixed-interval smoother (FIS)를 사용하여 전체 시계열에 대한 요인을 추정함
    \end{itemize}
\end{itemize}

\subsection{혼합 빈도 데이터 처리}

혼합 빈도(mixed-frequency) 데이터 처리는 거시경제 예측에서 핵심적인 과제임. 서로 다른 빈도의 데이터를 효과적으로 통합하기 위한 여러 방법론이 제안되어 왔음.

\subsubsection{MIDAS (Mixed Data Sampling)}
MIDAS는 Ghysels 등 (2004)에 의해 제안된 방법으로, 고빈도 데이터를 직접적으로 저빈도 예측에 활용할 수 있도록 설계된 회귀 모형임 \cite{ghysels2004midas}.
\begin{itemize}
    \item MIDAS는 고빈도 설명 변수를 저빈도 종속 변수에 직접 연결하는 방법으로, 분기별 GDP를 월간 또는 주간 지표로부터 예측하는 데 널리 활용됨
    \item MIDAS의 핵심은 고빈도 데이터에 대한 분산 가중치(distributed lag weights)를 사용하여 저빈도 예측을 생성하는 것임
    \item 이 방법은 DFM과 달리 요인 추출 없이 직접적으로 고빈도 데이터를 활용할 수 있다는 장점이 있음
\end{itemize}

\subsubsection{Clock 기반 프레임워크}
dfm-python 패키지는 clock 기반 프레임워크를 사용하여 혼합 빈도 데이터를 처리함.
\begin{itemize}
    \item 모든 잠재 요인(global factor와 block-level factor)이 공통의 "clock" 빈도에서 진화하도록 동기화함
    \item Clock 빈도는 일간('d'), 주간('w'), 월간('m'), 분기별('q'), 반기별('sa'), 연간('a') 중에서 선택 가능함
    \item 본 연구에서는 clock 빈도를 월간('m')으로 설정하여 모든 잠재 요인이 월간 빈도에서 진화하도록 함
    \item 이는 분기별 목표 변수를 월간 고빈도 지표로부터 예측하기 위한 설정임
\end{itemize}

\subsubsection{텐트 커널 집계}
저빈도 시계열(예: 분기별 GDP)을 고빈도 요인(예: 월간 요인)으로부터 생성하기 위해 텐트 커널(tent kernel) 집계 방식을 사용함. 텐트 커널은 Mariano와 Murasawa (2003)에 의해 제안된 방법으로, 혼합 빈도 데이터를 효과적으로 처리하기 위한 핵심 기법임 \cite{mariano2003new}. 이 방법은 FRBNY Staff Nowcast에서도 핵심적으로 사용되며, Bańbura 등 (2012)과 Bok 등 (2017, 2019)의 연구에서 활용됨 \cite{bok2017macroeconomic}.
\begin{itemize}
    \item \textbf{텐트 커널의 기원}: Mariano와 Murasawa (2003)는 혼합 빈도 시계열 모형에서 저빈도 변수를 고빈도 잠재 상태로 매핑하기 위한 결정론적 방법으로 텐트 커널을 제안함. 이 방법은 분기 내 각 월의 기여도를 시간 가중치로 부여하여, 분기의 중간 시점이 더 큰 가중치를 갖도록 함
    \item \textbf{수학적 정의}: 분기 $q$에 해당하는 월간 시점들의 집합을 $S_q = \{m_1, m_2, m_3\}$라고 하면, 각 월의 가중치는 다음과 같이 계산됨:
    \begin{equation}
    w_{m_i} = \begin{cases}
    \frac{i - 1}{2} & \text{if } i = 1, 2 \\
    1 - \frac{i - 2}{2} & \text{if } i = 2, 3
    \end{cases}
    \end{equation}
    \item 이러한 가중치는 분기의 첫 번째 월과 세 번째 월에는 작은 가중치를, 두 번째 월(중간 월)에는 큰 가중치를 부여함
    \item \textbf{텐트 커널을 사용하는 이유}:
    \begin{itemize}
        \item \textbf{분기 중간 시점의 대표성}: 분기의 중간 시점이 전체 분기 값을 더 잘 대표한다는 경제적 직관에 기반함. 분기 초반과 후반의 변동성이 중간 시점에 집중되어 있다고 가정함. 이는 분기별 집계 변수의 시간적 분포 특성을 반영함
        \item \textbf{균등 가중치의 한계}: 균등 가중치를 사용할 경우, 분기 내 각 월이 동일한 기여를 한다고 가정하나, 실제로는 분기 중간 시점의 정보가 더 중요할 수 있음. 또한 분기 초반과 후반의 정보 손실이 발생할 수 있음
        \item \textbf{최근 가중치의 한계}: 최근 가중치를 사용할 경우, 분기 후반의 정보만 강조되어 분기 전체의 정보를 충분히 활용하지 못함. 이는 분기 초반과 중반의 정보를 소홀히 하게 됨
        \item \textbf{실증적 활용}: 텐트 커널은 FRBNY Staff Nowcast에서 핵심 기법으로 사용되며, Bańbura 등 (2012)과 Bok 등 (2017, 2019)의 연구에서 활용됨 \cite{banbura2012nowcasting, bok2017macroeconomic, bok2019frbny}
    \end{itemize}
    \item \textbf{텐트 커널의 수학적 특성}:
    \begin{itemize}
        \item 가중치의 합은 1이 되도록 정규화되어, 분기별 값의 스케일을 보존함
        \item 가중치 함수는 대칭적이며, 분기 중간에서 최대값을 가짐
        \item 이러한 특성은 분기별 집계 변수의 시간적 분포를 더 정확하게 반영함
    \end{itemize}
    \item 텐트 커널은 FRBNY Staff Nowcast의 핵심 구성 요소로, 혼합 빈도 동적 요인 모형에서 저빈도 목표 변수를 고빈도 지표로부터 예측하는 데 필수적임
\end{itemize}

\subsection{심층 동적 요인 모형의 이론적 기초}

\subsubsection{자기인코더를 활용한 비선형 요인 추출}
DDFM은 자기인코더(autoencoder) 신경망 구조를 활용하여 잠재 상태를 생성하고 비선형 요인 구조를 학습함 \cite{andreini2020deep}.
\begin{itemize}
    \item \textbf{인코더(Encoder)}: 관측 시계열 $X_t$를 잠재 요인 $Z_t$로 매핑하는 비선형 함수 $f_{\text{encoder}}(X_t; \theta_e)$
    \begin{itemize}
        \item 인코더는 다층 퍼셉트론(MLP)으로 구현되며, 관측 시계열을 잠재 공간으로 변환함
        \item 비선형 활성 함수(ReLU, tanh 등)를 통해 비선형 관계를 포착함
        \item 자기인코더를 통해 동적 상태 공간 모형의 잠재 상태를 생성함
    \end{itemize}
    \item \textbf{디코더(Decoder)}: 잠재 요인 $Z_t$를 관측 시계열 $X_t$로 재구성하는 함수 $f_{\text{decoder}}(Z_t; \theta_d)$
    \begin{itemize}
        \item 디코더는 선형 변환으로 구현되며, 해석 가능성을 유지함
        \item 디코더 파라미터는 관측 행렬을 직접 추출하는 데 사용됨
    \end{itemize}
    \item \textbf{요인 동학}: 학습된 요인은 DFM과 동일하게 AR(1) 과정을 따름
    \begin{itemize}
        \item $Z_t = A Z_{t-1} + \eta_t$ (AR(1)의 경우)
        \item $A$는 OLS를 통해 추정되며, Kalman 필터를 통해 최종 요인을 추정함
    \end{itemize}
\end{itemize}

\subsubsection{학습 목적 함수}
DDFM은 다음과 같은 재구성 오차를 최소화하여 학습됨:
\begin{equation}
\mathcal{L}(\theta_e, \theta_d) = \sum_{t=1}^T ||X_t - f_{\text{decoder}}(f_{\text{encoder}}(X_t; \theta_e); \theta_d)||^2
\end{equation}
\begin{itemize}
    \item 재구성 오차(reconstruction error)를 최소화함으로써 관측 시계열을 정확하게 재구성하도록 학습함
    \item 자기인코더는 PCA의 비선형 일반화로, 선형 인코더와 디코더를 사용하면 PCA와 동치임
    \item 비선형 활성 함수를 추가하면 비선형 관계를 포착할 수 있음
    \item 자기인코더를 통해 동적 상태 공간 모형의 잠재 상태를 생성할 수 있음
\end{itemize}

\subsubsection{고유 오차 모델링}
DDFM은 고유 오차(idiosyncratic error)를 모델링하여 더 정확한 예측을 제공할 수 있는 잠재력을 보유함.
\begin{itemize}
    \item 고유 오차는 각 시계열의 요인으로 설명되지 않는 부분을 나타냄
    \item DDFM은 특이 성분(idiosyncratic component)에 AR(d) 동학을 부여하여 시간적 의존성을 포착함. 일반적으로 AR(1)이 사용되며, 대각 행렬의 자기회귀 계수를 가진다
    \item 이는 전체 상태 벡터에 요인과 고유 오차를 모두 포함시켜 Kalman 필터를 통해 추정함
\end{itemize}

\subsection{Nowcasting의 이론적 기초}

\subsubsection{출시 시차를 고려한 모델링}
Nowcasting은 각 시점에서 사용 가능한 데이터만을 활용하여 목표 변수를 예측함.
\begin{itemize}
    \item 각 변수는 서로 다른 출시 시차(release lag)를 가지며, 이는 데이터가 실제로 발생한 시점과 공식적으로 발표되는 시점 사이의 시간 차이임
    \item 예를 들어, 분기별 GDP는 해당 분기가 종료된 후 약 25일이 지나야 공식 발표됨
    \item 반면, 월간 생산지수는 해당 월이 종료된 후 약 30일이 지나면 발표됨
    \item Nowcasting에서는 각 시점에서 사용 가능한 데이터만을 선택하여 모델링함
\end{itemize}

\subsubsection{News Decomposition}
dfm-python 패키지는 News decomposition 기능을 제공하여 새로운 데이터 발표가 예측 변화에 미치는 기여도를 분석함.
\begin{itemize}
    \item News는 새로운 데이터 발표로 인한 예측 업데이트를 나타냄
    \item News decomposition은 각 변수의 발표가 예측 변화에 미치는 기여도를 정량화함
    \item 이를 통해 어떤 변수가 예측에 가장 중요한 정보를 제공하는지 파악할 수 있음
    \item 이는 nowcasting의 신뢰성을 향상시키는 데 유용함
\end{itemize}

\subsection{평가 지표}

\subsubsection{표준화된 평가 지표}
본 연구에서는 표준화된 평가 지표를 사용하여 모형 성능을 비교함.
\begin{itemize}
    \item \textbf{표준화된 MSE (sMSE)}: $sMSE = \frac{1}{T} \sum_{t=1}^T \frac{(y_t - \hat{y}_t)^2}{\sigma_{train}^2}$
    \item \textbf{표준화된 MAE (sMAE)}: $sMAE = \frac{1}{T} \sum_{t=1}^T \frac{|y_t - \hat{y}_t|}{\sigma_{train}}$
    \item \textbf{표준화된 RMSE (sRMSE)}: $sRMSE = \sqrt{\frac{1}{T} \sum_{t=1}^T \frac{(y_t - \hat{y}_t)^2}{\sigma_{train}^2}}$
    \item 여기서 $\sigma_{train}$은 훈련 데이터의 표준편차임
    \item 표준화를 통해 서로 다른 스케일을 가진 목표 변수 간의 성능을 공정하게 비교할 수 있음
\end{itemize}

