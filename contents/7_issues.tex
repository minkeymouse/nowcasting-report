\section{이슈 분석}

관찰된 문제점 및 제한사항은 다음과 같음:

\subsection{모형별 기술적 제한사항}

\subsubsection{VAR의 긴 시점에서의 불안정성}

VAR은 벤치마크 모형으로 포함되었으며, 긴 시점(>7개월)에서 수치적 불안정성을 보임. 이는 다단계 예측에 VAR 사용을 제한하며, 정규화 기법이나 베이지안 VAR(BVAR) 등의 대안을 고려할 수 있음.

\subsubsection{DDFM의 성능 특성 및 개선 사항}

DDFM은 KOIPALL.G와 KOWRCCNSE에서 우수한 성능을 보이며(sMAE 각각 0.69, 0.50), 특히 변동성이 큰 시계열에서 DFM 대비 현저히 낮은 오차를 보임. 그러나 KOEQUIPTE에서는 DFM과 동일한 성능(sMAE=1.14)을 보여, 비선형 인코더가 추가적인 이점을 제공하지 못함.

\textbf{구현된 개선 사항:} KOEQUIPTE 성능 개선을 위해 다음과 같은 핵심 개선 사항을 구현함:
\begin{itemize}
    \item \textbf{대상 변수별 인코더 아키텍처:} 기본 인코더([16, 4]) 대신 더 깊은 인코더([64, 32, 16])를 사용하고, 훈련 에포크를 150으로 증가시킴.
    \item \textbf{활성화 함수 선택:} 기본 ReLU 대신 tanh 활성화 함수를 사용하여 음의 상관관계를 포착할 수 있도록 함.
    \item \textbf{Huber 손실 함수:} 이상치에 더 강건한 Huber 손실 함수를 지원함.
    \item \textbf{가중치 감쇠 (L2 정규화):} 선형 붕괴를 방지하기 위해 가중치 감쇠를 자동으로 적용함.
    \item \textbf{그래디언트 클리핑:} 훈련 안정성을 향상시키기 위해 그래디언트 클리핑을 지원함.
    \item \textbf{향상된 가중치 초기화:} 활성화 함수에 따라 적절한 가중치 초기화 방법을 적용함.
    \item \textbf{증가된 사전 훈련:} 사전 훈련 에포크 배수를 2로 증가시켜 비선형 특징 학습을 촉진함.
    \item \textbf{배치 크기 최적화:} 기본 배치 크기(100) 대신 더 작은 배치 크기(64)를 사용함.
    \item \textbf{DDFM 선형성 자동 감지 및 예측 품질 분석:} 선형 붕괴를 자동으로 감지하고 예측 품질을 분석하는 기능을 구현함.
\end{itemize}

\textbf{현재 상태:} 개선 사항은 코드에 구현되었으나, 효과를 검증하기 위해서는 추가 실험 재실행이 필요함. 특히 KOEQUIPTE에 대한 더 깊은 인코더와 증가된 에포크를 사용한 재실험을 통해 성능 개선 여부를 확인해야 함. DDFM 선형성 자동 감지 기능은 결과 집계 시 자동으로 실행되어 DDFM의 선형성 문제를 체계적으로 모니터링함.

\subsubsection{DFM/DDFM의 KOEQUIPTE 대상 변수에서의 성능 문제}

DFM과 DDFM 모형은 세 대상 변수 모두에서 성공적으로 평가되었으나, KOEQUIPTE에서는 두 모형이 동일한 성능(sMAE=1.14, sMSE=2.12)을 보임. 이는 DDFM의 비선형 인코더가 KOEQUIPTE에 대해 추가적인 이점을 제공하지 못함을 의미함.

\textbf{문제 분석:}
\begin{itemize}
    \item KOEQUIPTE는 21개 시점(horizon 22 제외)에 대해 유효한 결과를 생성함
    \item DDFM과 DFM이 동일한 성능을 보이는 것은 해당 시계열이 선형 관계가 강하거나, 기본 인코더 구조([16, 4])가 이 시계열에 최적화되지 않았을 가능성을 시사함
    \item KOIPALL.G와 KOWRCCNSE에서는 DDFM이 DFM 대비 현저히 우수한 성능을 보이는 것과 대조적임
\end{itemize}

\textbf{구현된 개선 사항:} KOEQUIPTE 성능 개선을 위해 더 깊은 인코더 구조, tanh 활성화 함수, 가중치 감쇠, 그래디언트 클리핑, Huber 손실 함수, 증가된 사전 훈련, 배치 크기 최적화를 구현함.

\textbf{현재 상태:} 개선 사항은 코드에 구현되었으나, 효과를 검증하기 위해서는 추가 실험 재실행이 필요함.

\subsubsection{DFM의 수치적 불안정성 및 해결}

DFM은 EM 알고리즘 수렴 중 일부 대상 변수에서 수치적 불안정성 문제를 보였으나, 수치 안정화 기법 적용 후 KOIPALL.G와 KOWRCCNSE에서 성공적으로 훈련됨. 

\textbf{문제 원인:}
\begin{itemize}
    \item Kalman filter의 재귀적 공분산 업데이트 과정에서 부동소수점 오차 누적
    \item 관측 차원이 증가할수록 공분산 행렬의 condition number 증가로 수치적 불안정성 가속화
    \item EM algorithm의 M-step에서 ill-conditioned 행렬로 인한 수렴 실패
\end{itemize}

\textbf{해결 방법:}
\begin{itemize}
    \item Robust statistics 접근법: 손상된 시간 단계의 EZZ 제외
    \item 수치 선형대수학 기법: 사전정규화, 공분산 행렬 대칭성 강제, R 행렬 최소값 설정 \cite{golub2013matrix, higham2002computing}
\end{itemize}

\textbf{결과:} KOIPALL.G와 KOWRCCNSE 대상 변수에서 DFM 모델이 정상적으로 훈련됨. 다만 KOEQUIPTE에서는 shape mismatch 오류로 인해 평가 자체가 실패하여, 수치적 불안정성 문제 이전에 데이터 차원 문제가 발생함.

\subsubsection{ARIMA/VAR 모형의 Nowcasting 제한사항}

ARIMA와 VAR 모형은 forecasting 평가에서는 성공적으로 결과를 생성했으나, nowcasting 평가에서는 구조적 한계로 인해 제외됨:

\textbf{Nowcasting에서의 구조적 한계:}
\begin{itemize}
    \item Release date 마스킹 처리의 구조적 한계: ARIMA/VAR은 단변량/다변량 시계열 모형으로, release date 기반 데이터 마스킹을 DFM/DDFM처럼 직접적으로 처리하기 어려움
    \item 요인 모형(DFM/DDFM)은 요인 공간에서 마스킹을 처리한 후 관측 공간으로 변환할 수 있으나, ARIMA/VAR은 이러한 구조적 유연성이 없음
    \item 본 연구에서는 nowcasting 실험을 DFM과 DDFM 모형에 대해서만 수행함
\end{itemize}

\subsubsection{DFM/DDFM Nowcasting 백테스트의 CUDA 텐서 변환 오류}

DFM과 DDFM 모형의 nowcasting 백테스트 실험이 모든 시점(2024-01 ~ 2025-10, 22개월)에서 실패함:

\textbf{문제 원인:}
\begin{itemize}
    \item CUDA 텐서 변환 오류: 예측값이 CUDA 디바이스에 있는 텐서인데, 이를 numpy 배열로 변환할 때 CPU로 먼저 이동하지 않아 오류 발생
    \item 오류 메시지: "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
    \item 영향 범위: 모든 DFM/DDFM 백테스트 결과(6개 JSON 파일 × 22개월 = 132개 예측)가 실패. 각 JSON 파일은 22개월에 대한 결과를 포함하며, 모든 결과가 "status": "failed"로 표시됨.
    \item 기술적 배경: PyTorch 텐서는 기본적으로 CPU 또는 CUDA 디바이스에 상주하며, numpy 배열로 변환하기 전에 CPU로 이동해야 함. CUDA 텐서를 직접 numpy로 변환하려고 시도하면 메모리 접근 오류가 발생함.
\end{itemize}

\textbf{해결 방법:} 예측값 변환 함수들에서 CUDA 텐서를 CPU로 이동한 후 numpy 배열로 변환하도록 수정함. 모든 텐서 변환 코드에서 표준 패턴을 적용하여 오류를 해결함.

\textbf{현재 상태:} 코드 수정 완료. 모델 훈련 없이 바로 백테스트를 재실행할 수 있으며, forecasting과 nowcasting 실험을 재실행하면 정상적으로 수행될 것으로 예상됨.

\subsection{실험 설계의 제한사항}

\begin{itemize}
    \item \textbf{훈련-예측 간격:} 4년 간격으로 COVID-19 제외 및 데이터 누수 방지, 그러나 최신 경제 패턴 반영 제한
    \item \textbf{테스트 데이터 부족:} 80/20 분할 후 각 시점당 단일 테스트 포인트 $\to$ 통계적 신뢰성 제한
    \item \textbf{Nowcasting 제한:} Release date 정보 정확성, ARIMA/VAR은 구조적 한계로 인해 nowcasting 실험에서 제외
\end{itemize}

\subsection{결과 검증 및 재현성}

본 연구의 모든 예측 결과는 다음과 같은 검증 과정을 거쳤음:

\begin{itemize}
    \item \textbf{시점 계산 검증:} 예측 시점 계산 로직을 검증하여 예측값이 올바른 테스트 시점과 비교되도록 보장함. 초기 구현에서 발견된 1개월 오프셋 버그를 수정하여, 예측값이 정확히 해당 시점의 실제값과 비교되도록 함
    \item \textbf{모델 예측 검증:} VAR, DFM, DDFM 모델이 정상적으로 예측을 생성하는지 검증함. DFM과 DDFM 모델의 경우 초기 구현에서 발견된 import 오류를 수정하여 모든 시점에서 유효한 예측값을 생성하도록 함. ARIMA는 세 대상 변수 모두에서 유효한 결과를 생성하지 못하여 검증 대상에서 제외됨
    \item \textbf{결과 완전성:} VAR은 3개 대상 변수 모두에서 완전한 결과를 생성함(66개 결과 포인트). DFM과 DDFM은 KOIPALL.G와 KOWRCCNSE에서 완전한 결과를 생성했으나, KOEQUIPTE에서는 22개월 시점이 누락되어 21개 시점에 대한 결과만 생성됨. ARIMA는 세 대상 변수 모두에서 유효한 결과(n\_valid=0)가 없어 평가에 실패함. 전체적으로 3개 대상 변수 × 4개 모델 × 22개 시점 = 264개 결과 포인트 중 약 73\% (VAR: 66개 완료, DFM: 64개 완료, DDFM: 64개 완료, ARIMA: 0개 완료, 총 194개)가 유효한 값을 가짐
    \item \textbf{재현성:} 모든 실험은 저장된 체크포인트를 사용하여 재현 가능하며, 동일한 설정으로 실행 시 동일한 결과를 보장함
\end{itemize}

\subsection{ARIMA 모형 평가 실패 원인 분석}

ARIMA 모형은 세 대상 변수 모두에서 유효한 결과(n\_valid=0)를 생성하지 못하여 평가에 실패함. 이는 다음과 같은 원인들이 있을 수 있음:

\textbf{가능한 원인:}
\begin{itemize}
    \item \textbf{모형 훈련 실패:} ARIMA 모형의 파라미터 추정 과정에서 수렴 실패 또는 수치적 불안정성
    \item \textbf{데이터 전처리 문제:} 결측치 처리, 변환, 또는 인덱스 정렬 과정에서의 오류
    \item \textbf{예측 생성 오류:} 예측값 생성 과정에서 shape mismatch, 인덱스 불일치, 또는 변환 오류
    \item \textbf{모형 적합성 문제:} ARIMA(1,1,1) 모형이 세 대상 변수 모두에 부적합할 가능성
\end{itemize}

\textbf{향후 조사 방향:}
\begin{itemize}
    \item ARIMA 훈련 로그를 확인하여 훈련 과정에서의 오류 파악
    \item ARIMA 모형 인스턴스화 및 적합 과정 검증
    \item 예측값 생성 코드에서 shape 및 인덱스 정렬 확인
    \item 데이터 호환성 검증 (결측치 처리, 변환 적용 여부)
    \item 자동 차수 선택(auto\_arima) 또는 다른 ARIMA 파라미터 조합 시도
\end{itemize}

\textbf{현재 상태:} ARIMA는 forecasting 결과 비교에 포함할 수 없으며, 향후 연구에서 문제를 해결하여 벤치마크 모형으로 포함해야 함.

\subsection{스케일 일치성 검증}

DFM/DDFM 모델의 예측값이 원본 스케일로 변환되는지 확인하기 위해 다음과 같은 검증을 수행함:

\textbf{1. 전처리 파이프라인 확인:}
\begin{itemize}
    \item DFM/DDFM 훈련 시 \texttt{\_create\_preprocessing\_pipeline} 함수 사용
    \item 이 함수는 imputation과 scaling만 수행하며, transformation (log, pch 등)은 포함하지 않음
    \item 따라서 모델은 원본 스케일 데이터로 훈련됨
\end{itemize}

\textbf{2. 예측값 스케일 확인:}
\begin{itemize}
    \item DFM/DDFM 예측값은 $X_{\text{forecast}} = X_{\text{std}} \times W_x + M_x$ 공식으로 계산됨
    \item 이는 unstandardization만 수행하며, transformation은 되돌리지 않음
    \item 하지만 transformation이 적용되지 않았으므로, 예측값은 원본 스케일임
\end{itemize}

\textbf{3. 테스트 데이터 스케일 확인:}
\begin{itemize}
    \item 테스트 데이터는 \texttt{resample\_to\_monthly}만 적용되어 원본 스케일임
    \item Transformation이 적용되지 않음
\end{itemize}

\textbf{결론:} 현재 코드 구조에서는 예측값과 실제값이 모두 원본 스케일이므로 스케일 일치함. 다만, 만약 \texttt{create\_transformer\_from\_config}를 사용하여 transformation이 적용되는 경우, 예측값은 transformed 스케일이 되고 실제값은 원본 스케일이 되어 스케일 불일치가 발생할 수 있음. 현재 평가 코드는 \texttt{DFMForecaster}/\texttt{DDFMForecaster}를 사용하며, 이들은 \texttt{\_create\_preprocessing\_pipeline}을 사용하므로 문제 없음.

\subsection{향후 연구 방향}

\begin{itemize}
    \item \textbf{모형 개선:} Robust Kalman filter, adaptive state space dimension
    \item \textbf{실험 설계 개선:} 롤링 윈도우 평가, 교차 검증
    \item \textbf{Release date 마스킹 개선}
    \item \textbf{추가 모형 비교}
\end{itemize}
