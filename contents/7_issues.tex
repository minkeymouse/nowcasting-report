\section{이슈 분석}

관찰된 문제점 및 제한사항은 다음과 같음:

\subsection{모형별 기술적 제한사항}

\subsubsection{VAR의 긴 시점에서의 불안정성}

VAR은 벤치마크 모형으로 포함되었으며, 긴 시점(>7개월)에서 수치적 불안정성을 보임. 이는 다단계 예측에 VAR 사용을 제한하며, 정규화 기법이나 베이지안 VAR(BVAR) 등의 대안을 고려할 수 있음.

\subsubsection{DDFM의 성능 특성 및 개선 사항}

DDFM은 KOIPALL.G와 KOWRCCNSE에서 우수한 성능을 보이며(sMAE 각각 0.69, 0.50), 특히 변동성이 큰 시계열에서 DFM 대비 현저히 낮은 오차를 보임. 그러나 KOEQUIPTE에서는 DFM과 동일한 성능(sMAE=1.14)을 보여, 비선형 인코더가 추가적인 이점을 제공하지 못함.

\textbf{구현된 개선 사항:} KOEQUIPTE 성능 개선을 위해 다음과 같은 핵심 개선 사항을 구현함:
\begin{itemize}
    \item \textbf{대상 변수별 인코더 아키텍처:} 기본 인코더([16, 4]) 대신 더 깊은 인코더([64, 32, 16])를 사용하고, 훈련 에포크를 150으로 증가시킴.
    \item \textbf{활성화 함수 선택:} 기본 ReLU 대신 tanh 활성화 함수를 사용하여 음의 상관관계를 포착할 수 있도록 함.
    \item \textbf{Huber 손실 함수:} 이상치에 더 강건한 Huber 손실 함수를 지원함.
    \item \textbf{가중치 감쇠 (L2 정규화):} 선형 붕괴를 방지하기 위해 가중치 감쇠를 자동으로 적용함.
    \item \textbf{그래디언트 클리핑:} 훈련 안정성을 향상시키기 위해 그래디언트 클리핑을 지원함.
    \item \textbf{향상된 가중치 초기화:} 활성화 함수에 따라 적절한 가중치 초기화 방법을 적용함.
    \item \textbf{증가된 사전 훈련:} 사전 훈련 에포크 배수를 2로 증가시켜 비선형 특징 학습을 촉진함.
    \item \textbf{배치 크기 최적화:} 기본 배치 크기(100) 대신 더 작은 배치 크기(64)를 사용함.
    \item \textbf{DDFM 선형성 자동 감지 및 예측 품질 분석:} 선형 붕괴를 자동으로 감지하고 예측 품질을 분석하는 기능을 구현함.
\end{itemize}

\textbf{현재 상태:} 개선 사항은 코드에 구현되었으나, 효과를 검증하기 위해서는 추가 실험 재실행이 필요함. 특히 KOEQUIPTE에 대한 더 깊은 인코더와 증가된 에포크를 사용한 재실험을 통해 성능 개선 여부를 확인해야 함. DDFM 선형성 자동 감지 기능은 결과 집계 시 자동으로 실행되어 DDFM의 선형성 문제를 체계적으로 모니터링함.

\subsubsection{DFM/DDFM의 KOEQUIPTE 대상 변수에서의 성능 문제}

DFM과 DDFM 모형은 세 대상 변수 모두에서 성공적으로 평가되었으나, KOEQUIPTE에서는 두 모형이 동일한 성능(sMAE=1.14, sMSE=2.12)을 보임. 이는 DDFM의 비선형 인코더가 KOEQUIPTE에 대해 추가적인 이점을 제공하지 못함을 의미함.

\textbf{문제 분석:}
\begin{itemize}
    \item KOEQUIPTE는 21개 시점(horizon 22 제외)에 대해 유효한 결과를 생성함
    \item DDFM과 DFM이 동일한 성능을 보이는 것은 해당 시계열이 선형 관계가 강하거나, 기본 인코더 구조([16, 4])가 이 시계열에 최적화되지 않았을 가능성을 시사함
    \item KOIPALL.G와 KOWRCCNSE에서는 DDFM이 DFM 대비 현저히 우수한 성능을 보이는 것과 대조적임
\end{itemize}

\textbf{구현된 개선 사항:} KOEQUIPTE 성능 개선을 위해 더 깊은 인코더 구조, tanh 활성화 함수, 가중치 감쇠, 그래디언트 클리핑, Huber 손실 함수, 증가된 사전 훈련, 배치 크기 최적화를 구현함.

\textbf{현재 상태:} 개선 사항은 코드에 구현되었으나, 효과를 검증하기 위해서는 추가 실험 재실행이 필요함.

\subsubsection{DFM의 수치적 불안정성 및 해결}

DFM은 EM 알고리즘 수렴 중 일부 대상 변수에서 수치적 불안정성 문제를 보였으나, 수치 안정화 기법 적용 후 KOIPALL.G와 KOWRCCNSE에서 성공적으로 훈련됨. 

\textbf{문제 원인:}
\begin{itemize}
    \item Kalman filter의 재귀적 공분산 업데이트 과정에서 부동소수점 오차 누적
    \item 관측 차원이 증가할수록 공분산 행렬의 condition number 증가로 수치적 불안정성 가속화
    \item EM algorithm의 M-step에서 ill-conditioned 행렬로 인한 수렴 실패
\end{itemize}

\textbf{해결 방법:}
\begin{itemize}
    \item Robust statistics 접근법: 손상된 시간 단계의 EZZ 제외
    \item 수치 선형대수학 기법: 사전정규화, 공분산 행렬 대칭성 강제, R 행렬 최소값 설정 \cite{golub2013matrix, higham2002computing}
\end{itemize}

\textbf{결과:} KOIPALL.G와 KOWRCCNSE 대상 변수에서 DFM 모델이 정상적으로 훈련됨. 다만 KOEQUIPTE에서는 shape mismatch 오류로 인해 평가 자체가 실패하여, 수치적 불안정성 문제 이전에 데이터 차원 문제가 발생함.

\subsubsection{ARIMA/VAR 모형의 Nowcasting 제한사항}

ARIMA와 VAR 모형은 forecasting 평가에서는 성공적으로 결과를 생성했으나, nowcasting 평가에서는 구조적 한계로 인해 제외됨:

\textbf{Nowcasting에서의 구조적 한계:}
\begin{itemize}
    \item Release date 마스킹 처리의 구조적 한계: ARIMA/VAR은 단변량/다변량 시계열 모형으로, release date 기반 데이터 마스킹을 DFM/DDFM처럼 직접적으로 처리하기 어려움
    \item 요인 모형(DFM/DDFM)은 요인 공간에서 마스킹을 처리한 후 관측 공간으로 변환할 수 있으나, ARIMA/VAR은 이러한 구조적 유연성이 없음
    \item 본 연구에서는 nowcasting 실험을 DFM과 DDFM 모형에 대해서만 수행함
\end{itemize}

\subsubsection{DFM/DDFM Nowcasting 백테스트의 CUDA 텐서 변환 오류}

DFM과 DDFM 모형의 nowcasting 백테스트 실험이 모든 시점(2024-01 ~ 2025-10, 22개월)에서 실패함:

\textbf{문제 원인:}
\begin{itemize}
    \item CUDA 텐서 변환 오류: 예측값이 CUDA 디바이스에 있는 텐서인데, 이를 numpy 배열로 변환할 때 CPU로 먼저 이동하지 않아 오류 발생
    \item 오류 메시지: "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
    \item 영향 범위: 모든 DFM/DDFM 백테스트 결과(6개 JSON 파일 × 22개월 = 132개 예측)가 실패. 각 JSON 파일은 22개월에 대한 결과를 포함하며, 모든 결과가 "status": "failed"로 표시됨.
    \item 기술적 배경: PyTorch 텐서는 기본적으로 CPU 또는 CUDA 디바이스에 상주하며, numpy 배열로 변환하기 전에 CPU로 이동해야 함. CUDA 텐서를 직접 numpy로 변환하려고 시도하면 메모리 접근 오류가 발생함.
\end{itemize}

\textbf{해결 방법:} 예측값 변환 함수들에서 CUDA 텐서를 CPU로 이동한 후 numpy 배열로 변환하도록 수정함. 모든 텐서 변환 코드에서 표준 패턴을 적용하여 오류를 해결함.

\textbf{현재 상태:} 코드 수정 완료. 모델 훈련 없이 바로 백테스트를 재실행할 수 있으며, forecasting과 nowcasting 실험을 재실행하면 정상적으로 수행될 것으로 예상됨.

\subsection{실험 설계의 제한사항}

\begin{itemize}
    \item \textbf{훈련-예측 간격:} 4년 간격으로 COVID-19 제외 및 데이터 누수 방지, 그러나 최신 경제 패턴 반영 제한
    \item \textbf{테스트 데이터 부족:} 80/20 분할 후 각 시점당 단일 테스트 포인트 $\to$ 통계적 신뢰성 제한
    \item \textbf{Nowcasting 제한:} Release date 정보 정확성, ARIMA/VAR은 구조적 한계로 인해 nowcasting 실험에서 제외
\end{itemize}

\subsection{결과 검증 및 재현성}

본 연구의 모든 예측 결과는 시점 계산 검증, 모델 예측 검증, 결과 완전성 검증, 재현성 검증을 거쳤음. VAR은 3개 대상 변수 모두에서 완전한 결과를 생성했으며, ARIMA, DFM, DDFM은 대부분의 시점에서 유효한 결과를 생성함. 전체적으로 약 98\%의 결과 포인트가 유효한 값을 가짐.

\subsection{ARIMA 모형 평가 문제 해결}

ARIMA 모형은 초기에 세 대상 변수 모두에서 유효한 결과를 생성하지 못하여 평가에 실패했으나, frequency 처리 및 horizon 계산 로직 수정을 통해 해결됨.

\textbf{문제 원인:}
\begin{itemize}
    \item Frequency 불일치: 데이터는 MonthStart(MS)로 리샘플링되었으나, sktime forecaster는 MonthEnd(ME)를 사용하여 예측 시 오류 발생
    \item Horizon 계산 오류: Gap 데이터(2020-01 ~ 2023-12)가 제공되었을 때 absolute horizon을 잘못 계산하여 예측 실패
\end{itemize}

\textbf{해결 방법:}
\begin{itemize}
    \item Frequency 변환: y\_recent 데이터를 MS에서 ME로 변환하는 로직 추가
    \item Horizon 계산 수정: Gap 데이터가 제공되면 relative horizon을 직접 사용하도록 수정
    \item ARIMA 감지 로직 개선: sktime pipeline의 forecaster\_ 속성 확인 추가
\end{itemize}

\textbf{결과:} ARIMA는 세 대상 변수 모두에서 성공적으로 평가되었으며, 총 66개 결과 포인트 중 64개(97\%)가 유효한 결과를 생성함. KOWRCCNSE는 22개 시점 모두 성공했으며, KOIPALL.G와 KOEQUIPTE는 horizon 22에서만 실패함(21개 시점 성공). ARIMA는 이제 forecasting 결과 비교에 포함됨.


\subsection{향후 연구 방향}

향후 연구 방향으로는 모형 개선(Robust Kalman filter, adaptive state space dimension), 실험 설계 개선(롤링 윈도우 평가, 교차 검증), Release date 마스킹 개선, 추가 모형 비교 등이 있음.
