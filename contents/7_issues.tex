\section{이슈 분석}

관찰된 문제점 및 제한사항은 다음과 같음:

\subsection{모형별 기술적 제한사항}

\subsubsection{VAR의 긴 시점에서의 불안정성}

VAR은 벤치마크 모형으로 포함되었으며, 긴 시점(>7개월)에서 수치적 불안정성을 보임. 이는 다단계 예측에 VAR 사용을 제한하며, 정규화 기법이나 베이지안 VAR(BVAR) 등의 대안을 고려할 수 있음.

\subsubsection{DDFM의 성능 특성 및 개선 사항}

DDFM은 KOIPALL.G와 KOWRCCNSE에서 우수한 성능을 보이며(sMAE 각각 0.69, 0.50), 특히 변동성이 큰 시계열에서 DFM 대비 현저히 낮은 오차를 보임. 그러나 KOEQUIPTE에서는 DFM과 동일한 성능(sMAE=1.14)을 보여, 비선형 인코더가 추가적인 이점을 제공하지 못함.

\textbf{구현된 개선 사항:}
\begin{itemize}
    \item \textbf{대상 변수별 인코더 아키텍처:} KOEQUIPTE에 대해서는 기본 인코더([16, 4]) 대신 더 깊은 인코더([64, 32, 16])를 자동으로 사용하도록 구현함. 이는 더 복잡한 비선형 관계를 포착하기 위한 용량을 제공함. 또한 더 깊은 인코더에 대해서는 훈련 에포크를 100에서 150으로 증가시켜 충분한 학습을 보장함.
    \item \textbf{활성화 함수 선택:} KOEQUIPTE에 대해서는 기본 ReLU 활성화 함수 대신 tanh 활성화 함수를 자동으로 사용하도록 구현함. ReLU는 음의 값을 0으로 만드는 특성으로 인해 음의 상관관계를 포착하기 어려울 수 있음. 반면 tanh는 대칭적인 출력 범위(-1, 1)를 가지므로 음의 요인 부하를 학습할 수 있어, KOEQUIPTE와 같은 시계열에서 음의 상관관계가 중요한 경우 더 적합함. \texttt{activation: 'tanh'} 파라미터를 통해 설정 가능하며, 기본값은 'relu'임.
    \item \textbf{Huber 손실 함수 지원:} 이상치에 더 강건한 Huber 손실 함수를 지원하도록 구현함. Huber 손실은 작은 오차에 대해서는 MSE와 유사하게 동작하지만, 큰 오차에 대해서는 선형적으로 증가하여 이상치의 영향을 완화함. \texttt{loss\_function: 'huber'} 파라미터를 통해 설정 가능하며, \texttt{huber\_delta} 파라미터로 전환점을 조정할 수 있음 (기본값: 1.0).
    \item \textbf{가중치 감쇠 (L2 정규화):} KOEQUIPTE에 대해서는 가중치 감쇠(weight decay, L2 정규화)를 자동으로 적용함(\texttt{weight\_decay=1e-4}). L2 정규화는 인코더가 선형 PCA와 유사한 해에 과적합되는 것을 방지하고, 다양한 비선형 특징을 학습하도록 장려함. 이는 인코더가 선형 변환에 가까운 가중치를 학습하여 DFM과 동일한 성능을 보이는 문제를 완화하기 위한 것으로, 모든 옵티마이저 인스턴스에 적용됨. \texttt{weight\_decay} 파라미터를 통해 설정 가능하며, 기본값은 0.0임.
    \item \textbf{그래디언트 클리핑:} 훈련 안정성을 향상시키기 위해 그래디언트 클리핑을 지원함. \texttt{grad\_clip\_val} 파라미터로 클리핑 값을 조정할 수 있으며, 기본값은 1.0임. 그래디언트 폭발을 방지하여 NaN 값이나 선형 붕괴를 유발할 수 있는 훈련 불안정성을 완화함. 이는 pre-training, MCMC 훈련, 그리고 Lightning training step에 모두 적용됨.
    \item \textbf{향상된 가중치 초기화:} 인코더 레이어에 대해 활성화 함수에 따라 적절한 가중치 초기화 방법을 적용함. ReLU 활성화 함수의 경우 Kaiming 초기화를 사용하여 ReLU 네트워크에 최적화된 초기화를 제공함. tanh나 sigmoid와 같은 대칭 활성화 함수의 경우 Xavier 초기화를 사용하여 대칭 활성화 함수에 더 적합한 초기화를 제공함. 출력 레이어는 더 작은 초기화(gain=0.1)를 사용하여 초기 요인 값이 과도하게 크지 않도록 함. 이러한 개선은 특히 더 깊은 네트워크에서 훈련 안정성과 수렴 속도를 향상시킴. 이는 \texttt{dfm-python/src/dfm\_python/encoder/vae.py}에서 구현됨.
    \item \textbf{요인 차수 설정:} 요인 동역학에 대한 VAR 차수를 설정할 수 있도록 \texttt{factor\_order} 파라미터를 추가함. 기본값은 1(VAR(1))이며, 2(VAR(2))로 설정할 수 있음. VAR(2)는 더 긴 기간의 의존성을 포착할 수 있으나 더 많은 데이터가 필요함. 일부 대상 변수는 복잡한 다기간 동역학을 가지므로 VAR(2)가 도움이 될 수 있음. 이는 \texttt{src/models/models\_forecasters.py}와 \texttt{src/train.py}에서 구현됨.
    \item \textbf{향상된 훈련 안정성:} 더 깊은 네트워크(레이어 수 > 2)에 대해서는 입력 클리핑 범위를 더 엄격하게 설정하여 극단값에 대한 민감도를 줄임. 또한 훈련 단계에서 수치적 안정성 처리를 개선하여 더 깊은 아키텍처에서의 훈련 안정성을 향상시킴. 이는 \texttt{dfm-python/src/dfm\_python/models/ddfm.py}에서 구현됨.
    \item \textbf{증가된 사전 훈련:} KOEQUIPTE 대상 변수에 대해서는 사전 훈련 에포크 배수를 1에서 2로 증가시킴(\texttt{mult\_epoch\_pretrain=2}). 사전 훈련은 MCMC 훈련이 시작되기 전에 인코더가 비선형 특징을 학습하는 데 도움을 줌. 더 많은 사전 훈련 에포크는 인코더가 MCMC 반복 전에 비선형 특징을 학습할 시간을 더 제공하여, 인코더가 선형 동작으로 붕괴되는 것을 방지하는 데 도움이 됨. 이는 \texttt{src/train.py}와 \texttt{src/models/models\_forecasters.py}에서 구현됨.
    \item \textbf{배치 크기 최적화:} KOEQUIPTE 대상 변수에 대해서는 기본 배치 크기(100) 대신 더 작은 배치 크기(64)를 자동으로 사용하도록 구현함. 더 작은 배치 크기는 에포크당 더 다양한 그래디언트를 제공하여 인코더가 선형 PCA와 유사한 해에 수렴하는 것을 방지하고, 비선형 특징을 학습하도록 도울 수 있음. 이는 \texttt{src/train.py}에서 구현됨.
    \item \textbf{향상된 훈련 설정:} 손실 함수, 활성화 함수, Huber delta, 가중치 감쇠, 그래디언트 클리핑, 요인 차수, 사전 훈련 배수, 배치 크기를 모델 파라미터를 통해 설정할 수 있으며, 대상 변수별 하이퍼파라미터 조정이 가능함. 또한 손실 함수, 활성화 함수, 아키텍처 선택에 대한 로깅을 강화하여 실험 추적성을 향상시킴.
    \item \textbf{DDFM 선형성 자동 감지 기능:} DDFM이 선형 관계만 학습하는지 자동으로 감지하는 기능을 구현함. \texttt{src/evaluation/evaluation_aggregation.py}에 구현된 \texttt{detect\_ddfm\_linearity()} 함수는 결과 집계 시 자동으로 실행되어 DDFM과 DFM의 성능 메트릭을 비교함. 이 함수는 각 대상 변수와 시점에 대해 선형성 점수(0-1, 높을수록 선형)를 계산하며, 선형성 점수가 0.95 이상인 경우 DDFM이 선형 관계만 학습하고 있음을 경고함. 또한 선형성 감지 결과는 \texttt{outputs/experiments/ddfm\_linearity\_analysis.json}에 저장되며, 각 대상 변수에 대한 개선 권장사항(더 깊은 인코더, tanh 활성화 함수, 가중치 감쇠 등)을 제공함. 이 기능은 DDFM의 성능 문제를 조기에 발견하고 개선 방향을 제시하는 데 도움을 줌.
    \item \textbf{향상된 DDFM 예측 품질 분석 기능:} DDFM의 예측 품질을 상세히 분석하는 기능을 구현함. \texttt{src/evaluation/evaluation_aggregation.py}에 구현된 \texttt{analyze\_ddfm\_prediction\_quality()} 함수는 결과 집계 시 자동으로 실행되어 DDFM의 시점별 성능 패턴, 불안정한 시점 식별, 예측 안정성 메트릭, 그리고 DFM 기준선과의 비교를 수행함. 향상된 진단 메트릭으로는 예측 안정성 메트릭(계수 of variation, CV), 단기 vs 장기 성능 분석(1-6개월 vs 13-22개월), 일관성 메트릭(시점 간 개선의 일관성), 최고/최악 시점 식별(개선 비율 기준), 향상된 선형 붕괴 위험 평가(7가지 위험 요소 종합), 시점별 성능 저하 감지, 오차 패턴 유사성, 시점 간 오차 상관관계, 오차 분포 유사성(왜도/첨도), sMSE/sMAE 비율 안정성 등이 포함됨. 이 함수는 각 대상 변수에 대해 오차 분산, 불안정한 시점(평균 + 1.5 × 표준편차를 초과하는 시점), 그리고 DFM 대비 개선 비율을 계산함. 특히 향상된 선형 붕괴 위험 평가는 DFM 대비 개선 정도, 시점별 유사성, 일관성, 오차 패턴 유사성(sMSE/sMAE 비율), 시점 간 오차 상관관계, 상대적 개선 일관성, 오차 분포 유사성(왜도/첨도)을 종합적으로 고려하여 더 정확한 위험 평가를 제공함. 또한 각 대상 변수에 대한 구체적인 개선 권장사항을 생성하며, 예를 들어 오차 분산이 높은 경우 정규화나 앙상블 방법을 권장하고, 특정 시점에서 불안정성이 관찰되는 경우 시점별 튜닝을 권장하며, 오차 패턴 유사성이 높거나 시점 간 오차 상관관계가 높거나 오차 분포 유사성이 높은 경우 인코더 아키텍처 개선을 권장함. 이 기능은 DDFM의 성능 특성을 체계적으로 분석하고 개선 방향을 제시하는 데 도움을 줌.
    \item \textbf{향상된 오차 분포 메트릭:} DDFM의 예측 오차 분포를 더 자세히 분석하기 위해 \texttt{src/evaluation/evaluation_metrics.py}의 \texttt{calculate\_standardized\_metrics()} 함수에 오차 분포 분석 메트릭을 추가함. 이러한 메트릭들은 각 시점별로 계산되며, DDFM의 예측 특성을 더 깊이 이해하는 데 도움을 줌:
    \begin{itemize}
        \item \textbf{오차 왜도 (error\_skewness):} 오차 분포의 비대칭성을 측정하여 체계적인 과대/과소 예측 패턴을 식별함.
        \item \textbf{오차 첨도 (error\_kurtosis):} 오차 분포의 꼬리 두께를 측정하여 이상치에 취약한 예측을 식별함.
        \item \textbf{오차 편향 제곱 (error\_bias\_squared):} 편향-분산 분해에서 체계적 편향 성분을 측정하여 모델의 구조적 한계를 파악함.
        \item \textbf{오차 분산 (error\_variance):} 편향-분산 분해에서 분산 성분을 측정하여 예측 불안정성을 평가함.
        \item \textbf{오차 집중도 (error\_concentration):} 오차가 균등하게 분포되어 있는지 아니면 특정 시점에 집중되어 있는지를 측정하여 체계적 문제를 식별함.
    \end{itemize}
    이러한 메트릭들을 종합적으로 분석하면 DDFM의 예측 오차 원인을 더 정확히 파악할 수 있으며, 편향과 분산 중 어느 쪽을 개선해야 하는지 결정할 수 있음.
    \item \textbf{시점 간 오차 상관관계 분석:} DDFM의 오차 패턴이 시점 간에 어떻게 상관관계를 가지는지 분석하는 기능을 구현함. \texttt{src/evaluation/evaluation_aggregation.py}에 구현된 \texttt{analyze\_horizon\_error\_correlation()} 함수는 서로 다른 예측 시점 간의 오차 유사성을 계산하여 체계적 문제(예: 선형 붕괴)와 시점별 문제를 구분함. 이 함수는 유사성 행렬, 평균 유사성, 체계적 패턴 점수(0-1), 최대/최소 유사성 시점 쌍을 계산하며, 각 대상 변수에 대한 구체적인 개선 권장사항을 제공함. 높은 체계적 패턴 점수(> 0.7)는 인코더 아키텍처 개선을, 낮은 점수(< 0.3)는 시점별 정규화를 권장함.
    \item \textbf{상대 오차 안정성 메트릭:} DDFM과 DFM 간의 상대적 성능이 시점에 따라 어떻게 변화하는지 분석하는 기능을 구현함. \texttt{src/evaluation/evaluation_metrics.py}에 구현된 \texttt{calculate\_relative\_error\_stability()} 함수는 안정성 점수(0-1), 변동 계수(CV), 그리고 추세 분석(개선/저하/안정)을 계산하여 DDFM의 상대적 성능이 일관적인지 평가함. 이 메트릭은 \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합되어 자동으로 분석되며, 체계적 개선과 시점별 변동을 구분하는 데 도움을 줌.
    \item \textbf{개선 지속성 메트릭:} DDFM의 개선이 지속적인(일관된) 개선인지, 아니면 일시적인(노이즈) 개선인지 감지하는 기능을 구현함. \texttt{src/evaluation/evaluation_metrics.py}에 구현된 \texttt{calculate\_improvement\_persistence()} 함수는 지속성 점수(0-1), 개선 비율, 연속 개선 구간, 그리고 개선 클러스터를 계산하여 DDFM이 DFM 대비 체계적으로 개선되는지 평가함. 이 메트릭은 \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합되어 자동으로 분석되며, 실제 모델 개선과 랜덤 변동을 구분하는 데 도움을 줌.
    \item \textbf{시간적 일관성 메트릭:} 연속된 시점 간 예측값의 급격한 변화(점프)를 감지하는 기능을 구현함. \texttt{src/evaluation/evaluation_metrics.py}에 구현된 \texttt{calculate\_temporal\_consistency\_metrics()} 함수는 시간적 일관성 점수(0-1), 점프 개수, 점프 비율, 그리고 점프 크기를 계산하여 모델의 예측이 시간적으로 일관적인지 평가함. 이 메트릭은 평가 파이프라인에서 사용 가능하며, 모델 불안정성이나 요인 동역학 문제를 조기에 발견하는 데 도움을 줌.
    \item \textbf{향상된 메트릭 계산:} 메트릭 계산의 수치적 안정성을 향상시킴. \texttt{src/evaluation/evaluation_metrics.py}에서 매우 작은 값(< 1e-10)을 반올림하여 수치적 정밀도 문제를 방지하고, 표준화 과정에서 0으로 나누는 경우에 대한 검증을 추가함. 또한 극단값에 대한 엣지 케이스 처리를 개선함.
\end{itemize}

\textbf{현재 상태:} 개선 사항은 코드에 구현되었으나, 효과를 검증하기 위해서는 추가 실험 재실행이 필요함. 특히 KOEQUIPTE에 대한 더 깊은 인코더와 증가된 에포크를 사용한 재실험을 통해 성능 개선 여부를 확인해야 함. DDFM 선형성 자동 감지 기능은 결과 집계 시 자동으로 실행되어 DDFM의 선형성 문제를 체계적으로 모니터링함.

\textbf{분석 도구 활용:} DDFM 성능 개선을 위한 체계적인 분석을 위해 다음 함수들을 활용할 수 있음:
\begin{itemize}
    \item \textbf{상관관계 구조 분석 (\texttt{analyze\_correlation\_structure()}):} 모델 훈련 전에 실행 가능하며, 대상 변수와 모든 입력 시계열 간의 상관관계 패턴을 분석함. 음의 상관관계 비율, 강한 음의 상관관계 개수, 평균 상관관계 등을 계산하여 활성화 함수 선택(tanh vs ReLU) 및 인코더 아키텍처 결정에 활용함. 실행 방법: \texttt{python3 -c "from src.evaluation.evaluation\_aggregation import analyze\_correlation\_structure; result = analyze\_correlation\_structure('data/data.csv', 'KOEQUIPTE', output\_path='outputs/analysis/correlation\_analysis\_KOEQUIPTE.json')"}
    \item \textbf{DDFM 선형성 감지 (\texttt{detect\_ddfm\_linearity()}):} 결과 집계 시 자동으로 실행되며, DDFM과 DFM의 성능 메트릭을 비교하여 선형성 점수(0-1)를 계산함. 선형성 점수가 0.95 이상이면 DDFM이 선형 관계만 학습하고 있음을 경고하며, 개선 권장사항을 제공함. 결과는 \texttt{outputs/experiments/ddfm\_linearity\_analysis.json}에 저장됨.
    \item \textbf{DDFM 예측 품질 분석 (\texttt{analyze\_ddfm\_prediction\_quality()}):} 결과 집계 시 자동으로 실행되며, DDFM의 시점별 성능 패턴, 불안정한 시점 식별, 예측 안정성 메트릭(계수 of variation), 단기 vs 장기 성능 분석(1-6개월 vs 13-22개월), 일관성 메트릭, 최고/최악 시점 식별 등을 수행함. 각 대상 변수에 대한 구체적인 개선 권장사항을 생성하여 DDFM의 성능 특성을 체계적으로 분석함.
\end{itemize}
이러한 분석 도구들을 활용하여 DDFM 성능 개선을 위한 체계적인 연구를 수행할 수 있으며, 각 단계에서의 결과를 정량적으로 평가하여 다음 단계의 개선 방향을 결정할 수 있음.

\textbf{메트릭 기반 연구 방법론:} DDFM 성능 개선을 위한 체계적인 방법론은 메트릭 기반 의사결정을 통해 각 단계의 성공/실패를 정량적으로 평가함:
\begin{enumerate}
    \item \textbf{Phase 0: 사전 분석 (즉시 실행 가능, 훈련 불필요):} 
    \begin{itemize}
        \item \texttt{analyze\_correlation\_structure()} 함수를 사용하여 세 대상 변수에 대해 상관관계 구조 분석 실행 (~15분)
        \item 주요 메트릭: 음의 상관관계 비율(negative\_fraction), 강한 음의 상관관계 개수(strong\_negative\_count), 평균 상관관계(mean\_correlation), 상관관계 표준편차(std\_correlation)
        \item 의사결정 기준: KOEQUIPTE의 음의 상관관계 비율이 0.3 이상이고 다른 대상 변수가 0.2 미만이면, tanh 활성화 함수 전략이 타당함을 확인
        \item 출력: \texttt{outputs/analysis/correlation\_analysis\_\{target\}.json} (3개 파일)
    \end{itemize}
    \item \textbf{기준선 수립 (즉시 실행 가능, 훈련 불필요):}
    \begin{itemize}
        \item 현재 \texttt{aggregated\_results.csv}를 사용하여 기준선 메트릭 계산
        \item \texttt{detect\_ddfm\_linearity()} 실행: 기준선 선형성 점수 계산 (예상: ~0.99)
        \item \texttt{analyze\_ddfm\_prediction\_quality()} 실행: 기준선 개선 비율, 붕괴 위험 점수 계산
        \item 출력: \texttt{outputs/analysis/baseline\_linearity.json}, \texttt{outputs/analysis/baseline\_quality.json}
        \item 목적: 개선 후 결과와 비교하여 정량적 개선 여부 평가
    \end{itemize}
    \item \textbf{Phase 1: 검증 (모델 훈련 필요, 예측 실험 실행):}
    \begin{itemize}
        \item 현재 \texttt{checkpoint/} 디렉토리에는 12개의 모델 파일이 존재하므로, 모델 훈련 없이 바로 예측 실험을 실행하여 최신 코드 개선사항이 반영된 결과 생성
        \item 결과 집계 시 \texttt{detect\_ddfm\_linearity()}와 \texttt{analyze\_ddfm\_prediction\_quality()} 함수가 자동으로 실행됨
        \item 성공 기준 (정량적 임계값):
        \begin{itemize}
            \item \textbf{주요}: sMAE 개선 ≥ 10\% (목표: sMAE < 1.03 from baseline 1.14) AND DDFM이 DFM보다 최소 5\% 이상 우수
            \item \textbf{선형성 점수}: < 0.95 (기준선: ~0.99)
            \item \textbf{개선 비율}: > 10\% (기준선: ~0\%)
            \item \textbf{붕괴 위험}: < 0.5 (기준선: ~0.95+)
            \item \textbf{일관성 메트릭}: > 0.7
        \end{itemize}
        \item 의사결정 트리:
        \begin{itemize}
            \item ✅ \textbf{SUCCESS}: 개선 ≥ 10\% AND DDFM > 5\% better AND 선형성 < 0.95 AND 붕괴 위험 < 0.5 → Phase 1.2로 진행
            \item ⚠️ \textbf{PARTIAL}: 개선 5-10\% OR 선형성 0.95-0.98 → 조사 후 Phase 1.2로 신중하게 진행
            \item ❌ \textbf{NEEDS INVESTIGATION}: 개선 < 10\% OR 선형성 ≥ 0.95 OR 붕괴 위험 ≥ 0.5 → 로그 확인, Phase 2로 진행
            \item ❌ \textbf{FAILURE}: 개선 없음 또는 성능 저하 → 로그 확인, 원인 조사, Phase 2로 진행
        \end{itemize}
    \end{itemize}
    \item \textbf{Phase 1.2: 활성화 함수 비교 (Phase 1 성공 시):}
    \begin{itemize}
        \item KOEQUIPTE에 대해 4가지 활성화 함수(relu, tanh, sigmoid, leaky\_relu)로 DDFM 모델 훈련
        \item 각 활성화 함수에 대해 메트릭 비교: 개선 비율, 선형성 점수, 오차 분포 차이
        \item 최적 활성화 함수 선택: 가장 높은 개선 비율과 가장 낮은 선형성 점수를 가진 활성화 함수
    \end{itemize}
    \item \textbf{Phase 2: 고급 개선 (Phase 1 실패 시):}
    \begin{itemize}
        \item 인코더 아키텍처 그리드 서치: 다양한 구조([32, 16, 8], [128, 64, 32], [64, 32, 16, 8] 등) 체계적 테스트
        \item 요인 부하 분석: DFM과 DDFM이 학습한 요인 부하 비교하여 선형 붕괴 확인
        \item 정규화 실험: Dropout, L1/L2 정규화 다양한 강도 테스트
    \end{itemize}
    \item \textbf{Phase 3: 앙상블 및 고급 기법 (Phase 2 실패 시):}
    \begin{itemize}
        \item 앙상블 방법: DFM과 DDFM 예측값의 가중 평균 사용
        \item 특징 공학: 다른 변환 또는 상호작용 특징 추가
        \item 하이브리드 접근: KOEQUIPTE에는 DFM 사용, 다른 대상 변수에는 DDFM 사용
    \end{itemize}
\end{enumerate}

\textbf{예상 결과:}
\begin{itemize}
    \item \textbf{최선의 경우:} tanh 활성화 함수와 더 깊은 인코더로 KOEQUIPTE의 sMAE가 1.03 이하로 개선됨. 이는 음의 상관관계가 중요하고 인코더 용량이 부족했음을 시사함.
    \item \textbf{중간 경우:} 일부 개선이 관찰되지만 목표(sMAE < 1.0)에 도달하지 못함. 이 경우 추가 아키텍처 최적화나 정규화 기법이 필요함.
    \item \textbf{최악의 경우:} 개선이 관찰되지 않음. 이는 KOEQUIPTE가 본질적으로 선형 관계가 강한 시계열이거나, 현재 데이터로는 비선형 관계를 학습하기 어렵다는 것을 시사함. 이 경우 하이브리드 접근(DFM for KOEQUIPTE, DDFM for others)을 고려해야 함.
\end{itemize}

\subsubsection{DFM/DDFM의 KOEQUIPTE 대상 변수에서의 성능 문제}

DFM과 DDFM 모형은 세 대상 변수 모두에서 성공적으로 평가되었으나, KOEQUIPTE에서는 두 모형이 동일한 성능(sMAE=1.14, sMSE=2.12)을 보임. 이는 DDFM의 비선형 인코더가 KOEQUIPTE에 대해 추가적인 이점을 제공하지 못함을 의미함.

\textbf{문제 분석:}
\begin{itemize}
    \item KOEQUIPTE는 21개 시점(horizon 22 제외)에 대해 유효한 결과를 생성함
    \item DDFM과 DFM이 동일한 성능을 보이는 것은 해당 시계열이 선형 관계가 강하거나, 기본 인코더 구조([16, 4])가 이 시계열에 최적화되지 않았을 가능성을 시사함
    \item KOIPALL.G와 KOWRCCNSE에서는 DDFM이 DFM 대비 현저히 우수한 성능을 보이는 것과 대조적임
\end{itemize}

\textbf{구현된 개선 사항:}
\begin{itemize}
    \item KOEQUIPTE에 대해서는 더 깊은 인코더 구조([64, 32, 16])를 자동으로 사용하도록 구현함
    \item 더 깊은 인코더에 대해서는 훈련 에포크를 100에서 150으로 증가시킴
    \item tanh 활성화 함수를 자동으로 사용하여 음의 상관관계를 포착할 수 있도록 함
    \item 가중치 감쇠(L2 정규화, weight\_decay=1e-4)를 자동으로 적용하여 선형 붕괴를 방지함
    \item 그래디언트 클리핑을 지원하여 훈련 안정성을 향상시킴
    \item Huber 손실 함수 지원을 추가하여 이상치에 대한 강건성을 향상시킴
    \item 증가된 사전 훈련(mult\_epoch\_pretrain=2)을 자동으로 적용하여 인코더가 MCMC 전에 비선형 특징을 학습할 시간을 확보함
    \item 배치 크기 최적화(batch\_size=64)를 자동으로 적용하여 더 다양한 그래디언트로 선형 해 탈출을 지원함
\end{itemize}

\textbf{현재 상태:} 개선 사항은 코드에 구현되었으나, 효과를 검증하기 위해서는 추가 실험 재실행이 필요함.

\subsubsection{DFM의 수치적 불안정성 및 해결}

DFM은 EM 알고리즘 수렴 중 일부 대상 변수에서 수치적 불안정성 문제를 보였으나, 수치 안정화 기법 적용 후 KOIPALL.G와 KOWRCCNSE에서 성공적으로 훈련됨. 

\textbf{문제 원인:}
\begin{itemize}
    \item Kalman filter의 재귀적 공분산 업데이트 과정에서 부동소수점 오차 누적
    \item 관측 차원이 증가할수록 공분산 행렬의 condition number 증가로 수치적 불안정성 가속화
    \item EM algorithm의 M-step에서 ill-conditioned 행렬로 인한 수렴 실패
\end{itemize}

\textbf{해결 방법:}
\begin{itemize}
    \item Robust statistics 접근법: 손상된 시간 단계의 EZZ 제외
    \item 수치 선형대수학 기법: 사전정규화, 공분산 행렬 대칭성 강제, R 행렬 최소값 설정 \cite{golub2013matrix, higham2002computing}
\end{itemize}

\textbf{결과:} KOIPALL.G와 KOWRCCNSE 대상 변수에서 DFM 모델이 정상적으로 훈련됨. 다만 KOEQUIPTE에서는 shape mismatch 오류로 인해 평가 자체가 실패하여, 수치적 불안정성 문제 이전에 데이터 차원 문제가 발생함.

\subsubsection{ARIMA/VAR 모형의 Nowcasting 제한사항}

ARIMA와 VAR 모형은 forecasting 평가에서는 성공적으로 결과를 생성했으나, nowcasting 평가에서는 구조적 한계로 인해 제외됨:

\textbf{Nowcasting에서의 구조적 한계:}
\begin{itemize}
    \item Release date 마스킹 처리의 구조적 한계: ARIMA/VAR은 단변량/다변량 시계열 모형으로, release date 기반 데이터 마스킹을 DFM/DDFM처럼 직접적으로 처리하기 어려움
    \item 요인 모형(DFM/DDFM)은 요인 공간에서 마스킹을 처리한 후 관측 공간으로 변환할 수 있으나, ARIMA/VAR은 이러한 구조적 유연성이 없음
    \item 본 연구에서는 nowcasting 실험을 DFM과 DDFM 모형에 대해서만 수행함
\end{itemize}

\subsubsection{DFM/DDFM Nowcasting 백테스트의 CUDA 텐서 변환 오류}

DFM과 DDFM 모형의 nowcasting 백테스트 실험이 모든 시점(2024-01 ~ 2025-10, 22개월)에서 실패함:

\textbf{문제 원인:}
\begin{itemize}
    \item CUDA 텐서 변환 오류: 예측값이 CUDA 디바이스에 있는 텐서인데, 이를 numpy 배열로 변환할 때 CPU로 먼저 이동하지 않아 오류 발생
    \item 오류 메시지: "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
    \item 영향 범위: 모든 DFM/DDFM 백테스트 결과(6개 JSON 파일 × 22개월 = 132개 예측)가 실패. 각 JSON 파일은 22개월에 대한 결과를 포함하며, 모든 결과가 "status": "failed"로 표시됨.
    \item 기술적 배경: PyTorch 텐서는 기본적으로 CPU 또는 CUDA 디바이스에 상주하며, numpy 배열로 변환하기 전에 CPU로 이동해야 함. CUDA 텐서를 직접 numpy로 변환하려고 시도하면 메모리 접근 오류가 발생함.
\end{itemize}

\textbf{해결 방법:}
\begin{itemize}
    \item 예측값 변환 함수들에서 CUDA 텐서를 CPU로 이동한 후 numpy 배열로 변환하도록 수정
    \item 수정된 파일: \texttt{src/models/models\_utils.py} (함수: \texttt{\_convert\_predictions\_to\_dataframe}, \texttt{\_validate\_predictions}), \texttt{src/evaluation/evaluation\_forecaster.py} (예측값 추출 로직), \texttt{src/evaluation/evaluation\_metrics.py} (메트릭 계산 로직)
    \item 모든 텐서 변환 코드에서 \texttt{.cpu().numpy()} 패턴 적용. 이는 텐서를 CPU로 이동한 후 numpy 배열로 변환하는 표준 패턴임.
\end{itemize}

\textbf{현재 상태:} 코드 수정 완료. 모든 텐서 변환 코드가 \texttt{.cpu().numpy()} 패턴을 사용하도록 수정되었으며, 코드 검증을 통해 수정 사항이 올바르게 적용되었음을 확인함. 현재 \texttt{checkpoint/} 디렉토리에는 12개의 모델 파일이 존재하므로, 모델 훈련 없이 바로 백테스트를 재실행할 수 있음. 현재 코드에는 최신 DDFM 개선사항(더 깊은 인코더, tanh 활성화 함수, 가중치 감쇠, 증가된 사전 훈련, 배치 크기 최적화 등)이 구현되어 있으며, 훈련된 모델에 이러한 개선사항이 반영되었을 것으로 예상됨. Forecasting과 nowcasting 실험을 재실행하면 정상적으로 수행될 것으로 예상됨.

\subsection{실험 설계의 제한사항}

\begin{itemize}
    \item \textbf{훈련-예측 간격:} 4년 간격으로 COVID-19 제외 및 데이터 누수 방지, 그러나 최신 경제 패턴 반영 제한
    \item \textbf{테스트 데이터 부족:} 80/20 분할 후 각 시점당 단일 테스트 포인트 $\to$ 통계적 신뢰성 제한
    \item \textbf{Nowcasting 제한:} Release date 정보 정확성, ARIMA/VAR은 구조적 한계로 인해 nowcasting 실험에서 제외
\end{itemize}

\subsection{결과 검증 및 재현성}

본 연구의 모든 예측 결과는 다음과 같은 검증 과정을 거쳤음:

\begin{itemize}
    \item \textbf{시점 계산 검증:} 예측 시점 계산 로직을 검증하여 예측값이 올바른 테스트 시점과 비교되도록 보장함. 초기 구현에서 발견된 1개월 오프셋 버그를 수정하여, 예측값이 정확히 해당 시점의 실제값과 비교되도록 함
    \item \textbf{모델 예측 검증:} VAR, DFM, DDFM 모델이 정상적으로 예측을 생성하는지 검증함. DFM과 DDFM 모델의 경우 초기 구현에서 발견된 import 오류를 수정하여 모든 시점에서 유효한 예측값을 생성하도록 함. ARIMA는 세 대상 변수 모두에서 유효한 결과를 생성하지 못하여 검증 대상에서 제외됨
    \item \textbf{결과 완전성:} VAR은 3개 대상 변수 모두에서 완전한 결과를 생성함(66개 결과 포인트). DFM과 DDFM은 KOIPALL.G와 KOWRCCNSE에서 완전한 결과를 생성했으나, KOEQUIPTE에서는 22개월 시점이 누락되어 21개 시점에 대한 결과만 생성됨. ARIMA는 세 대상 변수 모두에서 유효한 결과(n\_valid=0)가 없어 평가에 실패함. 전체적으로 3개 대상 변수 × 4개 모델 × 22개 시점 = 264개 결과 포인트 중 약 73\% (VAR: 66개 완료, DFM: 64개 완료, DDFM: 64개 완료, ARIMA: 0개 완료, 총 194개)가 유효한 값을 가짐
    \item \textbf{재현성:} 모든 실험은 저장된 체크포인트를 사용하여 재현 가능하며, 동일한 설정으로 실행 시 동일한 결과를 보장함
\end{itemize}

\subsection{ARIMA 모형 평가 실패 원인 분석}

ARIMA 모형은 세 대상 변수 모두에서 유효한 결과(n\_valid=0)를 생성하지 못하여 평가에 실패함. 이는 다음과 같은 원인들이 있을 수 있음:

\textbf{가능한 원인:}
\begin{itemize}
    \item \textbf{모형 훈련 실패:} ARIMA 모형의 파라미터 추정 과정에서 수렴 실패 또는 수치적 불안정성
    \item \textbf{데이터 전처리 문제:} 결측치 처리, 변환, 또는 인덱스 정렬 과정에서의 오류
    \item \textbf{예측 생성 오류:} 예측값 생성 과정에서 shape mismatch, 인덱스 불일치, 또는 변환 오류
    \item \textbf{모형 적합성 문제:} ARIMA(1,1,1) 모형이 세 대상 변수 모두에 부적합할 가능성
\end{itemize}

\textbf{향후 조사 방향:}
\begin{itemize}
    \item ARIMA 훈련 로그를 확인하여 훈련 과정에서의 오류 파악
    \item ARIMA 모형 인스턴스화 및 적합 과정 검증
    \item 예측값 생성 코드에서 shape 및 인덱스 정렬 확인
    \item 데이터 호환성 검증 (결측치 처리, 변환 적용 여부)
    \item 자동 차수 선택(auto\_arima) 또는 다른 ARIMA 파라미터 조합 시도
\end{itemize}

\textbf{현재 상태:} ARIMA는 forecasting 결과 비교에 포함할 수 없으며, 향후 연구에서 문제를 해결하여 벤치마크 모형으로 포함해야 함.

\subsection{스케일 일치성 검증}

DFM/DDFM 모델의 예측값이 원본 스케일로 변환되는지 확인하기 위해 다음과 같은 검증을 수행함:

\textbf{1. 전처리 파이프라인 확인:}
\begin{itemize}
    \item DFM/DDFM 훈련 시 \texttt{\_create\_preprocessing\_pipeline} 함수 사용
    \item 이 함수는 imputation과 scaling만 수행하며, transformation (log, pch 등)은 포함하지 않음
    \item 따라서 모델은 원본 스케일 데이터로 훈련됨
\end{itemize}

\textbf{2. 예측값 스케일 확인:}
\begin{itemize}
    \item DFM/DDFM 예측값은 $X_{\text{forecast}} = X_{\text{std}} \times W_x + M_x$ 공식으로 계산됨
    \item 이는 unstandardization만 수행하며, transformation은 되돌리지 않음
    \item 하지만 transformation이 적용되지 않았으므로, 예측값은 원본 스케일임
\end{itemize}

\textbf{3. 테스트 데이터 스케일 확인:}
\begin{itemize}
    \item 테스트 데이터는 \texttt{resample\_to\_monthly}만 적용되어 원본 스케일임
    \item Transformation이 적용되지 않음
\end{itemize}

\textbf{결론:} 현재 코드 구조에서는 예측값과 실제값이 모두 원본 스케일이므로 스케일 일치함. 다만, 만약 \texttt{create\_transformer\_from\_config}를 사용하여 transformation이 적용되는 경우, 예측값은 transformed 스케일이 되고 실제값은 원본 스케일이 되어 스케일 불일치가 발생할 수 있음. 현재 평가 코드는 \texttt{DFMForecaster}/\texttt{DDFMForecaster}를 사용하며, 이들은 \texttt{\_create\_preprocessing\_pipeline}을 사용하므로 문제 없음.

\subsection{향후 연구 방향}

\begin{itemize}
    \item \textbf{모형 개선:} Robust Kalman filter, adaptive state space dimension
    \item \textbf{실험 설계 개선:} 롤링 윈도우 평가, 교차 검증
    \item \textbf{Release date 마스킹 개선}
    \item \textbf{추가 모형 비교}
\end{itemize}
