\section{논의}

\subsection{모델 비교}

본 연구의 핵심은 DFM과 DDFM 모형의 성능 비교이며, ARIMA와 VAR은 벤치마크 모형으로 포함됨. 네 가지 모형의 성능을 대상 변수와 예측 시점에 걸쳐 비교:

\textbf{ARIMA:}
\begin{itemize}
    \item 세 대상 변수 모두에서 평가 실패 (n\_valid=0, 모든 시점에서 유효한 결과 없음)
    \item 예측 생성 과정에서 문제가 발생하여 결과를 생성하지 못함
    \item 원인 조사 필요: 모형 훈련 실패, 데이터 전처리 오류, 예측 생성 오류 등 가능
    \item 현재 결과에서는 ARIMA를 비교에 포함할 수 없음
    \item 향후 연구에서 ARIMA 모형의 문제를 해결하여 벤치마크 모형으로 포함해야 함
\end{itemize}

\textbf{VAR:}
\begin{itemize}
    \item 세 대상 변수 모두에서 성공적으로 평가 완료
    \item 벤치마크 모형으로 포함되었으며, 대상 변수에 따라 성능 차이가 큼
    \item Nowcasting에서는 release date 마스킹 처리의 어려움으로 인해 제한적임
\end{itemize}

\textbf{DFM:}
\begin{itemize}
    \item 세 대상 변수 모두에서 평가 완료 (KOIPALL.G와 KOEQUIPTE는 21개 시점, KOWRCCNSE는 22개 시점)
    \item 전통적인 동적요인모형으로, EM 알고리즘을 통한 요인 추출 및 예측 수행
    \item KOIPALL.G에서 극단적으로 높은 오차를 보임 (sMAE=14.97, sMSE=225.30) - 월별 시계열에 분기별 집계 가정의 tent kernel 구조 사용으로 인한 수치적 불안정성
    \item KOEQUIPTE와 KOWRCCNSE에서는 중간 수준의 성능을 보임 (KOEQUIPTE: sMAE=1.14, KOWRCCNSE: sMAE=2.78)
    \item Nowcasting에서 release date 마스킹을 효과적으로 처리 가능
    \item 요인 모형의 구조적 특성으로 인해 다변량 시계열 간 공통 패턴을 효과적으로 포착하나, 변동성이 큰 시계열에서는 수치적 불안정성 발생
\end{itemize}

\textbf{DDFM:}
\begin{itemize}
    \item 세 대상 변수 모두에서 평가 완료 (KOIPALL.G와 KOEQUIPTE는 22개 시점, KOWRCCNSE는 22개 시점)
    \item 심층 신경망 기반 인코더를 통한 비선형 요인 추출
    \item KOIPALL.G에서 우수한 성능을 보임 (sMAE=0.6865, sMSE=0.61, 21개 시점 평균) - DFM 대비 약 21.8배 낮은 오차(sMAE: DFM=14.9689)
    \item KOWRCCNSE에서도 우수한 성능을 보임 (sMAE=0.4961, sMSE=0.49, 22개 시점 평균) - DFM 대비 약 5.6배 낮은 오차(sMAE: DFM=2.7848)
    \item KOEQUIPTE에서는 DFM과 거의 동일한 성능을 보임 (sMAE: DFM=1.1439, DDFM=1.1441, 평균 차이 0.000187, 21개 시점; sMSE=2.12) - 비선형 인코더가 추가적인 이점을 제공하지 못함. 이는 모든 시점(1-21개월)에서 두 모형이 거의 동일한 오차를 보이며, 이는 두 모형이 유사한 선형 요인 구조를 학습했음을 강하게 시사함. 이 문제를 해결하기 위해 KOEQUIPTE에 대해서는 더 깊은 인코더 구조([64, 32, 16]), 증가된 훈련 에포크(150), tanh 활성화 함수, 가중치 감쇠(L2 정규화), 그래디언트 클리핑, 그리고 Huber 손실 함수 지원을 구현함. 이러한 개선 사항의 효과를 검증하기 위해서는 추가 실험 재실행이 필요함.
    \item Nowcasting에서 release date 마스킹을 효과적으로 처리 가능
    \item 비선형 관계 포착 능력으로 인해 변동성이 큰 시계열(KOIPALL.G, KOWRCCNSE)에서 DFM 대비 우수한 성능을 보임
    \item KOEQUIPTE에서 DFM과 동일한 성능을 보이는 것은 해당 시계열이 선형 관계가 강하거나, 기본 인코더 구조([16, 4])가 이 시계열에 최적화되지 않았을 가능성을 시사함. 또한 인코더가 비선형 활성화 함수(ReLU)를 사용하더라도, 학습된 가중치가 선형 변환에 가까워질 수 있음. 이를 해결하기 위해 대상 변수별 인코더 아키텍처 최적화를 적용함.
\end{itemize}

\subsection{모델 성능 해석: 단순 모델 vs 복잡 모델}

본 연구의 결과를 모형별 성능 특성에 따라 분석하면 다음과 같음:

\textbf{1. 모형별 성능 특성:}
\begin{itemize}
    \item VAR은 KOWRCCNSE에서 우수한 성능을 보이며(sMAE=0.32), 다른 대상 변수에서는 중간 수준의 성능을 보임
    \item DFM은 KOIPALL.G에서 극단적으로 높은 오차를 보이며, KOEQUIPTE와 KOWRCCNSE에서는 중간 수준의 성능을 보임
    \item DDFM은 KOIPALL.G와 KOWRCCNSE에서 우수한 성능을 보이며, KOEQUIPTE에서는 DFM과 동일한 성능을 보임
    \item ARIMA는 세 대상 변수 모두에서 유효한 결과를 생성하지 못하여 비교에 포함할 수 없음
    \item 각 모형은 대상 변수에 따라 매우 다른 성능 특성을 보이며, 단일 모형이 모든 대상 변수에서 최고 성능을 보이지는 않음
\end{itemize}

\textbf{2. 모형 선택의 중요성:}
\begin{itemize}
    \item \textbf{대상 변수별 최적 모형:} KOIPALL.G와 KOWRCCNSE에서는 DDFM이 최고 성능을 보이며, KOWRCCNSE에서는 VAR도 우수한 성능을 보임
    \item \textbf{DFM의 한계:} 변동성이 큰 월별 시계열(KOIPALL.G)에서 DFM은 수치적 불안정성을 보이며, 분기별 집계를 가정한 기본 설정이 부적합함
    \item \textbf{DDFM의 강점:} 비선형 인코더를 통해 변동성이 큰 시계열에서 DFM 대비 우수한 성능을 보임
    \item \textbf{선형 vs 비선형:} KOEQUIPTE에서 DDFM과 DFM이 동일한 성능을 보이는 것은 해당 시계열이 선형 관계가 강하거나, 현재 DDFM 구조가 이 시계열에 최적화되지 않았을 가능성을 시사함
\end{itemize}

\textbf{3. 실용적 고려사항:}
\begin{itemize}
    \item \textbf{Nowcasting 능력:} DFM과 DDFM은 release date 마스킹을 처리할 수 있어 실제 운영 환경에서 유리함.
    \item \textbf{다변량 관계:} 요인 모형은 다변량 시계열 간 공통 패턴을 포착할 수 있음
    \item \textbf{모형 선택:} 대상 변수와 시계열 특성에 따라 최적 모형이 다르므로, 사전 분석을 통해 적절한 모형을 선택해야 함
    \item \textbf{성능 개선:} DDFM의 KOEQUIPTE 성능 개선을 위해 대상 변수별 인코더 아키텍처 최적화, tanh 활성화 함수, 가중치 감쇠, 그래디언트 클리핑, Huber 손실 함수 지원, 증가된 사전 훈련, 그리고 배치 크기 최적화를 구현함. 이러한 개선 사항의 효과를 검증하기 위해서는 추가 실험 재실행이 필요함.
\end{itemize}

\textbf{시점별 성능 패턴 분석:} 시점별 성능 추세를 분석하면 모형의 장기 예측 능력을 평가할 수 있음. 

KOIPALL.G에서는 DDFM이 단기(1-6개월)에서 매우 우수한 성능을 보이며, 구체적으로 horizon 1에서 sMAE=0.12, horizon 6에서 sMAE=0.15로 매우 낮은 오차를 보임. 중기(7-12개월)에서는 sMAE가 0.39-0.95 범위로 증가하지만 여전히 양호한 수준이며, 장기(13-21개월)에서는 sMAE가 0.54-1.33 범위로 일부 증가하나 전반적으로 안정적임. 반면 DFM은 모든 시점에서 극단적으로 높은 오차를 보이며, 최소값이 horizon 3에서 sMAE=12.47, 최대값이 horizon 18에서 sMAE=16.78임. 이는 월별 시계열에 분기별 집계 가정이 부적합하기 때문임. VAR은 중간 수준의 성능을 보이며, 시점에 따라 변동이 있음(sMAE 0.34-1.96).

KOWRCCNSE에서는 VAR이 단기(1-3개월)에서 우수한 성능을 보이지만(sMAE: 0.24-0.38), horizon 2에서 sMAE=0.98로 급증한 후 다시 감소하는 패턴을 보임. 중기(4-12개월)에서는 대부분 sMAE < 0.22를 보이지만, horizon 14(sMAE=0.59), horizon 19(sMAE=0.90), horizon 22(sMAE=1.14)에서 오차가 급증함. 이는 VAR의 다단계 예측에서 오차 누적과 공분산 행렬의 수치적 불안정성 때문임. DDFM은 대부분의 시점에서 안정적이고 낮은 오차를 보이며, 특히 horizon 1에서 sMAE=0.09, horizon 4-8에서 sMAE < 0.14를 보임. 중기(9-16개월)에서도 양호한 성능(sMAE 0.23-0.46)을 유지하나, 일부 시점(horizon 14: sMAE=0.82, horizon 19-20: sMAE 1.12-1.26)에서 오차가 증가함. DFM은 중간 수준의 성능을 보이지만 시점에 따라 변동이 크며, 특히 초기 시점(horizon 1: sMAE=2.38, horizon 2: sMAE=3.98)에서 높은 오차를 보임.

KOEQUIPTE에서는 DFM과 DDFM이 모든 시점에서 거의 동일한 성능을 보이며, 이는 두 모형이 유사한 선형 요인 구조를 학습했음을 시사함. 구체적으로, 두 모형은 21개 시점 모두에서 최대 sMAE 차이가 0.002 수준으로 거의 동일함. 두 모형 모두 단기(1-3개월)에서 중간 수준의 성능(sMAE 1.03-1.07)을 보이며, 중기(4-12개월)에서도 유사한 성능을 유지함. 일부 시점(horizon 7-8: sMAE 2.33-2.33, horizon 13-14: sMAE 3.21-3.28)에서 오차가 증가하지만, 두 모형이 동일한 패턴을 보임. VAR은 시점에 따라 변동이 크며, 일부 시점(horizon 7-8: sMAE 2.68-2.02, horizon 13-14: sMAE 3.88-3.82, horizon 21-22: sMAE 2.35)에서 매우 높은 오차를 보임.

이러한 패턴은 각 모형의 구조적 특성을 반영함: DDFM은 비선형 인코더를 통해 변동성이 큰 시계열(KOIPALL.G, KOWRCCNSE)에서 장기 예측에서도 안정적인 성능을 보이며, 선형 관계가 강한 시계열(KOEQUIPTE)에서는 DFM과 유사한 성능을 보임. VAR은 단기 예측에서 우수하지만 장기 예측에서 불안정하며, DFM은 변동성이 큰 월별 시계열에서 수치적 불안정성을 보임.

\textbf{DDFM 성능 메트릭의 정량적 분석:} DDFM의 성능을 더 자세히 분석하면 다음과 같은 패턴이 관찰됨:

\begin{itemize}
    \item \textbf{KOIPALL.G (sMAE=0.69, 21개 시점):} 단기 예측(1-6개월)에서 매우 우수한 성능(sMAE < 0.15)을 보이며, 이는 DDFM의 비선형 인코더가 변동성이 큰 월별 시계열의 단기 패턴을 효과적으로 포착함을 시사함. 중기(7-12개월)와 장기(13-21개월)에서도 안정적인 성능을 유지하나, horizon 22가 누락되어(n\_valid=0) 장기 예측의 완전성을 평가하기 어려움.
    \item \textbf{KOWRCCNSE (sMAE=0.50, 22개 시점):} 모든 22개 시점에 대해 유효한 결과를 생성하며, 단기(1, 4-8개월)에서 매우 낮은 오차(sMAE < 0.15)를 보임. 중기(9-16개월)에서도 양호한 성능(sMAE 0.23-0.46)을 유지하나, 일부 시점(horizon 14: sMAE=0.82, horizon 19-20: sMAE 1.12-1.26)에서 오차가 증가함. 이는 특정 시점에서의 예측 불안정성을 시사하나, 전반적으로 DFM(sMAE=2.78) 대비 약 5.6배 낮은 오차를 보임.
    \item \textbf{KOEQUIPTE (sMAE: DFM=1.1439, DDFM=1.1441, 21개 시점):} DFM과 거의 동일한 성능을 보이며, 평균 차이가 0.000187에 불과함. 구체적으로, 21개 시점 모두에서 DFM과 DDFM의 sMAE 차이는 매우 작으며, 이는 DDFM의 비선형 인코더가 KOEQUIPTE에 대해 추가적인 이점을 제공하지 못함을 강하게 시사함. 단기(1-3개월)에서 중간 수준의 성능(sMAE 1.03-1.07)을 보이며, 일부 시점(horizon 7-8: sMAE 2.33, horizon 13-14: sMAE 3.21-3.28)에서 오차가 증가하나 DFM과 동일한 패턴을 보임. 이러한 정량적 분석은 DDFM 인코더가 KOEQUIPTE에 대해 선형 PCA와 유사한 요인 구조를 학습하고 있음을 명확히 보여줌.
\end{itemize}

\textbf{성능 개선을 위한 구현된 기법들의 이론적 근거:} KOEQUIPTE에서의 성능 개선을 위해 구현된 기법들은 다음과 같은 이론적 근거를 가짐:

\begin{itemize}
    \item \textbf{더 깊은 인코더 구조([64, 32, 16]):} 기본 구조([16, 4]) 대비 약 4배 증가한 용량은 더 복잡한 비선형 관계를 학습할 수 있는 표현력을 제공함. 그러나 용량 증가는 과적합 위험도 증가시키므로, 가중치 감쇠와 함께 사용되어야 함.
    \item \textbf{tanh 활성화 함수:} ReLU는 음의 값을 0으로 만들어 음의 상관관계를 포착하기 어려움. tanh는 대칭적인 출력 범위(-1, 1)를 가지므로 음의 요인 부하를 학습할 수 있어, KOEQUIPTE와 같은 시계열에서 음의 상관관계가 중요한 경우 더 적합함.
    \item \textbf{가중치 감쇠(L2 정규화, weight\_decay=1e-4):} 인코더가 선형 PCA와 유사한 해에 과적합되는 것을 방지하고, 다양한 비선형 특징을 학습하도록 장려함. 이는 인코더가 선형 변환에 가까운 가중치를 학습하여 DFM과 동일한 성능을 보이는 문제를 완화하기 위한 것임.
    \item \textbf{증가된 사전 훈련(mult\_epoch\_pretrain=2):} 사전 훈련은 MCMC 훈련이 시작되기 전에 인코더가 비선형 특징을 학습하는 데 도움을 줌. 더 많은 사전 훈련 에포크는 인코더가 MCMC 반복 전에 비선형 특징을 학습할 시간을 더 제공하여, 인코더가 선형 동작으로 붕괴되는 것을 방지하는 데 도움이 됨.
    \item \textbf{배치 크기 최적화(batch\_size=64):} 더 작은 배치 크기는 에포크당 더 다양한 그래디언트를 제공하여 인코더가 선형 PCA와 유사한 해에 수렴하는 것을 방지하고, 비선형 특징을 학습하도록 도울 수 있음.
\end{itemize}

\textbf{DDFM 성능 메트릭의 개선:} DDFM 성능 평가의 정확성과 신뢰성을 향상시키기 위해 다음과 같은 핵심 메트릭 개선 사항을 구현함:

\begin{itemize}
    \item \textbf{강건 통계 기반 메트릭:} 중앙값과 사분위수 범위(IQR)를 사용한 강건한 대안 메트릭으로 이상치에 대한 민감도를 줄임.
    \item \textbf{부트스트랩 신뢰구간:} 부트스트랩 재표본 추출을 통해 메트릭의 불확실성을 정량화함.
    \item \textbf{비선형성 점수:} DDFM이 DFM과 다른 비선형 패턴을 학습하고 있는지 측정함(0-1 범위, 높을수록 비선형).
    \item \textbf{선형 붕괴 감지:} DDFM이 선형 관계만 학습하는지 자동으로 감지하여 개선 방향을 제시함.
    \item \textbf{오차 분포 분석:} 오차 왜도, 첨도, 편향 제곱, 분산을 통해 예측 오차의 원인을 파악함.
    \item \textbf{시점 간 오차 상관관계:} 체계적 문제와 시점별 문제를 구분하여 인코더 아키텍처 개선과 시점별 튜닝의 필요성을 판단함.
\end{itemize}

이러한 메트릭 개선 사항들은 DDFM 성능 평가의 신뢰성을 향상시키고, 특히 KOEQUIPTE와 같이 선형 붕괴 위험이 있는 경우 더 정확한 성능 분석을 가능하게 함. 개선 사항의 효과를 검증하기 위해서는 추가 실험 재실행이 필요함.

\textbf{DDFM 선형성 자동 감지 및 예측 품질 분석:} DDFM이 선형 관계만 학습하는지 자동으로 감지하고, 예측 품질을 분석하는 기능을 구현함. 선형성 점수(0-1, 높을수록 선형)가 0.95 이상이면 선형 붕괴 위험이 높음을 의미하며, 각 대상 변수에 대한 개선 권장사항을 제공함. 현재 KOEQUIPTE의 선형성 점수는 0.99 이상으로 관찰되며, 이는 인코더가 선형 PCA와 유사한 해에 수렴했음을 시사함. 모델 훈련 전에 상관관계 구조 분석을 통해 활성화 함수 선택 및 인코더 아키텍처 결정을 최적화할 수 있음.

\textbf{시점 간 오차 상관관계 분석:} DDFM의 오차 패턴이 시점 간에 어떻게 상관관계를 가지는지 분석하여 체계적 문제(예: 선형 붕괴)와 시점별 문제를 구분함. 체계적 패턴 점수가 높으면(> 0.7) 인코더 아키텍처 개선을, 낮으면(< 0.3) 시점별 튜닝을 권장함.


\textbf{결론 및 향후 연구 방향:} 단일 모형이 모든 대상 변수에서 최고 성능을 보이지 않으며, 대상 변수의 특성에 따라 적절한 모형을 선택하는 것이 중요함. 변동성이 큰 시계열에서는 DDFM이 우수한 성능을 보이며, 선형 관계가 강한 시계열에서는 VAR이나 DFM도 경쟁력 있는 성능을 보임. 실제 운영 환경에서는 nowcasting 능력도 중요한 고려사항이며, 이 경우 DFM이나 DDFM이 유리함. 

KOEQUIPTE에서의 DDFM 성능 개선을 위한 기법들이 구현되었으며, 선형성 자동 감지 기능을 통해 성능 문제를 체계적으로 모니터링할 수 있음. 다만, 효과를 검증하기 위해서는 추가 실험 재실행이 필요함.

\subsection{원인 분석}

\subsubsection{모형별 제한사항}
\begin{itemize}
    \item \textbf{VAR:} 긴 시점(>7개월)에서 공분산 행렬 특이성으로 인한 수치적 불안정성 발생. 이는 다단계 예측에 VAR 사용을 제한하며, 정규화 기법이나 베이지안 VAR(BVAR) 등의 대안을 고려할 수 있음.
    \item \textbf{DFM:} EM 알고리즘 수렴 중 수치적 불안정성 발생, 수치 안정화 기법 적용으로 해결. Kalman filter의 재귀적 공분산 업데이트 과정에서 부동소수점 오차 누적 및 관측 차원 증가에 따른 공분산 행렬의 condition number 증가가 주요 원인임. Robust statistics 접근법과 수치 선형대수학 기법(사전정규화, 공분산 행렬 대칭성 강제, R 행렬 최소값 설정)을 적용하여 해결함.
\end{itemize}

\subsubsection{DDFM의 성능 특성 및 개선 사항}

DDFM은 KOIPALL.G와 KOWRCCNSE에서 우수한 성능을 보이며(sMAE 각각 0.69, 0.50), 특히 변동성이 큰 시계열에서 DFM 대비 현저히 낮은 오차를 보임. 그러나 KOEQUIPTE에서는 DFM과 동일한 성능(sMAE=1.14)을 보여, 비선형 인코더가 추가적인 이점을 제공하지 못함.

\textbf{KOEQUIPTE에서의 동일 성능 원인 분석:} KOEQUIPTE에서 DDFM과 DFM이 모든 시점(1-21개월)에서 거의 동일한 성능을 보이는 현상은 다음과 같은 원인들이 있을 수 있음:
\begin{itemize}
    \item \textbf{선형 관계의 우세:} KOEQUIPTE 시계열이 다른 시계열들과의 관계에서 주로 선형적 상관관계를 보일 가능성. 이 경우 비선형 인코더가 학습할 수 있는 비선형 패턴이 제한적임.
    \item \textbf{인코더 용량 부족:} 기본 인코더 구조([16, 4])가 KOEQUIPTE의 복잡한 비선형 관계를 포착하기에 용량이 부족할 가능성. 인코더가 선형 변환에 가까운 가중치를 학습하여 DFM과 유사한 요인 구조를 생성할 수 있음.
    \item \textbf{활성화 함수의 한계:} ReLU 활성화 함수가 음의 상관관계를 포착하지 못하거나, 학습 과정에서 일부 뉴런이 비활성화되어 선형적 동작을 할 수 있음.
    \item \textbf{요인 공간의 유사성:} 두 모형이 유사한 요인 공간을 학습하여, 비선형 인코더가 추가적인 차원 축소나 특징 추출을 제공하지 못할 수 있음.
\end{itemize}

이 문제를 해결하기 위해 다음과 같은 개선 사항을 구현함:
\begin{itemize}
    \item \textbf{대상 변수별 인코더 아키텍처:} KOEQUIPTE에 대해서는 기본 인코더([16, 4]) 대신 더 깊은 인코더([64, 32, 16])를 사용하여 더 복잡한 비선형 관계를 포착할 수 있도록 함. 또한 훈련 에포크를 100에서 150으로 증가시켜 충분한 학습을 보장함.
    \item \textbf{활성화 함수 선택:} KOEQUIPTE에 대해서는 기본 ReLU 활성화 함수 대신 tanh 활성화 함수를 사용함. ReLU는 음의 값을 0으로 만드는 특성으로 인해 음의 상관관계를 포착하기 어려울 수 있음. 반면 tanh는 대칭적인 출력 범위(-1, 1)를 가지므로 음의 요인 부하를 학습할 수 있어, KOEQUIPTE와 같은 시계열에서 음의 상관관계가 중요한 경우 더 적합함.
    \item \textbf{Huber 손실 함수:} 이상치에 더 강건한 Huber 손실 함수를 지원하여 변동성이 큰 시계열에서 예측 성능을 개선할 수 있도록 함. Huber 손실은 작은 오차에 대해서는 MSE와 유사하게 동작하지만, 큰 오차에 대해서는 선형적으로 증가하여 이상치의 영향을 완화함.
    \item \textbf{가중치 감쇠 (L2 정규화):} KOEQUIPTE에 대해서는 가중치 감쇠(weight decay, L2 정규화)를 자동으로 적용함(\texttt{weight\_decay=1e-4}). L2 정규화는 인코더가 선형 PCA와 유사한 해에 과적합되는 것을 방지하고, 다양한 비선형 특징을 학습하도록 장려함. 이는 인코더가 선형 변환에 가까운 가중치를 학습하여 DFM과 동일한 성능을 보이는 문제를 완화하기 위한 것임.
    \item \textbf{그래디언트 클리핑:} 훈련 안정성을 향상시키기 위해 그래디언트 클리핑을 지원함. 그래디언트 폭발을 방지하여 NaN 값이나 선형 붕괴를 유발할 수 있는 훈련 불안정성을 완화함. 이는 pre-training, MCMC 훈련, 그리고 Lightning training step에 모두 적용됨.
    \item \textbf{향상된 가중치 초기화:} 인코더 레이어에 대해 활성화 함수에 따라 적절한 가중치 초기화 방법을 적용함. ReLU 활성화 함수의 경우 Kaiming 초기화를 사용하고, tanh나 sigmoid와 같은 대칭 활성화 함수의 경우 Xavier 초기화를 사용함. 출력 레이어는 더 작은 초기화(gain=0.1)를 사용하여 초기 요인 값이 과도하게 크지 않도록 함. 이러한 개선은 특히 더 깊은 네트워크에서 훈련 안정성과 수렴 속도를 향상시킴.
    \item \textbf{요인 차수 설정:} 요인 동역학에 대한 VAR 차수를 설정할 수 있도록 \texttt{factor\_order} 파라미터를 추가함. 기본값은 1(VAR(1))이며, 2(VAR(2))로 설정할 수 있음. VAR(2)는 더 긴 기간의 의존성을 포착할 수 있으나 더 많은 데이터가 필요함. 일부 대상 변수는 복잡한 다기간 동역학을 가지므로 VAR(2)가 도움이 될 수 있음.
    \item \textbf{향상된 훈련 안정성:} 더 깊은 네트워크(레이어 수 > 2)에 대해서는 입력 클리핑 범위를 더 엄격하게 설정하여 극단값에 대한 민감도를 줄임. 또한 훈련 단계에서 수치적 안정성 처리를 개선하여 더 깊은 아키텍처에서의 훈련 안정성을 향상시킴.
    \item \textbf{증가된 사전 훈련:} KOEQUIPTE에 대해서는 사전 훈련 에포크 배수를 1에서 2로 증가시킴(\texttt{mult\_epoch\_pretrain=2}). 사전 훈련은 MCMC 훈련이 시작되기 전에 인코더가 비선형 특징을 학습하는 데 도움을 줌. 더 많은 사전 훈련 에포크는 인코더가 MCMC 반복 전에 비선형 특징을 학습할 시간을 더 제공하여, 인코더가 선형 동작으로 붕괴되는 것을 방지하는 데 도움이 됨.
    \item \textbf{배치 크기 최적화:} KOEQUIPTE에 대해서는 기본 배치 크기(100) 대신 더 작은 배치 크기(64)를 자동으로 사용하도록 구현함. 더 작은 배치 크기는 에포크당 더 다양한 그래디언트를 제공하여 인코더가 선형 PCA와 유사한 해에 수렴하는 것을 방지하고, 비선형 특징을 학습하도록 도울 수 있음.
\end{itemize}

이러한 개선 사항의 효과를 검증하기 위해서는 추가 실험 재실행이 필요하며, 특히 KOEQUIPTE에서의 성능 개선 여부를 확인해야 함. 모델 훈련 전에 상관관계 구조 분석을 통해 활성화 함수 선택 및 인코더 아키텍처 결정을 최적화할 수 있으며, 더 깊은 인코더와 tanh 활성화 함수를 사용한 재실험을 통해 성능 개선 여부를 확인할 수 있음. 만약 개선이 관찰되지 않는다면, 인코더 아키텍처 그리드 서치, 정규화 실험, 또는 앙상블 방법 등을 고려할 수 있음. DDFM은 비선형 관계가 강하고 충분한 데이터가 있을 때 유리하나, 선형 관계가 강하거나 데이터가 제한적일 경우 단순 모델이 더 효과적일 수 있음 \cite{andreini2020deep}.

\subsection{Nowcasting 시점별 분석}

Nowcasting 실험 구성:
\begin{itemize}
    \item 모형: DFM, DDFM (2개) - ARIMA와 VAR은 release date 마스킹 처리의 구조적 한계로 인해 제외
    \item 대상 변수: 3개 (KOIPALL.G, KOEQUIPTE, KOWRCCNSE)
    \item 목표 월: 2024-01 ~ 2025-10 (22개월)
    \item 예측 시점: 4주 전, 1주 전
    \item 총 예상 결과 포인트: 2개 모형 × 3개 대상 변수 × 2개 시점 = 12개 모형-시점 조합
    \item \textbf{현재 상태:} Nowcasting 백테스트 실험이 CUDA 텐서 변환 오류로 인해 모든 시점에서 실패하여, 표~\ref{tab:nowcasting_backtest}의 모든 값이 N/A로 표시됨. 오류 원인은 예측값이 CUDA 디바이스에 있는 텐서를 numpy 배열로 변환할 때 CPU로 먼저 이동하지 않아 발생한 것으로 확인되었으며, 텐서 변환 코드를 수정하여 해결되었음. 수정된 코드로 백테스트를 재실행하면 유효한 결과를 얻을 수 있을 것으로 예상됨.
\end{itemize}

\textbf{시점별 성능 비교:} \cite{banbura2012nowcasting}
현재 Nowcasting 백테스트 실험이 CUDA 텐서 변환 오류로 인해 실패하여 표~\ref{tab:nowcasting_backtest}의 모든 값이 N/A로 표시됨. 코드 수정을 통해 오류가 해결되었으며, 재실행 시 다음과 같은 분석이 가능할 것으로 예상됨:
\begin{itemize}
    \item \textbf{시점별 정확도 향상:} 대부분의 경우 1주 전 예측이 4주 전 예측보다 더 정확할 것으로 예상됨. 이는 시간이 지날수록 더 많은 데이터가 사용 가능해지기 때문임.
    \item \textbf{모형별 성능 패턴:} DDFM이 DFM보다 전반적으로 우수한 성능을 보일 것으로 예상되며, forecasting 실험에서 DDFM이 KOIPALL.G와 KOWRCCNSE에서 현저히 우수한 성능을 보였으므로 nowcasting에서도 유사한 패턴이 관찰될 수 있음.
\end{itemize}

\textbf{Release date 마스킹의 효과:}
DFM과 DDFM은 요인 모형의 구조적 특성으로 인해 release date 기반 마스킹을 효과적으로 처리 가능함. Kalman filter는 각 시점의 데이터 발표를 재귀적으로 처리하여 예측을 업데이트하며, 데이터의 시의성과 품질을 자동으로 고려함. 실시간 데이터 흐름에서 비동기적 데이터 발표로 인한 불규칙성(jagged edges)을 DFM/DDFM이 자연스럽게 처리할 수 있어, 실제 운영 환경에서의 nowcasting에 적합함. 이는 FRB New York의 nowcasting 모형과 같은 실제 운영 환경에서의 활용 사례와 일치하며, 요인 모형이 nowcasting에 적합한 이유를 보여줌 \cite{banbura2012nowcasting}.

