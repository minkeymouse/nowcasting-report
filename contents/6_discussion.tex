\section{논의}

\subsection{모델 비교}

네 가지 모형(ARIMA, VAR, DFM, DDFM)의 성능을 대상 변수와 예측 수평선에 걸쳐 비교:

\textbf{ARIMA:}
\begin{itemize}
    \item 세 대상 변수 모두에서 성공적으로 평가 완료
    \item 특징: 단순성, 해석 가능성, 안정적 성능
    \item 일부 수평선에서 우수한 성능을 보임 (예: KOEQUIPTE 3개월에서 최소 sMAE/sMSE)
    \item Nowcasting에서는 release date 마스킹 처리의 어려움으로 인해 제한적임
\end{itemize}

\textbf{VAR:}
\begin{itemize}
    \item 세 대상 변수 모두에서 성공적으로 평가 완료
    \item 제한: 다단계 예측에서 수치적 불안정성 문제 (이론적)
    \item 단기 수평선(1-2개월)에서 상대적으로 안정적인 성능을 보임
    \item Nowcasting에서는 release date 마스킹 처리의 어려움으로 인해 제한적임
\end{itemize}

\textbf{DFM:}
\begin{itemize}
    \item KOEQUIPTE: 1개월 sMAE = 0.7920, sMSE = 0.6272; 11개월 sMAE = 1.9887, sMSE = 3.9550; 22개월 sMAE = 0.1891, sMSE = 0.0358
    \item KOIPALL.G: 1개월 sMAE = 0.2301, sMSE = 0.0529; 11개월 sMAE = 0.9854, sMSE = 0.9710; 22개월 sMAE = 0.0137, sMSE = 0.0002
    \item KOWRCCNSE: 1개월 sMAE = 0.6003, sMSE = 0.3603; 11개월 sMAE = 0.1296, sMSE = 0.0168; 22개월 sMAE = 0.4937, sMSE = 0.2438
\end{itemize}

\textbf{DDFM:}
\begin{itemize}
    \item KOEQUIPTE: 1개월 sMAE = 0.7717, sMSE = 0.5956; 11개월 sMAE = 2.0090, sMSE = 4.0359; 22개월 sMAE = 0.1688, sMSE = 0.0285
    \item KOIPALL.G: 1개월 sMAE = 0.4414, sMSE = 0.1949; 11개월 sMAE = 0.3138, sMSE = 0.0985; 22개월 sMAE = 0.6579, sMSE = 0.4328
    \item KOWRCCNSE: 1개월 sMAE = 0.4529, sMSE = 0.2051; 11개월 sMAE = 0.0178, sMSE = 0.0003; 22개월 sMAE = 0.3464, sMSE = 0.1200
    \item 특징: KOWRCCNSE에서 11개월 수평선에서 가장 우수한 성능, KOIPALL.G에서는 DFM보다 높은 오차
\end{itemize}

\subsection{원인 분석}

\subsubsection{VAR의 수치적 불안정성}
\begin{itemize}
    \item 1개월 예측: 낮은 오차
    \item 긴 수평선: 공분산 행렬 특이성으로 인한 수치적 불안정성
    \item 원인: 재귀적 예측 과정에서 수치 오차 누적 및 증폭
\end{itemize}

\subsubsection{DFM의 EM 알고리즘 수렴 문제}
\begin{itemize}
    \item 원인: MATLAB/Python 구현 차이 (R 행렬 최소값, 대칭성 강제, 칼만 필터 재귀적 업데이트)
    \item 적용 기법: 사전정규화, R 행렬 최소값 $10^{-4}$ 강제, 공분산 행렬 대칭성 강제 \cite{golub2013matrix, higham2002computing}
\end{itemize}

\subsubsection{DDFM의 성능 특성 및 제한사항}

DDFM 성능 분석:
\begin{itemize}
    \item \textbf{중간 수평선에서의 우수성:} 11개월 수평선에서 가장 낮은 오차를 보임. 이는 딥러닝 인코더가 중기 예측에서 복잡한 패턴을 포착할 수 있음을 시사함
    \item \textbf{단기/장기 수평선에서의 제한:} 1개월과 22개월 수평선에서는 VAR, DFM, ARIMA보다 높은 오차를 보임
    \item \textbf{가능한 원인:}
    \begin{itemize}
        \item \textbf{데이터 양 부족:} 딥러닝 모델은 충분한 데이터가 필요하나, 훈련 기간(1985-2019)이 제한적일 수 있음
        \item \textbf{선형 관계:} 시계열이 선형적일 경우 비선형 인코더가 오히려 과도한 복잡성을 도입하여 일반화 성능 저하 가능 \cite{andreini2020deep}
        \item \textbf{하이퍼파라미터:} epochs=100, learning\_rate=0.005 등 설정이 최적이 아닐 수 있음
        \item \textbf{오버피팅:} 모델 복잡도에 비해 데이터가 부족하여 훈련 데이터에 과적합될 가능성
    \end{itemize}
\end{itemize}

\textbf{시사점:} DDFM은 비선형 관계가 강하고 충분한 데이터가 있을 때 유리하나, 선형 관계가 강하거나 데이터가 제한적일 경우 단순 모델(ARIMA, VAR, DFM)이 더 효과적일 수 있음.

\subsection{Nowcasting 시점별 분석}

Nowcasting 실험 구성:
\begin{itemize}
    \item 모형: ARIMA, VAR, DFM, DDFM (4개)
    \item 대상 변수: 3개
    \item 목표 월: 2024--01 ~ 2025--10 (22개월)
    \item 예측 시점: 4주 전, 1주 전
    \item 결과: 네 가지 모형(ARIMA, VAR, DFM, DDFM) 모두 forecasting 평가에서 성공적으로 결과를 생성했으며, nowcasting에서는 DFM과 DDFM이 모든 대상 변수에서 성공적이며 ARIMA와 VAR은 일부 제한이 있음
\end{itemize}

\textbf{예상 성능 향상:} \cite{banbura2012nowcasting}
\begin{itemize}
    \item 시간 경과에 따라 더 많은 데이터 사용 가능 $\to$ 예측 정확도 향상
    \item DFM/DDFM: 많은 시계열 활용, 요인 추출 $\to$ 데이터 증가 시 성능 향상 기대
    \item Release date 마스킹: DFM/DDFM에서 더 정확, ARIMA/VAR은 근사화 구현으로 제한
\end{itemize}

