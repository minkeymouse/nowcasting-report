\section{논의}

\subsection{모델 비교}

본 연구의 핵심은 DFM과 DDFM 모형의 성능 비교이며, ARIMA와 VAR은 벤치마크 모형으로 포함됨. 네 가지 모형의 성능을 대상 변수와 예측 시점에 걸쳐 비교:

\textbf{ARIMA:}
\begin{itemize}
    \item 세 대상 변수 모두에서 평가 실패 (n\_valid=0, 모든 시점에서 유효한 결과 없음)
    \item 예측 생성 과정에서 문제가 발생하여 결과를 생성하지 못함
    \item 원인 조사 필요: 모형 훈련 실패, 데이터 전처리 오류, 예측 생성 오류 등 가능
    \item 현재 결과에서는 ARIMA를 비교에 포함할 수 없음
    \item 향후 연구에서 ARIMA 모형의 문제를 해결하여 벤치마크 모형으로 포함해야 함
\end{itemize}

\textbf{VAR:}
\begin{itemize}
    \item 세 대상 변수 모두에서 성공적으로 평가 완료
    \item 벤치마크 모형으로 포함되었으며, 대상 변수에 따라 성능 차이가 큼
    \item Nowcasting에서는 release date 마스킹 처리의 어려움으로 인해 제한적임
\end{itemize}

\textbf{DFM:}
\begin{itemize}
    \item 세 대상 변수 모두에서 평가 완료 (KOIPALL.G와 KOEQUIPTE는 21개 시점, KOWRCCNSE는 22개 시점)
    \item 전통적인 동적요인모형으로, EM 알고리즘을 통한 요인 추출 및 예측 수행
    \item KOIPALL.G에서 극단적으로 높은 오차를 보임 (sMAE=14.97, sMSE=225.30) - 월별 시계열에 분기별 집계 가정의 tent kernel 구조 사용으로 인한 수치적 불안정성
    \item KOEQUIPTE와 KOWRCCNSE에서는 중간 수준의 성능을 보임 (KOEQUIPTE: sMAE=1.14, KOWRCCNSE: sMAE=2.78)
    \item Nowcasting에서 release date 마스킹을 효과적으로 처리 가능
    \item 요인 모형의 구조적 특성으로 인해 다변량 시계열 간 공통 패턴을 효과적으로 포착하나, 변동성이 큰 시계열에서는 수치적 불안정성 발생
\end{itemize}

\textbf{DDFM:}
\begin{itemize}
    \item 세 대상 변수 모두에서 평가 완료 (KOIPALL.G와 KOEQUIPTE는 22개 시점, KOWRCCNSE는 22개 시점)
    \item 심층 신경망 기반 인코더를 통한 비선형 요인 추출
    \item KOIPALL.G에서 우수한 성능을 보임 (sMAE=0.6865, sMSE=0.61, 21개 시점 평균) - DFM 대비 약 21.8배 낮은 오차(sMAE: DFM=14.9689)
    \item KOWRCCNSE에서도 우수한 성능을 보임 (sMAE=0.4961, sMSE=0.49, 22개 시점 평균) - DFM 대비 약 5.6배 낮은 오차(sMAE: DFM=2.7848)
    \item KOEQUIPTE에서는 DFM과 거의 동일한 성능을 보임 (sMAE: DFM=1.1439, DDFM=1.1441, 평균 차이 0.000187, 21개 시점; sMSE=2.12) - 비선형 인코더가 추가적인 이점을 제공하지 못함. 이는 모든 시점(1-21개월)에서 두 모형이 거의 동일한 오차를 보이며, 이는 두 모형이 유사한 선형 요인 구조를 학습했음을 강하게 시사함. 이 문제를 해결하기 위해 KOEQUIPTE에 대해서는 더 깊은 인코더 구조([64, 32, 16]), 증가된 훈련 에포크(150), tanh 활성화 함수, 가중치 감쇠(L2 정규화), 그래디언트 클리핑, 그리고 Huber 손실 함수 지원을 구현함. 이러한 개선 사항의 효과를 검증하기 위해서는 추가 실험 재실행이 필요함.
    \item Nowcasting에서 release date 마스킹을 효과적으로 처리 가능
    \item 비선형 관계 포착 능력으로 인해 변동성이 큰 시계열(KOIPALL.G, KOWRCCNSE)에서 DFM 대비 우수한 성능을 보임
    \item KOEQUIPTE에서 DFM과 동일한 성능을 보이는 것은 해당 시계열이 선형 관계가 강하거나, 기본 인코더 구조([16, 4])가 이 시계열에 최적화되지 않았을 가능성을 시사함. 또한 인코더가 비선형 활성화 함수(ReLU)를 사용하더라도, 학습된 가중치가 선형 변환에 가까워질 수 있음. 이를 해결하기 위해 대상 변수별 인코더 아키텍처 최적화를 적용함.
\end{itemize}

\subsection{모델 성능 해석: 단순 모델 vs 복잡 모델}

본 연구의 결과를 모형별 성능 특성에 따라 분석하면 다음과 같음:

\textbf{1. 모형별 성능 특성:}
\begin{itemize}
    \item VAR은 KOWRCCNSE에서 우수한 성능을 보이며(sMAE=0.32), 다른 대상 변수에서는 중간 수준의 성능을 보임
    \item DFM은 KOIPALL.G에서 극단적으로 높은 오차를 보이며, KOEQUIPTE와 KOWRCCNSE에서는 중간 수준의 성능을 보임
    \item DDFM은 KOIPALL.G와 KOWRCCNSE에서 우수한 성능을 보이며, KOEQUIPTE에서는 DFM과 동일한 성능을 보임
    \item ARIMA는 세 대상 변수 모두에서 유효한 결과를 생성하지 못하여 비교에 포함할 수 없음
    \item 각 모형은 대상 변수에 따라 매우 다른 성능 특성을 보이며, 단일 모형이 모든 대상 변수에서 최고 성능을 보이지는 않음
\end{itemize}

\textbf{2. 모형 선택의 중요성:}
\begin{itemize}
    \item \textbf{대상 변수별 최적 모형:} KOIPALL.G와 KOWRCCNSE에서는 DDFM이 최고 성능을 보이며, KOWRCCNSE에서는 VAR도 우수한 성능을 보임
    \item \textbf{DFM의 한계:} 변동성이 큰 월별 시계열(KOIPALL.G)에서 DFM은 수치적 불안정성을 보이며, 분기별 집계를 가정한 기본 설정이 부적합함
    \item \textbf{DDFM의 강점:} 비선형 인코더를 통해 변동성이 큰 시계열에서 DFM 대비 우수한 성능을 보임
    \item \textbf{선형 vs 비선형:} KOEQUIPTE에서 DDFM과 DFM이 동일한 성능을 보이는 것은 해당 시계열이 선형 관계가 강하거나, 현재 DDFM 구조가 이 시계열에 최적화되지 않았을 가능성을 시사함
\end{itemize}

\textbf{3. 실용적 고려사항:}
\begin{itemize}
    \item \textbf{Nowcasting 능력:} DFM과 DDFM은 release date 마스킹을 처리할 수 있어 실제 운영 환경에서 유리함. 다만, 현재 nowcasting 백테스트 실험이 CUDA 텐서 변환 오류로 인해 실패하였으며, 코드 수정은 완료되었음. 현재 \texttt{checkpoint/} 디렉토리에는 12개의 모델 파일이 존재하므로, 모델 훈련 없이 바로 백테스트를 재실행할 수 있음.
    \item \textbf{다변량 관계:} 요인 모형은 다변량 시계열 간 공통 패턴을 포착할 수 있음
    \item \textbf{모형 선택:} 대상 변수와 시계열 특성에 따라 최적 모형이 다르므로, 사전 분석을 통해 적절한 모형을 선택해야 함
    \item \textbf{성능 개선:} DDFM의 KOEQUIPTE 성능 개선을 위해 대상 변수별 인코더 아키텍처 최적화([64, 32, 16]), tanh 활성화 함수, 가중치 감쇠(L2 정규화), 그래디언트 클리핑, Huber 손실 함수 지원, 증가된 사전 훈련(\texttt{mult\_epoch\_pretrain=2}), 그리고 배치 크기 최적화(\texttt{batch\_size=64})를 구현함. 이러한 개선 사항의 효과를 검증하기 위해서는 추가 실험 재실행이 필요함.
\end{itemize}

\textbf{시점별 성능 패턴 분석:} 시점별 성능 추세를 분석하면 모형의 장기 예측 능력을 평가할 수 있음. 

KOIPALL.G에서는 DDFM이 단기(1-6개월)에서 매우 우수한 성능을 보이며, 구체적으로 horizon 1에서 sMAE=0.12, horizon 6에서 sMAE=0.15로 매우 낮은 오차를 보임. 중기(7-12개월)에서는 sMAE가 0.39-0.95 범위로 증가하지만 여전히 양호한 수준이며, 장기(13-21개월)에서는 sMAE가 0.54-1.33 범위로 일부 증가하나 전반적으로 안정적임. 반면 DFM은 모든 시점에서 극단적으로 높은 오차를 보이며, 최소값이 horizon 3에서 sMAE=12.47, 최대값이 horizon 18에서 sMAE=16.78임. 이는 월별 시계열에 분기별 집계 가정이 부적합하기 때문임. VAR은 중간 수준의 성능을 보이며, 시점에 따라 변동이 있음(sMAE 0.34-1.96).

KOWRCCNSE에서는 VAR이 단기(1-3개월)에서 우수한 성능을 보이지만(sMAE: 0.24-0.38), horizon 2에서 sMAE=0.98로 급증한 후 다시 감소하는 패턴을 보임. 중기(4-12개월)에서는 대부분 sMAE < 0.22를 보이지만, horizon 14(sMAE=0.59), horizon 19(sMAE=0.90), horizon 22(sMAE=1.14)에서 오차가 급증함. 이는 VAR의 다단계 예측에서 오차 누적과 공분산 행렬의 수치적 불안정성 때문임. DDFM은 대부분의 시점에서 안정적이고 낮은 오차를 보이며, 특히 horizon 1에서 sMAE=0.09, horizon 4-8에서 sMAE < 0.14를 보임. 중기(9-16개월)에서도 양호한 성능(sMAE 0.23-0.46)을 유지하나, 일부 시점(horizon 14: sMAE=0.82, horizon 19-20: sMAE 1.12-1.26)에서 오차가 증가함. DFM은 중간 수준의 성능을 보이지만 시점에 따라 변동이 크며, 특히 초기 시점(horizon 1: sMAE=2.38, horizon 2: sMAE=3.98)에서 높은 오차를 보임.

KOEQUIPTE에서는 DFM과 DDFM이 모든 시점에서 거의 동일한 성능을 보이며, 이는 두 모형이 유사한 선형 요인 구조를 학습했음을 시사함. 구체적으로, 두 모형은 21개 시점 모두에서 최대 sMAE 차이가 0.002 수준으로 거의 동일함. 두 모형 모두 단기(1-3개월)에서 중간 수준의 성능(sMAE 1.03-1.07)을 보이며, 중기(4-12개월)에서도 유사한 성능을 유지함. 일부 시점(horizon 7-8: sMAE 2.33-2.33, horizon 13-14: sMAE 3.21-3.28)에서 오차가 증가하지만, 두 모형이 동일한 패턴을 보임. VAR은 시점에 따라 변동이 크며, 일부 시점(horizon 7-8: sMAE 2.68-2.02, horizon 13-14: sMAE 3.88-3.82, horizon 21-22: sMAE 2.35)에서 매우 높은 오차를 보임.

이러한 패턴은 각 모형의 구조적 특성을 반영함: DDFM은 비선형 인코더를 통해 변동성이 큰 시계열(KOIPALL.G, KOWRCCNSE)에서 장기 예측에서도 안정적인 성능을 보이며, 선형 관계가 강한 시계열(KOEQUIPTE)에서는 DFM과 유사한 성능을 보임. VAR은 단기 예측에서 우수하지만 장기 예측에서 불안정하며, DFM은 변동성이 큰 월별 시계열에서 수치적 불안정성을 보임.

\textbf{DDFM 성능 메트릭의 정량적 분석:} DDFM의 성능을 더 자세히 분석하면 다음과 같은 패턴이 관찰됨:

\begin{itemize}
    \item \textbf{KOIPALL.G (sMAE=0.69, 21개 시점):} 단기 예측(1-6개월)에서 매우 우수한 성능(sMAE < 0.15)을 보이며, 이는 DDFM의 비선형 인코더가 변동성이 큰 월별 시계열의 단기 패턴을 효과적으로 포착함을 시사함. 중기(7-12개월)와 장기(13-21개월)에서도 안정적인 성능을 유지하나, horizon 22가 누락되어(n\_valid=0) 장기 예측의 완전성을 평가하기 어려움.
    \item \textbf{KOWRCCNSE (sMAE=0.50, 22개 시점):} 모든 22개 시점에 대해 유효한 결과를 생성하며, 단기(1, 4-8개월)에서 매우 낮은 오차(sMAE < 0.15)를 보임. 중기(9-16개월)에서도 양호한 성능(sMAE 0.23-0.46)을 유지하나, 일부 시점(horizon 14: sMAE=0.82, horizon 19-20: sMAE 1.12-1.26)에서 오차가 증가함. 이는 특정 시점에서의 예측 불안정성을 시사하나, 전반적으로 DFM(sMAE=2.78) 대비 약 5.6배 낮은 오차를 보임.
    \item \textbf{KOEQUIPTE (sMAE: DFM=1.1439, DDFM=1.1441, 21개 시점):} DFM과 거의 동일한 성능을 보이며, 평균 차이가 0.000187에 불과함. 구체적으로, 21개 시점 모두에서 DFM과 DDFM의 sMAE 차이는 매우 작으며, 이는 DDFM의 비선형 인코더가 KOEQUIPTE에 대해 추가적인 이점을 제공하지 못함을 강하게 시사함. 단기(1-3개월)에서 중간 수준의 성능(sMAE 1.03-1.07)을 보이며, 일부 시점(horizon 7-8: sMAE 2.33, horizon 13-14: sMAE 3.21-3.28)에서 오차가 증가하나 DFM과 동일한 패턴을 보임. 이러한 정량적 분석은 DDFM 인코더가 KOEQUIPTE에 대해 선형 PCA와 유사한 요인 구조를 학습하고 있음을 명확히 보여줌.
\end{itemize}

\textbf{성능 개선을 위한 구현된 기법들의 이론적 근거:} KOEQUIPTE에서의 성능 개선을 위해 구현된 기법들은 다음과 같은 이론적 근거를 가짐:

\begin{itemize}
    \item \textbf{더 깊은 인코더 구조([64, 32, 16]):} 기본 구조([16, 4]) 대비 약 4배 증가한 용량은 더 복잡한 비선형 관계를 학습할 수 있는 표현력을 제공함. 그러나 용량 증가는 과적합 위험도 증가시키므로, 가중치 감쇠와 함께 사용되어야 함.
    \item \textbf{tanh 활성화 함수:} ReLU는 음의 값을 0으로 만들어 음의 상관관계를 포착하기 어려움. tanh는 대칭적인 출력 범위(-1, 1)를 가지므로 음의 요인 부하를 학습할 수 있어, KOEQUIPTE와 같은 시계열에서 음의 상관관계가 중요한 경우 더 적합함.
    \item \textbf{가중치 감쇠(L2 정규화, weight\_decay=1e-4):} 인코더가 선형 PCA와 유사한 해에 과적합되는 것을 방지하고, 다양한 비선형 특징을 학습하도록 장려함. 이는 인코더가 선형 변환에 가까운 가중치를 학습하여 DFM과 동일한 성능을 보이는 문제를 완화하기 위한 것임.
    \item \textbf{증가된 사전 훈련(mult\_epoch\_pretrain=2):} 사전 훈련은 MCMC 훈련이 시작되기 전에 인코더가 비선형 특징을 학습하는 데 도움을 줌. 더 많은 사전 훈련 에포크는 인코더가 MCMC 반복 전에 비선형 특징을 학습할 시간을 더 제공하여, 인코더가 선형 동작으로 붕괴되는 것을 방지하는 데 도움이 됨.
    \item \textbf{배치 크기 최적화(batch\_size=64):} 더 작은 배치 크기는 에포크당 더 다양한 그래디언트를 제공하여 인코더가 선형 PCA와 유사한 해에 수렴하는 것을 방지하고, 비선형 특징을 학습하도록 도울 수 있음.
\end{itemize}

\textbf{DDFM 성능 메트릭의 개선:} DDFM 성능 평가의 정확성과 신뢰성을 향상시키기 위해 다음과 같은 메트릭 개선 사항을 구현함:

\begin{itemize}
    \item \textbf{강건 통계 기반 메트릭(robust statistics):} 평균 기반 메트릭은 이상치(outlier)에 민감하므로, 중앙값(median)과 사분위수 범위(IQR)를 사용한 강건한 대안 메트릭을 추가함. 이는 특정 시점에서의 수치적 불안정성이나 극단적 오차로 인한 왜곡을 줄임. 구체적으로, \texttt{calculate\_robust\_metrics()} 함수는 중앙값 기반의 sMAE, sMSE, sRMSE를 계산하며, IQR 기반 메트릭과 이상치 비율을 제공함.
    \item \textbf{부트스트랩 신뢰구간(bootstrap confidence intervals):} 부트스트랩 재표본 추출을 통해 메트릭의 불확실성을 정량화하는 신뢰구간을 계산함. 이를 통해 DDFM 성능 평가의 통계적 신뢰성을 향상시키고, 메트릭 간 비교 시 불확실성을 고려할 수 있음. \texttt{calculate\_bootstrap\_confidence\_intervals()} 함수는 기본적으로 1000회 재표본 추출을 수행하여 95\% 신뢰구간을 제공함.
    \item \textbf{요인 동역학 안정성 추론(factor dynamics stability inference):} VAR 요인 동역학의 안정성을 예측 패턴으로부터 추론하는 기능을 추가함. \texttt{calculate\_factor\_dynamics\_stability()} 함수는 시점별 예측값을 분석하여 진동, 지수적 성장/감쇠, 예측 평활도, 발산/수렴 패턴을 감지함. 이를 통해 VAR 전이 행렬의 고유값이 단위원 밖에 있거나 복소 고유값으로 인한 진동 행동을 간접적으로 평가할 수 있음. 이 메트릭은 요인 동역학의 수치적 불안정성을 조기에 감지하여 모델 개선 방향을 제시하는 데 도움을 줌. 이 기능은 \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합되어 자동으로 계산되며, 각 대상 변수에 대한 요인 동역학 안정성 점수, 진동 감지 여부, 평활도 점수, 발산/수렴 감지 여부를 제공함.
    \item \textbf{강건한 시점별 집계(robust horizon aggregation):} 여러 시점에 걸친 메트릭 집계 시 평균 대신 중앙값을 사용하는 옵션을 제공함. 이는 특정 문제가 있는 시점의 극단적 오차가 전체 성능 평가를 왜곡하는 것을 방지함. \texttt{aggregate\_robust\_metrics\_across\_horizons()} 함수는 중앙값 기반 집계와 IQR 통계를 제공함.
    \item \textbf{향상된 이상치 탐지:} IQR 방법을 사용한 이상치 탐지 기능을 추가하여, 특정 시점에서의 예측 불안정성을 자동으로 식별함. 이를 통해 DDFM 성능 분석 시 문제가 있는 시점을 사전에 식별할 수 있음.
    \item \textbf{비선형성 점수(nonlinearity score):} DDFM 예측이 얼마나 비선형적인지를 정량화하는 메트릭을 추가함. \texttt{calculate\_nonlinearity\_score()} 함수는 선형성 감지의 보완적 메트릭으로, DDFM이 DFM과 다른 비선형 패턴을 학습하고 있는지 긍정적으로 측정함(0-1 범위, 높을수록 비선형). 이 메트릭은 다음 세 가지 요소를 종합하여 계산됨:
    \begin{itemize}
        \item \textbf{패턴 발산도(pattern divergence):} DDFM과 DFM의 예측 패턴이 시점 간에 얼마나 다른지를 측정함. 낮은 상관관계는 높은 발산도를 의미하며, 이는 DDFM이 DFM과 다른 패턴을 학습하고 있음을 시사함.
        \item \textbf{오차 비선형성(error nonlinearity):} DDFM 오차 패턴의 비선형성을 측정함. 비상수 분산, 왜도, 첨도 등의 비선형 패턴을 감지하여 DDFM이 비선형 관계를 학습하고 있는지 평가함.
        \item \textbf{시점 상호작용 효과(horizon interaction):} DDFM이 시점별로 다른 개선 패턴을 보이는지 감지함. 시점별로 일관된 개선이 아닌 시점 특이적 비선형 효과가 있는지 평가함.
    \end{itemize}
    비선형성 점수는 \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합되어 자동으로 계산되며, 각 대상 변수에 대한 비선형성 점수와 해석을 제공함. 점수 < 0.2는 매우 낮은 비선형성(선형 붕괴 가능성 높음)을 의미하며, 점수 > 0.7은 높은 비선형성(DDFM이 명확한 비선형 특징을 학습)을 의미함. 이 메트릭은 선형성 감지와 함께 사용하여 DDFM의 비선형 학습 능력을 종합적으로 평가함.
    \item \textbf{분위수 기반 오차 메트릭(quantile-based error metrics):} 평균 기반 메트릭이 이상치에 민감한 문제를 해결하기 위해 분위수 기반 강건 메트릭을 추가함. \texttt{calculate\_quantile\_based\_metrics()} 함수는 여러 분위수(0.1, 0.25, 0.5, 0.75, 0.9)에서 sMAE와 sMSE를 계산하며, 다음 메트릭들을 제공함:
    \begin{itemize}
        \item \textbf{분위수별 sMAE/sMSE:} 각 분위수에서의 표준화된 오차를 계산하여 오차 분포의 전체적인 모양을 파악함. 중앙값(0.5 분위수)은 평균보다 이상치에 강건한 성능 지표를 제공함.
        \item \textbf{IQR sMAE:} 사분위수 범위(IQR)를 사용한 오차 분포의 퍼짐 정도를 측정함. 높은 IQR은 오차가 넓게 분포되어 있음을 의미하며, 예측 불안정성을 시사함.
        \item \textbf{꼬리 비율(tail ratio):} 90번째 분위수와 10번째 분위수의 비율을 계산하여 오차 분포의 꼬리 두께를 측정함. 높은 꼬리 비율(> 5)은 무거운 꼬리를 의미하며, 가끔 극단적인 예측 오차가 발생함을 시사함.
    \end{itemize}
    분위수 기반 메트릭은 변동성이 큰 시점이나 왜도가 있는 오차 분포에서 더 신뢰할 수 있는 성능 평가를 제공하며, \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합되어 자동으로 계산됨. 특히 KOEQUIPTE와 같이 일부 시점(horizon 7-8, 13-14)에서 극단적 오차가 발생하는 경우, 분위수 기반 메트릭은 평균 기반 메트릭보다 더 정확한 성능 평가를 제공함.
    \item \textbf{요인 부하 비교(factor loading comparison):} DFM과 DDFM이 학습한 요인 부하를 비교하여 선형 붕괴를 감지하는 기능을 추가함. \texttt{compare\_factor\_loadings()} 함수는 두 모형의 요인 부하 간 유사성을 계산하며, 높은 유사성은 DDFM 인코더가 선형 특징만 학습하고 있음을 시사함. 이 메트릭은 모델 내부(요인 부하)에 접근할 수 있을 때 사용 가능하며, 코사인 유사도와 상관관계를 사용하여 요인 부하의 유사성을 정량화함. 이 기능은 선형 붕괴 위험 평가에 활용되며, DDFM 인코더가 선형 PCA와 유사한 해에 수렴했는지 확인하는 데 도움을 줌.
    \item \textbf{상대적 기술 평가(relative skill assessment):} 실제 예측값이 없는 경우에도 오차 메트릭을 사용하여 기술 점수와 유사한 평가를 제공하는 기능을 추가함. \texttt{calculate\_relative\_skill\_assessment()} 함수는 DDFM의 성능을 DFM 및 기준 모형(VAR)과 비교하여 기술 점수와 유사한 평가를 제공함. 이 메트릭은 다음을 평가함:
    \begin{itemize}
        \item \textbf{DDFM vs DFM:} DDFM이 DFM 대비 얼마나 개선되었는지 백분율로 계산
        \item \textbf{DDFM vs VAR:} DDFM이 VAR 기준선 대비 얼마나 개선되었는지 평가
        \item \textbf{기술 일관성:} 시점 간 기술 점수가 얼마나 일관적인지 측정 (0-1, 높을수록 일관적)
        \item \textbf{시점별 기술:} 각 예측 시점에서의 기술 평가
    \end{itemize}
    이 메트릭은 \texttt{forecast\_skill\_score()}를 보완하여, 예측값이 \texttt{aggregated\_results.csv}에 저장되지 않은 경우에도 오차 메트릭을 사용하여 기술 점수와 유사한 평가를 제공함. 기술 수준은 HIGH(>10\% 개선), MODERATE(5-10\% 개선), LOW(유사), NEGATIVE(저하)로 분류되며, DDFM의 상대적 성능을 더 해석하기 쉽게 평가할 수 있게 함.
    \item \textbf{근선형 붕괴 감지(near-linear collapse detection):} DDFM과 DFM의 오차가 수치적 정밀도 범위 내(< 0.01 절대 차이, < 0.1\% 상대 차이)에 있는 경우를 특별히 감지하는 기능을 추가함. \texttt{calculate\_near\_linear\_collapse\_detection()} 함수는 선형성 감지보다 더 강한 신호를 제공하며, KOEQUIPTE와 같이 모든 시점에서 DDFM과 DFM의 오차가 거의 동일한 경우를 조기에 감지함. 이 메트릭은 절대 차이 분석, 상대 차이 분석, 근붕괴 비율(근붕괴를 보이는 시점의 비율), 근붕괴 점수(0-1, 높을수록 근붕괴 가능성)를 계산하며, 시점별 근붕괴 감지를 제공함. 이 메트릭은 유사성 메트릭만으로는 감지하기 어려운 수치적 정밀도 수준의 선형 붕괴를 조기에 발견하는 데 도움을 줌.
    \item \textbf{오차 패턴 평활도(error pattern smoothness):} DDFM의 오차 패턴이 시점 간에 얼마나 일관적이고 평활한지를 측정하는 메트릭을 추가함. \texttt{calculate\_error\_pattern\_smoothness()} 함수는 변동 계수(CV), 1차 차분, 2차 차분, 자기상관을 사용하여 평활도 점수(0-1, 높을수록 평활)를 계산하며, 인코더가 잘 학습된 경우 비선형 특징이 시점 간 일관된 성능을 제공하므로 더 평활한 오차 패턴을 보일 것으로 기대됨. KOEQUIPTE의 경우 낮은 평활도 점수가 예상되며, 이는 시점 간 오차 변동성이 크고 일관성이 낮음을 시사함.
    \item \textbf{개선 통계적 유의성 검정(improvement significance testing):} 부트스트랩 재표본 추출을 통해 DDFM의 개선이 통계적으로 유의한지를 검정하는 기능을 추가함. \texttt{calculate\_improvement\_significance()} 함수는 기본적으로 1000회 부트스트랩 재표본 추출을 수행하여 개선 비율의 신뢰구간을 계산하고, 개선이 통계적으로 유의한지(신뢰구간이 0을 포함하지 않음)를 판단함. p-value, 유의한 시점 목록, 시점별 유의성 분석을 제공하여 DDFM 개선이 실제 개선인지 랜덤 변동인지 구분함. KOEQUIPTE의 경우 개선 비율이 거의 0\%이므로 통계적으로 유의하지 않을 것으로 예상됨.
    \item \textbf{대상 변수 간 패턴 비교(cross-target pattern comparison):} 세 대상 변수 간의 DDFM 성능 패턴을 비교하여 공통 패턴과 이상치를 식별하는 기능을 추가함. \texttt{calculate\_cross\_target\_pattern\_comparison()} 함수는 대상 변수 간 개선 비율, 일관성, 선형 붕괴 위험을 비교하여 어떤 대상 변수가 다른 패턴을 보이는지 식별함. 이를 통해 KOEQUIPTE와 같이 선형 붕괴를 보이는 대상 변수를 조기에 발견하고, 다른 대상 변수에서 성공한 전략을 적용할 수 있음.
    \item \textbf{체계적 편향 감지(systematic bias detection):} DDFM이 DFM보다 일관되게 나쁜 성능을 보이는 경우를 감지하는 메트릭을 추가함. \texttt{analyze\_ddfm\_prediction\_quality()} 함수는 다음 세 가지 메트릭을 계산함:
    \begin{itemize}
        \item \textbf{체계적 편향 점수(systematic\_bias\_score):} 0-1 범위의 점수로, 높을수록 DDFM이 DFM보다 일관되게 나쁨을 의미함. DDFM이 더 나쁜 시점의 비율이 50\% 이상이거나, 근선형 붕괴 비율이 80\% 이상인 경우 높은 점수를 받음.
        \item \textbf{근선형 붕괴 비율(near\_linear\_fraction):} 근선형 붕괴를 보이는 시점의 비율. 이 비율이 높으면 DDFM 인코더가 선형 특징만 학습하고 있음을 시사함.
        \item \textbf{DDFM 저하 비율(ddfm\_worse\_fraction):} DDFM이 DFM보다 나쁜 성능을 보이는 시점의 비율. 이 비율이 높으면 DDFM이 체계적으로 DFM보다 나쁨을 의미함.
    \end{itemize}
    이러한 메트릭들은 KOEQUIPTE와 같이 DDFM이 DFM과 거의 동일한 성능을 보이는 경우를 정량적으로 진단하는 데 도움을 줌. KOEQUIPTE의 경우 근선형 붕괴 비율이 1.0(모든 시점에서 근선형 붕괴)이고, 체계적 편향 점수가 높을 것으로 예상됨.
    \item \textbf{오차 자기상관 분석(error autocorrelation analysis):} 연속된 시점 간 오차의 상관관계를 분석하여 체계적 편향 패턴을 감지하는 메트릭을 추가함. \texttt{calculate\_error\_autocorrelation\_analysis()} 함수는 여러 시차(lag)에 대해 DDFM과 DFM의 오차 자기상관을 계산함. 높은 자기상관(> 0.5)은 오차가 시점 간에 지속되는 체계적 편향을 나타내며, 낮은 자기상관(< 0.2)은 오차가 상대적으로 독립적임을 의미함. 이 메트릭은 DDFM 인코더가 학습한 패턴이 시점 간에 체계적으로 지속되는지, 아니면 더 랜덤한 오차를 생성하는지를 구분하는 데 도움을 줌. DDFM이 DFM보다 높은 자기상관을 보이면 인코더가 체계적 패턴을 학습하고 있음을 시사하며, 이는 선형 붕괴의 조기 신호일 수 있음. 이 메트릭은 \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합되어 자동으로 계산되며, 각 대상 변수에 대한 오차 자기상관 점수와 해석을 제공함.
    \item \textbf{개선 안정성 메트릭(improvement stability metrics):} DDFM 개선이 시점 간에 얼마나 일관적인지를 측정하는 메트릭을 추가함. \texttt{calculate\_improvement\_stability()} 함수는 개선 비율의 분산, 변동 계수, 범위, 사분위수 범위를 계산하여 개선의 안정성을 평가함. 높은 안정성 점수(> 0.8)는 시점 간 일관된 개선을 의미하며, 낮은 안정성(< 0.4)은 개선이 시점별로 크게 다름을 나타냄. 이 메트릭은 DDFM 인코더가 일반화 가능한 특징을 학습했는지(일관된 개선), 아니면 특정 시점에 과적합했는지(변동적인 개선)를 구분하는 데 도움을 줌. 또한 양수 개선과 음수 개선의 개수를 추적하여 DDFM이 일관되게 개선하는지, 아니면 일부 시점에서 성능이 저하되는지를 정량화함. 이 메트릭은 \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합되어 자동으로 계산되며, 각 대상 변수에 대한 개선 안정성 점수와 해석을 제공함.
\end{itemize}

이러한 메트릭 개선 사항들은 DDFM 성능 평가의 신뢰성을 향상시키고, 특히 KOEQUIPTE와 같이 선형 붕괴(linear collapse) 위험이 있는 경우 더 정확한 성능 분석을 가능하게 함. 향후 실험에서 이러한 강건 메트릭들을 활용하여 DDFM 성능을 더 정확하게 평가하고, 개선 전략을 수립할 수 있음.

이러한 개선 사항들의 효과를 검증하기 위해서는 추가 실험 재실행이 필요하며, 특히 KOEQUIPTE에서의 성능 개선 여부를 확인해야 함. 현재 \texttt{checkpoint/} 디렉토리에는 12개의 모델 파일이 존재하므로, 모델 훈련 없이 바로 예측 실험을 재실행하여 최신 코드 개선사항이 반영된 결과를 생성할 수 있음. 성공 기준은 sMAE가 1.14에서 1.03 이하로 개선되는 것(10\% 이상 개선)이며, 이는 비선형 인코더가 KOEQUIPTE에 대해 추가적인 이점을 제공할 수 있음을 시사함. 구체적인 연구 계획과 실행 단계는 ISSUES.md에 상세히 문서화되어 있으며, Phase 0(상관관계 구조 분석)부터 Phase 3(고급 기법)까지의 단계별 접근 방식을 제시함.

\textbf{DDFM 선형성 자동 감지 기능:} DDFM이 선형 관계만 학습하는지 자동으로 감지하는 기능을 구현함. \texttt{src/evaluation/evaluation\_aggregation.py}에 구현된 \texttt{detect\_ddfm\_linearity()} 함수는 결과 집계 시 자동으로 실행되어 DDFM과 DFM의 성능 메트릭을 비교함. 이 함수는 각 대상 변수와 시점에 대해 선형성 점수(0-1, 높을수록 선형)를 계산하며, 선형성 점수가 0.95 이상인 경우 DDFM이 선형 관계만 학습하고 있음을 경고함. 또한 선형성 감지 결과는 \texttt{outputs/experiments/ddfm\_linearity\_analysis.json}에 저장되며, 각 대상 변수에 대한 개선 권장사항(더 깊은 인코더, tanh 활성화 함수, 가중치 감쇠 등)을 제공함. 이 기능은 DDFM의 성능 문제를 조기에 발견하고 개선 방향을 제시하는 데 도움을 줌. 현재 KOEQUIPTE에 대한 선형성 점수는 0.99 이상으로 관찰되며, 이는 인코더가 선형 PCA와 유사한 해에 수렴했음을 강하게 시사함.

\textbf{상관관계 구조 분석 활용:} 모델 훈련 전에 수행 가능한 상관관계 구조 분석을 통해 DDFM 성능 개선 전략을 수립할 수 있음. \texttt{analyze\_correlation\_structure()} 함수를 사용하여 대상 변수와 모든 입력 시계열 간의 상관관계 패턴을 분석함. 주요 분석 지표는 다음과 같음:
\begin{itemize}
    \item \textbf{음의 상관관계 비율 (negative\_fraction):} 전체 상관관계 중 음의 상관관계의 비율. KOEQUIPTE의 경우 이 값이 0.3 이상이고 다른 대상 변수가 0.2 미만이면, tanh 활성화 함수가 도움이 될 것으로 예상됨.
    \item \textbf{강한 음의 상관관계 개수 (strong\_negative\_count):} 절댓값이 0.3 이상인 음의 상관관계의 개수. 이 값이 높으면 ReLU 활성화 함수로는 포착하기 어려운 음의 관계가 많다는 것을 의미하며, tanh 활성화 함수가 유리함.
    \item \textbf{평균 상관관계 (mean\_correlation):} 대상 변수와 모든 입력 시계열 간의 평균 상관관계. 이 값이 낮으면(예: < 0.1) 신호가 약하다는 것을 의미하며, 더 깊은 인코더나 더 많은 훈련 에포크가 필요할 수 있음.
    \item \textbf{상관관계 표준편차 (std\_correlation):} 상관관계 분포의 퍼짐 정도. 이 값이 높으면 구조적 복잡성이 높다는 것을 의미하며, 더 복잡한 인코더 아키텍처가 필요할 수 있음.
\end{itemize}
이러한 분석을 통해 모델 훈련 전에 활성화 함수 선택, 인코더 아키텍처 결정, 그리고 개선 전략을 수립할 수 있으며, 실험 비용을 절감하면서도 효율적인 개선 방향을 제시할 수 있음.

\textbf{DDFM 예측 품질 분석 기능:} DDFM의 예측 품질을 상세히 분석하는 기능을 구현함. \texttt{src/evaluation/evaluation\_aggregation.py}에 구현된 \texttt{analyze\_ddfm\_prediction\_quality()} 함수는 결과 집계 시 자동으로 실행되어 DDFM의 시점별 성능 패턴, 불안정한 시점 식별, 예측 안정성 메트릭, 그리고 DFM 기준선과의 비교를 수행함. 이 함수는 시점 가중 메트릭, 훈련 정렬 메트릭, 상대 오차 안정성 메트릭, 그리고 개선 지속성 메트릭을 통합하여 더 정확한 성능 평가를 제공함. 이 함수는 각 대상 변수에 대해 다음과 같은 향상된 진단 메트릭을 계산함:
\begin{itemize}
    \item \textbf{오차 분산 및 불안정한 시점 식별:} 각 시점별 오차의 분산을 계산하고, 평균 + 1.5 × 표준편차를 초과하는 불안정한 시점을 식별함.
    \item \textbf{예측 안정성 메트릭 (계수 of variation, CV):} 시점 간 예측 안정성을 측정하는 CV 메트릭을 계산함. 낮은 CV 값은 더 안정적인 예측을 의미함.
    \item \textbf{단기 vs 장기 성능 분석:} 단기 예측(1-6개월)과 장기 예측(13-22개월)의 성능을 비교하여 시점별 성능 패턴을 분석함.
    \item \textbf{일관성 메트릭 (0-1):} DDFM이 DFM 대비 시점 간 개선이 얼마나 일관적인지를 측정함. 높은 일관성 값은 모든 시점에서 일관된 개선을 의미함.
    \item \textbf{최고/최악 시점 식별:} DFM 대비 개선 비율이 가장 높은 시점과 가장 낮은 시점을 식별하고, 개선 비율을 백분율로 계산함.
    \item \textbf{DFM 대비 개선 비율:} 각 시점에서 DDFM이 DFM 대비 얼마나 개선되었는지를 계산함 (음수 = DDFM이 더 나쁨, 양수 = DDFM이 더 좋음).
    \item \textbf{향상된 선형 붕괴 위험 평가:} 인코더가 선형 관계만 학습하는 위험을 0-1 점수로 평가함. 높은 점수는 인코더가 선형 PCA와 유사한 해에 수렴할 위험이 높음을 의미함. 이 평가는 다음 7가지 위험 요소를 종합적으로 고려함:
    \begin{itemize}
        \item \textbf{위험 요소 1:} DFM 대비 개선이 매우 작음 (< 5\%) 또는 음수 (가중치: 25\%)
        \item \textbf{위험 요소 2:} 모든 시점에서 DFM과의 높은 유사성 (가중치: 18\%)
        \item \textbf{위험 요소 3:} 낮은 일관성 (시점 간 개선 정도가 크게 다름) (가중치: 13\%)
        \item \textbf{위험 요소 4:} 오차 패턴 유사성 (sMSE/sMAE 비율 유사성) - DDFM과 DFM의 오차 구조가 유사하면 선형 행동을 시사함 (가중치: 13\%)
        \item \textbf{위험 요소 5:} 시점 간 오차 상관관계 - DDFM과 DFM의 시점별 오차가 높은 양의 상관관계를 가지면 체계적 선형 행동을 시사함 (가중치: 10\%)
        \item \textbf{위험 요소 6:} 상대적 개선 일관성 - DDFM이 DFM 대비 개선되는 시점의 비율이 낮으면 선형 행동을 시사함 (가중치: 10\%)
        \item \textbf{위험 요소 7:} 오차 분포 유사성 - DDFM과 DFM의 오차 분포(왜도, 첨도)가 유사하면 두 모형이 유사한 오차 패턴을 보이며 선형 행동을 시사함 (가중치: 11\%)
    \end{itemize}
    이러한 다차원적 평가를 통해 선형 붕괴 위험을 더 정확하게 감지할 수 있으며, 각 위험 요소에 대한 구체적인 개선 권장사항을 제공함. 특히 오차 분포 유사성(위험 요소 7)은 DDFM과 DFM의 오차 분포가 유사할 때 선형 붕괴를 더 정확하게 감지하는 데 도움을 줌.
    \item \textbf{시점별 성능 저하 감지:} DDFM이 DFM보다 성능이 나쁜 시점을 식별하여 시점별 튜닝이 필요한 영역을 파악함.
\end{itemize}
또한 각 대상 변수에 대한 구체적인 개선 권장사항을 생성하며, 예를 들어 오차 분산이 높은 경우 정규화나 앙상블 방법을 권장하고, 특정 시점에서 불안정성이 관찰되는 경우 시점별 튜닝을 권장함. 이 기능은 DDFM의 성능 특성을 체계적으로 분석하고 개선 방향을 제시하는 데 도움을 줌.

\textbf{향상된 오차 분포 메트릭:} DDFM의 예측 오차 분포를 더 자세히 분석하기 위해 \texttt{src/evaluation/evaluation\_metrics.py}의 \texttt{calculate\_standardized\_metrics()} 함수에 오차 분포 분석 메트릭을 추가함. 이러한 메트릭들은 각 시점별로 계산되며, DDFM의 예측 특성을 더 깊이 이해하는 데 도움을 줌:
\begin{itemize}
    \item \textbf{오차 왜도 (error\_skewness):} 오차 분포의 비대칭성을 측정함. 양수는 오른쪽 꼬리가 긴 분포(가끔 큰 과대 예측)를 의미하고, 음수는 왼쪽 꼬리가 긴 분포(가끔 큰 과소 예측)를 의미함. 이를 통해 체계적인 과대/과소 예측 패턴을 식별할 수 있음.
    \item \textbf{오차 첨도 (error\_kurtosis):} 오차 분포의 꼬리 두께를 측정함. 양수는 무거운 꼬리(가끔 극단적인 예측 오차)를 의미하고, 음수는 가벼운 꼬리(안정적인 예측)를 의미함. 이를 통해 이상치에 취약한 예측을 식별할 수 있음.
    \item \textbf{오차 편향 제곱 (error\_bias\_squared):} 편향-분산 분해에서 체계적 편향 성분을 측정함. 높은 값은 체계적인 과대/과소 예측을 의미하며, 이는 모델의 구조적 한계를 시사함.
    \item \textbf{오차 분산 (error\_variance):} 편향-분산 분해에서 분산 성분을 측정함. 높은 값은 예측이 불안정함을 의미하며, 이는 정규화나 앙상블 방법으로 개선할 수 있음.
    \item \textbf{오차 집중도 (error\_concentration):} 오차가 균등하게 분포되어 있는지(0에 가까움) 아니면 특정 시점에 집중되어 있는지(1에 가까움)를 측정함. 높은 집중도는 특정 시점에서 체계적인 문제가 있음을 시사함.
\end{itemize}
이러한 메트릭들을 종합적으로 분석하면 DDFM의 예측 오차 원인을 더 정확히 파악할 수 있으며, 편향과 분산 중 어느 쪽을 개선해야 하는지 결정할 수 있음. 예를 들어, 높은 오차 편향 제곱과 낮은 오차 분산은 모델 구조 개선이 필요함을 시사하고, 낮은 오차 편향 제곱과 높은 오차 분산은 정규화나 앙상블 방법이 도움이 될 수 있음을 시사함.

\textbf{시점 간 오차 상관관계 분석:} DDFM의 오차 패턴이 시점 간에 어떻게 상관관계를 가지는지 분석하는 기능을 구현함. \texttt{src/evaluation/evaluation\_aggregation.py}에 구현된 \texttt{analyze\_horizon\_error\_correlation()} 함수는 서로 다른 예측 시점 간의 오차 유사성을 계산하여 체계적 문제(예: 선형 붕괴)와 시점별 문제를 구분함:
\begin{itemize}
    \item \textbf{유사성 행렬:} 각 시점 쌍 간의 오차 유사성을 계산하여 시점 간 오차 패턴의 유사성을 정량화함.
    \item \textbf{평균 유사성:} 모든 시점 쌍의 평균 유사성을 계산하여 전반적인 오차 패턴의 일관성을 측정함.
    \item \textbf{체계적 패턴 점수 (0-1):} 높은 점수(> 0.7)는 시점 간 오차가 유사함을 의미하며, 이는 체계적 문제(예: 인코더가 선형 특징만 학습)를 시사함. 낮은 점수(< 0.3)는 시점별로 오차가 다름을 의미하며, 이는 시점별 튜닝이 필요함을 시사함.
    \item \textbf{최대/최소 유사성 시점 쌍:} 가장 유사한 오차를 보이는 시점 쌍과 가장 다른 오차를 보이는 시점 쌍을 식별하여 오차 패턴의 특성을 파악함.
\end{itemize}
이 분석을 통해 인코더 아키텍처 문제(체계적)와 시점별 튜닝 필요성(시점별)을 구분할 수 있으며, 각 대상 변수에 대한 구체적인 개선 권장사항을 제공함. 예를 들어, 체계적 패턴 점수가 높으면 인코더 아키텍처 개선을 권장하고, 낮으면 시점별 정규화나 앙상블 방법을 권장함.

\textbf{구체적인 분석 메트릭 활용 방법:} DDFM 성능 개선을 위한 체계적인 분석을 위해 다음 메트릭들을 활용할 수 있음:
\begin{itemize}
    \item \textbf{선형성 점수 (linearity score):} 0-1 범위의 값으로, 0.95 이상이면 DDFM이 선형 관계만 학습하고 있음을 의미함. KOEQUIPTE의 경우 현재 선형성 점수가 0.99 이상으로 관찰되며, 이는 인코더가 선형 PCA와 유사한 해에 수렴했음을 강하게 시사함.
    \item \textbf{개선 비율 (improvement ratio):} DDFM이 DFM 대비 얼마나 개선되었는지를 백분율로 계산함. 음수는 DDFM이 더 나쁨을 의미하고, 양수는 개선을 의미함. KOEQUIPTE의 경우 현재 개선 비율이 거의 0\%에 가까워 DDFM이 추가적인 이점을 제공하지 못함을 보여줌.
    \item \textbf{예측 안정성 메트릭 (coefficient of variation, CV):} 시점 간 예측 안정성을 측정하는 메트릭으로, 낮은 CV 값은 더 안정적인 예측을 의미함. CV > 0.5이면 예측이 불안정하다는 것을 의미하며, 정규화나 앙상블 방법을 고려해야 함.
    \item \textbf{sMSE/sMAE 비율 안정성:} 시점 간 sMSE/sMAE 비율의 변동 계수(CV)를 계산하여 예측 오차 구조의 안정성을 측정함. 높은 비율 CV(> 0.3)는 시점 간 오차 구조가 불안정함을 의미하며, 이는 정규화나 시점별 튜닝이 필요함을 시사함.
    \item \textbf{일관성 메트릭 (consistency):} 0-1 범위의 값으로, DDFM이 DFM 대비 시점 간 개선이 얼마나 일관적인지를 측정함. 높은 일관성 값(> 0.7)은 모든 시점에서 일관된 개선을 의미하며, 낮은 일관성 값(< 0.5)은 시점별로 개선 정도가 크게 다름을 의미함.
    \item \textbf{단기 vs 장기 성능 분석:} 단기 예측(1-6개월)과 장기 예측(13-22개월)의 성능을 비교하여 시점별 성능 패턴을 분석함. 장기 성능이 단기 성능보다 1.5배 이상 나쁘면, 시점별 모델이나 앙상블 방법을 고려해야 함.
    \item \textbf{불안정한 시점 식별:} 평균 + 1.5 × 표준편차를 초과하는 오차를 보이는 시점을 불안정한 시점으로 식별함. 이러한 시점에 대해서는 시점별 튜닝이나 특별한 정규화 기법을 적용할 수 있음.
    \item \textbf{오차 분포 메트릭:} 오차 왜도, 첨도, 편향 제곱, 분산, 집중도를 통해 예측 오차의 원인을 파악함. 높은 편향 제곱은 모델 구조 개선이 필요함을 시사하고, 높은 분산은 정규화나 앙상블이 도움이 될 수 있음을 시사함.
    \item \textbf{시점 간 오차 상관관계:} 체계적 패턴 점수를 통해 인코더 아키텍처 문제(체계적)와 시점별 튜닝 필요성(시점별)을 구분함. 높은 체계적 패턴 점수(> 0.7)는 인코더 개선을, 낮은 점수(< 0.3)는 시점별 정규화를 권장함.
    \item \textbf{시점 가중 메트릭:} 실용적 예측 관점에서 단기 예측(1-6개월)에 더 높은 가중치(2.0)를 부여하고, 장기 예측(13-22개월)에는 낮은 가중치(0.5)를 부여하여 가중 평균을 계산함. 이를 통해 단기 예측 성능을 더 강조한 평가가 가능하며, DDFM 예측 품질 분석에 통합되어 시점별 가중 개선 비율을 제공함. 이 메트릭은 실용적 예측 관점에서 모델 성능을 평가하는 데 유용함.
    \item \textbf{훈련 정렬 메트릭:} 모델이 훈련 중 최적화한 손실 함수(MSE 또는 Huber)와 일치하는 평가 메트릭을 계산함. 이를 통해 평가 메트릭이 훈련 목표와 일치하도록 보장하여, 모델이 실제로 최적화한 목표에 대한 성능을 정확히 측정할 수 있음. Huber 손실을 사용한 모델의 경우 특히 유용하며, 이상치에 대한 강건성을 평가하는 데 도움을 줌.
    \item \textbf{상대 오차 안정성 메트릭:} DDFM과 DFM 간의 상대적 성능이 시점에 따라 어떻게 변화하는지 분석하는 기능을 구현함. \texttt{calculate\_relative\_error\_stability()} 함수는 안정성 점수(0-1), 변동 계수(CV), 그리고 추세 분석(개선/저하/안정)을 계산하여 DDFM의 상대적 성능이 일관적인지, 아니면 특정 시점에서만 개선되는지를 식별함. 높은 안정성 점수(> 0.7)는 일관된 개선을 의미하며, 낮은 점수(< 0.5)는 시점별로 개선 정도가 크게 다름을 의미함. 이를 통해 체계적 개선(인코더 아키텍처 효과)과 시점별 변동(노이즈)을 구분할 수 있음.
    \item \textbf{개선 지속성 메트릭:} DDFM의 개선이 지속적인(일관된) 개선인지, 아니면 일시적인(노이즈) 개선인지 감지하는 기능을 구현함. \texttt{calculate\_improvement\_persistence()} 함수는 지속성 점수(0-1), 개선 비율, 연속 개선 구간, 그리고 개선 클러스터를 계산하여 DDFM이 DFM 대비 체계적으로 개선되는지 평가함. 높은 지속성 점수(> 0.7)는 일관된 개선을 의미하며, 낮은 점수(< 0.5)는 특정 시점에서만 우연히 개선되는 것을 의미함. 이를 통해 실제 모델 개선과 랜덤 변동을 구분할 수 있음.
    \item \textbf{시간적 일관성 메트릭:} 연속된 시점 간 예측값의 급격한 변화(점프)를 감지하는 기능을 구현함. \texttt{calculate\_temporal\_consistency\_metrics()} 함수는 시간적 일관성 점수(0-1), 점프 개수, 점프 비율, 그리고 점프 크기를 계산하여 모델의 예측이 시간적으로 일관적인지 평가함. 낮은 일관성 점수(< 0.5)는 연속된 시점 간 예측값이 급격히 변동함을 의미하며, 이는 모델 불안정성이나 요인 동역학 문제를 시사함. 이를 통해 모델 안정성 문제를 조기에 발견할 수 있음.
    \item \textbf{예측 기술 점수 (Forecast Skill Score):} DDFM의 성능을 단순 기준선(무작위 보행 또는 평균 예측)과 비교하여 정량화하는 메트릭임. \texttt{calculate\_forecast\_skill\_score()} 함수는 기술 점수를 -inf에서 1.0 범위로 계산하며, 1.0은 완벽한 예측, 0.0은 기준선과 동일, 음수는 기준선보다 나쁨을 의미함. MSE, MAE, RMSE에 대해 각각 기술 점수를 계산하여 기준선 대비 개선 비율을 백분율로 제공함. 이를 통해 DDFM 성능을 더 해석 가능한 방식으로 평가할 수 있으며, 단순 기준선 대비 예측 개선 정도를 정량화함. 높은 기술 점수(> 0.5)는 DDFM이 기준선 대비 현저히 우수함을 의미하며, 낮은 기술 점수(< 0.0)는 기준선보다 나쁨을 의미함.
    \item \textbf{정보 획득 메트릭 (Information Gain):} DDFM이 DFM 대비 제공하는 추가 정보의 양을 측정하는 메트릭임. \texttt{calculate\_information\_gain()} 함수는 두 가지 방법을 사용함: (1) KL 발산 방법은 DDFM과 DFM의 오차 분포 간 KL 발산을 계산하여 두 모형의 오차 패턴 차이를 정량화함. (2) 상호 정보량 방법은 예측값과 실제값 간의 상호 정보량을 계산하여 DDFM이 DFM 대비 얼마나 많은 정보를 제공하는지 측정함. 정보 획득 메트릭은 DDFM 인코더가 학습한 비선형 특징의 가치를 정량화하며, DDFM이 DFM과 다른 패턴을 학습하고 있는지 식별하는 데 도움을 줌. 높은 정보 획득 값은 DDFM이 DFM 대비 더 많은 정보를 제공하며 비선형 특징을 효과적으로 학습하고 있음을 시사함. 반면 낮은 정보 획득 값은 DDFM이 DFM과 유사한 패턴을 학습하고 있음을 시사하며, 선형 붕괴 위험을 나타낼 수 있음.
    \item \textbf{향상된 시점별 개선 추적:} DDFM의 시점별 개선 정도를 분류하여 추적하는 기능임. \texttt{analyze\_ddfm\_prediction\_quality()} 함수에 통합된 시점 분류 기능은 각 시점을 개선 수준에 따라 분류함: 유의미한 개선(>10\%), 중간 개선(5-10\%), 경미한 개선(0-5\%), 개선 없음, 성능 저하. 각 카테고리별 비율과 개수를 계산하여 DDFM이 어떤 시점에서 가장 큰 이점을 제공하는지 파악할 수 있음. 이를 통해 DDFM 개선 전략을 시점별로 최적화할 수 있으며, 각 대상 변수에 대한 구체적인 개선 권장사항을 생성함. 예를 들어, 단기 시점(1-6개월)에서 유의미한 개선이 관찰되면 단기 예측에 최적화된 모델을 권장하고, 장기 시점(13-22개월)에서 성능 저하가 관찰되면 장기 예측 안정성을 개선하는 기법을 권장함.
\end{itemize}
이러한 메트릭들을 종합적으로 분석하여 DDFM 성능 개선을 위한 구체적인 전략을 수립할 수 있으며, 각 대상 변수별로 최적화된 하이퍼파라미터 설정을 결정할 수 있음.

\textbf{DDFM 메트릭 활용 실전 가이드:} DDFM 성능 개선을 위한 단계별 분석 워크플로우는 다음과 같음:
\begin{enumerate}
    \item \textbf{1단계: 선형성 자동 감지 확인} - 결과 집계 후 \texttt{outputs/experiments/ddfm\_linearity\_analysis.json} 파일을 확인함. 선형성 점수가 0.95 이상이면 즉시 개선이 필요함을 의미함. KOEQUIPTE의 경우 현재 선형성 점수가 0.99 이상으로 관찰되며, 이는 인코더가 선형 PCA와 유사한 해에 수렴했음을 강하게 시사함.
    \item \textbf{2단계: 예측 품질 분석 검토} - \texttt{analyze\_ddfm\_prediction\_quality()} 함수가 자동으로 생성한 분석 결과를 확인함. 개선 비율이 0\%에 가까우면 DDFM이 DFM 대비 이점이 없음을 의미하며, 일관성 메트릭이 0.5 미만이면 시점별로 개선 정도가 크게 다름을 의미함. 이러한 경우 인코더 아키텍처 개선이 필요함.
    \item \textbf{3단계: 오차 분포 메트릭 분석} - \texttt{aggregated\_results.csv}의 오차 분포 메트릭(error\_skewness, error\_kurtosis, error\_bias\_squared, error\_variance)을 확인함. 높은 편향 제곱(> 0.1)은 모델 구조 개선이 필요함을 시사하고, 높은 분산(> 0.5)은 정규화나 앙상블이 도움이 될 수 있음을 시사함.
    \item \textbf{4단계: 시점별 패턴 분석} - 시점 간 오차 상관관계 분석 결과를 확인함. 체계적 패턴 점수가 0.7 이상이면 인코더 아키텍처 문제(체계적)를 의미하며, 0.3 미만이면 시점별 튜닝이 필요함을 의미함. KOEQUIPTE의 경우 체계적 패턴 점수가 높을 것으로 예상되며, 이는 인코더 개선이 필요함을 시사함.
    \item \textbf{5단계: 개선 전략 결정} - 위 메트릭들을 종합하여 개선 전략을 결정함:
    \begin{itemize}
        \item 선형성 점수 > 0.95 AND 개선 비율 < 5\%: 더 깊은 인코더, tanh 활성화 함수, 가중치 감쇠 적용
        \item 일관성 < 0.5 AND 체계적 패턴 점수 < 0.3: 시점별 정규화 또는 앙상블 방법 고려
        \item 편향 제곱 > 0.1: 모델 구조 개선 (인코더 아키텍처, 활성화 함수)
        \item 분산 > 0.5: 정규화 강화 또는 앙상블 방법
    \end{itemize}
\end{enumerate}
이러한 단계별 워크플로우를 통해 DDFM 성능 문제를 체계적으로 진단하고 개선할 수 있음.

\textbf{Phase 0 사전 분석 준비 상태:} 모델 훈련 전에 수행 가능한 상관관계 구조 분석 기능이 구현되어 있으며, 세 대상 변수에 대해 즉시 실행 가능함. \texttt{analyze\_correlation\_structure()} 함수는 훈련 없이도 데이터의 구조적 특성을 분석하여 DDFM 개선 전략을 수립하는 데 활용할 수 있음. 특히 KOEQUIPTE의 경우, 음의 상관관계 비율이 다른 대상 변수보다 높은지 확인하여 tanh 활성화 함수의 효과를 예측할 수 있으며, 평균 상관관계가 낮은지 확인하여 더 깊은 인코더나 증가된 훈련 에포크의 필요성을 판단할 수 있음. 이 분석은 실험 비용을 절감하면서도 효율적인 개선 방향을 제시하는 데 도움을 줌. \textbf{현재 상태:} 이 분석은 아직 실행되지 않았으며(함수는 구현되어 있으나 실행 대기 중), 모델 훈련 전에 실행하여 개선 전략을 수립하는 것이 권장됨. 분석 결과는 \texttt{outputs/analysis/correlation\_analysis\_\{target\}.json}에 저장되며, 주요 지표(음의 상관관계 비율, 강한 음의 상관관계 개수, 평균 상관관계, 상관관계 표준편차)를 비교하여 개선 전략을 결정할 수 있음. 실행 명령어는 ISSUES.md에 상세히 문서화되어 있으며, 세 대상 변수에 대해 약 15분 내에 완료 가능함.

\textbf{구체적인 실행 계획:} Phase 0 상관관계 분석은 다음 명령어로 세 대상 변수에 대해 실행할 수 있음:
\begin{verbatim}
mkdir -p outputs/analysis
for target in KOEQUIPTE KOIPALL.G KOWRCCNSE; do
  python3 -c "from src.evaluation.evaluation_aggregation import 
  analyze_correlation_structure; import json; result = 
  analyze_correlation_structure('data/data.csv', '$target', 
  output_path='outputs/analysis/correlation_analysis_${target}.json'); 
  print(f'\n=== $target ==='); 
  print(json.dumps(result['summary'], indent=2))"
done
\end{verbatim}
분석 결과는 각 대상 변수별로 JSON 파일로 저장되며, 주요 지표(음의 상관관계 비율, 강한 음의 상관관계 개수, 평균 상관관계, 상관관계 표준편차)를 비교하여 개선 전략을 수립함. 예를 들어, KOEQUIPTE의 음의 상관관계 비율이 0.3 이상이고 다른 대상 변수가 0.2 미만이면, tanh 활성화 함수가 유리함을 시사함. 평균 상관관계가 0.1 미만이고 다른 대상 변수가 0.2 이상이면, 더 깊은 인코더나 증가된 훈련 에포크가 필요함을 시사함.

\textbf{메트릭 기반 의사결정 트리:} DDFM 성능 개선을 위한 구체적인 의사결정 기준은 다음과 같음:
\begin{itemize}
    \item \textbf{선형성 점수 > 0.95 AND 개선 비율 < 5\%}: 인코더가 선형 관계만 학습하고 있음 → 더 깊은 인코더([64, 32, 16]), tanh 활성화 함수, 가중치 감쇠(weight\_decay=1e-4), 증가된 사전 훈련(mult\_epoch\_pretrain=2), 배치 크기 최적화(batch\_size=64) 적용
    \item \textbf{개선 비율 5-10\% AND 일관성 > 0.7}: 부분적 개선 관찰 → 활성화 함수별 비교 실험(Phase 1.2) 수행하여 최적 활성화 함수 결정
    \item \textbf{개선 비율 < 5\% AND 체계적 패턴 점수 > 0.7}: 인코더 아키텍처 문제 → 인코더 아키텍처 그리드 서치, 요인 부하 분석 수행(Phase 2)
    \item \textbf{편향 제곱 > 0.1}: 체계적 편향 존재 → 모델 구조 개선(인코더 아키텍처, 활성화 함수) 필요
    \item \textbf{분산 > 0.5}: 예측 불안정성 → 정규화 강화 또는 앙상블 방법 고려
    \item \textbf{일관성 < 0.5 AND 체계적 패턴 점수 < 0.3}: 시점별 변동성 → 시점별 정규화 또는 앙상블 방법 고려
\end{itemize}
이러한 의사결정 트리를 통해 각 대상 변수별로 최적화된 개선 전략을 수립할 수 있음.

\textbf{실행 우선순위 요약:} DDFM 성능 개선을 위한 구체적인 실행 계획은 다음과 같음:
\begin{enumerate}
    \item \textbf{Phase 0 (즉시 실행 가능, 훈련 불필요):} 상관관계 구조 분석을 세 대상 변수에 대해 실행하여 개선 전략 수립 (~15분). \texttt{analyze\_correlation\_structure()} 함수를 사용하여 KOEQUIPTE의 데이터 구조적 특성을 분석하고, tanh 활성화 함수 및 더 깊은 인코더 전략의 타당성을 검증함. 이 분석은 모델 훈련 전에 실행 가능하여 실험 비용을 절감하면서도 효율적인 개선 방향을 제시함.
    \item \textbf{Phase 1 (훈련 필요):} 모델 재훈련 → 예측 실험 실행 → 기준선과 비교하여 개선 여부 확인. 성공 기준: sMAE < 1.03 (≥10\% 개선), DDFM이 DFM보다 5\% 이상 우수, 선형성 점수 < 0.95. 자동 분석 함수들(\texttt{detect\_ddfm\_linearity()}, \texttt{analyze\_ddfm\_prediction\_quality()})이 결과 집계 시 자동으로 실행되어 개선 여부를 정량적으로 평가함.
    \item \textbf{Phase 1.2 (조건부):} Phase 1에서 개선이 관찰되면(개선 비율 ≥ 5\%) 활성화 함수별 비교 실험 수행 (relu, tanh, sigmoid, leaky\_relu).
    \item \textbf{Phase 2/3 (조건부):} Phase 1이 실패하면(개선 비율 < 5\% 또는 선형성 점수 > 0.98) 인코더 아키텍처 그리드 서치, 요인 부하 분석, 정규화 실험, 또는 앙상블/특징 공학 기법 시도.
\end{enumerate}
각 단계의 구체적인 실행 명령어, 검증 방법, 성공 기준은 ISSUES.md에 상세히 문서화되어 있으며, 메트릭 기반 의사결정 트리를 통해 각 단계의 성공/실패를 정량적으로 평가함.

\textbf{결론 및 향후 연구 방향:} 단일 모형이 모든 대상 변수에서 최고 성능을 보이지 않으며, 대상 변수의 특성에 따라 적절한 모형을 선택하는 것이 중요함. 변동성이 큰 시계열에서는 DDFM이 우수한 성능을 보이며, 선형 관계가 강한 시계열에서는 VAR이나 DFM도 경쟁력 있는 성능을 보임. 실제 운영 환경에서는 nowcasting 능력도 중요한 고려사항이며, 이 경우 DFM이나 DDFM이 유리함. 

KOEQUIPTE에서의 DDFM 성능 개선을 위한 기법들이 구현되었으며, 선형성 자동 감지 기능을 통해 성능 문제를 체계적으로 모니터링할 수 있음. 다만, 효과를 검증하기 위해서는 추가 실험 재실행이 필요함. 

\textbf{즉시 실행 가능한 개선 전략:} Phase 0 상관관계 구조 분석을 통해 모델 훈련 전에 개선 전략을 수립할 수 있으며, 이를 통해 실험 효율성을 높일 수 있음. 이 분석은 모델 훈련 없이도 수행 가능하며, 세 대상 변수에 대해 약 15분 내에 완료 가능함. 분석 결과는 tanh 활성화 함수 및 더 깊은 인코더 전략의 타당성을 검증하는 데 활용되며, 실험 비용을 절감하면서도 효율적인 개선 방향을 제시함.

\textbf{현재 실험 결과 기반 DDFM 메트릭 개선 계획:} 현재 실험 결과(\texttt{outputs/experiments/aggregated\_results.csv})를 분석한 결과, KOEQUIPTE에서 DDFM과 DFM이 21개 시점 모두에서 거의 동일한 성능을 보임(평균 sMAE 차이 0.00085, 최대 차이 0.00212). 이는 DDFM 인코더가 선형 PCA와 유사한 요인 구조만 학습하고 있음을 강하게 시사함. 개선을 위한 구체적인 실행 계획은 다음과 같음:

\textbf{즉시 실행 가능한 분석 (훈련 불필요):}
\begin{enumerate}
    \item \textbf{기준선 메트릭 분석 (우선순위 1, ~5분):} 현재 \texttt{aggregated\_results.csv}를 사용하여 기준선 메트릭을 계산함. \texttt{detect\_ddfm\_linearity()}와 \texttt{analyze\_ddfm\_prediction\_quality()} 함수를 실행하여 기준선 선형성 점수(예상: ~0.99), 개선 비율(예상: ~0\%), 붕괴 위험 점수(예상: ~0.95+)를 계산하고 저장함. 이 기준선은 개선 후 결과와 비교하여 정량적 개선 여부를 평가하는 데 사용됨.
    \item \textbf{Phase 0: 상관관계 구조 분석 (우선순위 2, ~15분):} \texttt{analyze\_correlation\_structure()} 함수를 사용하여 세 대상 변수에 대해 상관관계 구조 분석을 실행함. 주요 의사결정 기준: KOEQUIPTE의 음의 상관관계 비율(\texttt{negative\_fraction})이 0.3 이상이고 다른 대상 변수가 0.2 미만이면, tanh 활성화 함수 전략이 타당함을 확인. 평균 상관관계(\texttt{mean\_correlation})가 0.1 미만이고 다른 대상 변수가 0.2 이상이면, 더 깊은 인코더 전략이 타당함을 확인. 분석 결과는 \texttt{outputs/analysis/correlation\_analysis\_\{target\}.json}에 저장되며, 개선 전략 수립에 활용됨.
\end{enumerate}

\textbf{실험 재실행 (모델 훈련 필요):}
\begin{enumerate}
    \item \textbf{Phase 1: 예측 실험 재실행:} 현재 \texttt{checkpoint/} 디렉토리에는 12개의 모델 파일이 존재하므로, 모델 훈련 없이 바로 예측 실험을 실행하여 최신 코드 개선사항이 반영된 결과를 생성함. 결과 집계 시 자동으로 실행되는 \texttt{detect\_ddfm\_linearity()}와 \texttt{analyze\_ddfm\_prediction\_quality()} 함수를 통해 개선 여부를 정량적으로 평가함. 성공 기준: sMAE 개선 ≥ 10\% (목표: sMAE < 1.03 from baseline 1.14), DDFM이 DFM보다 최소 5\% 이상 우수, 선형성 점수 < 0.95, 붕괴 위험 < 0.5.
    \item \textbf{의사결정 단계:} 계산된 메트릭들을 기반으로 다음 단계를 결정함:
    \begin{itemize}
        \item \textbf{성공 (SUCCESS):} 개선 ≥ 10\% AND DDFM > 5\% better AND 선형성 < 0.95 AND 붕괴 위험 < 0.5 → Phase 1.2(활성화 함수별 비교 실험)로 진행
        \item \textbf{부분 성공 (PARTIAL):} 개선 5-10\% OR 선형성 0.95-0.98 → 조사 후 Phase 1.2로 신중하게 진행
        \item \textbf{조사 필요 (NEEDS INVESTIGATION):} 개선 < 10\% OR 선형성 ≥ 0.95 OR 붕괴 위험 ≥ 0.5 → 로그 확인, 설정 검증, Phase 2(고급 개선)로 진행
        \item \textbf{실패 (FAILURE):} 개선 없음 또는 성능 저하 → 로그 확인, 원인 조사, Phase 2로 진행
    \end{itemize}
\end{enumerate}

이러한 메트릭 기반 방법론을 통해 DDFM 성능 개선을 체계적이고 정량적으로 수행할 수 있으며, 각 대상 변수별로 최적화된 하이퍼파라미터 설정을 결정할 수 있음. 구체적인 실행 명령어와 검증 방법은 ISSUES.md에 상세히 문서화되어 있음.

\textbf{메트릭 기반 개선 방법론의 실행 계획:} DDFM 성능 개선을 위한 체계적인 실행 계획은 다음과 같음:
\begin{enumerate}
    \item \textbf{Phase 0 (즉시 실행 가능, 훈련 불필요):} 상관관계 구조 분석을 세 대상 변수에 대해 실행하여 개선 전략 수립. \texttt{analyze\_correlation\_structure()} 함수를 사용하여 KOEQUIPTE의 데이터 구조적 특성을 분석하고, tanh 활성화 함수 및 더 깊은 인코더 전략의 타당성을 검증함. 주요 의사결정 기준: KOEQUIPTE의 음의 상관관계 비율이 0.3 이상이고 다른 대상 변수가 0.2 미만이면, tanh 활성화 함수가 유리함을 시사함. 평균 상관관계가 0.1 미만이고 다른 대상 변수가 0.2 이상이면, 더 깊은 인코더나 증가된 훈련 에포크가 필요함을 시사함.
    \item \textbf{기준선 수립 (즉시 실행 가능, 훈련 불필요):} 현재 실험 결과를 바탕으로 기준선 메트릭을 계산함. \texttt{detect\_ddfm\_linearity()}와 \texttt{analyze\_ddfm\_prediction\_quality()} 함수를 사용하여 기준선 선형성 점수(예상: ~0.99), 개선 비율(예상: ~0\%), 붕괴 위험 점수(예상: ~0.95+)를 계산하고 저장함. 이 기준선은 개선 후 결과와 비교하여 정량적 개선 여부를 평가하는 데 사용됨.
    \item \textbf{Phase 1 (모델 존재, 예측 실험 재실행):} 모델이 이미 훈련되어 있으므로(Dec 9 02:35-02:47), 예측 실험을 재실행하여 최신 코드 개선사항이 반영된 결과를 생성함. 결과 집계 시 \texttt{detect\_ddfm\_linearity()}와 \texttt{analyze\_ddfm\_prediction\_quality()} 함수가 자동으로 실행되어 개선 여부를 정량적으로 평가함. 성공 기준: sMAE 개선 ≥ 10\% (목표: sMAE < 1.03), DDFM이 DFM보다 최소 5\% 이상 우수, 선형성 점수 < 0.95, 붕괴 위험 < 0.5.
    \item \textbf{의사결정 단계:} 계산된 메트릭들을 기반으로 다음 단계를 결정함. 성공(SUCCESS)의 경우 Phase 1.2(활성화 함수별 비교 실험)로 진행하고, 부분 성공(PARTIAL)의 경우 조사 후 신중하게 진행하며, 조사 필요(NEEDS INVESTIGATION) 또는 실패(FAILURE)의 경우 Phase 2(고급 개선)로 진행함.
    \item \textbf{반복 개선 단계:} 각 실험 반복 후 모든 메트릭을 확인하고, 시간에 따른 개선 추세를 모니터링함. 메트릭들을 종합하여 다음 반복의 개선 방향을 결정하고, 결과를 보고서에 문서화함.
\end{enumerate}

\textbf{검증이 필요한 개선 사항:} 구현된 개선 사항(더 깊은 인코더, tanh 활성화 함수, 가중치 감쇠, 증가된 사전 훈련, 배치 크기 최적화)의 효과를 검증하기 위해서는 모델 재훈련 및 예측 실험 재실행이 필요함. 성공 기준은 KOEQUIPTE sMAE가 1.14에서 1.03 이하로 개선되는 것(≥10\% 개선)이며, DDFM이 DFM보다 최소 5\% 이상 우수해야 함. 또한 선형성 점수가 0.95 미만으로 감소하고, 일관성 메트릭이 0.7 이상으로 향상되어야 함.

\textbf{메트릭 기반 개선 방법론:} DDFM 성능 개선을 위한 체계적인 방법론을 수립함. 이 방법론은 실험 전 사전 분석, 실험 후 자동 분석, 그리고 메트릭 기반 의사결정을 통해 지속적인 개선을 가능하게 함:

\begin{enumerate}
    \item \textbf{사전 분석 단계 (Phase 0):} 모델 훈련 전에 \texttt{analyze\_correlation\_structure()} 함수를 실행하여 데이터 구조적 특성을 분석함. 주요 지표는 음의 상관관계 비율(negative\_fraction), 강한 음의 상관관계 개수(strong\_negative\_count), 평균 상관관계(mean\_correlation), 상관관계 표준편차(std\_correlation)임. 이러한 분석을 통해 활성화 함수 선택(tanh vs ReLU)과 인코더 아키텍처 결정을 사전에 최적화할 수 있음. 예를 들어, KOEQUIPTE의 음의 상관관계 비율이 0.3 이상이고 다른 대상 변수가 0.2 미만이면, tanh 활성화 함수가 유리함을 시사함. 평균 상관관계가 0.1 미만이고 다른 대상 변수가 0.2 이상이면, 더 깊은 인코더나 증가된 훈련 에포크가 필요함을 시사함.
    
    \item \textbf{기준선 수립 단계:} 기존 실험 결과를 바탕으로 기준선 메트릭을 계산함. \texttt{detect\_ddfm\_linearity()}와 \texttt{analyze\_ddfm\_prediction\_quality()} 함수를 사용하여 기준선 선형성 점수, 개선 비율, 붕괴 위험 점수를 계산하고 저장함. 이 기준선은 개선 후 결과와 비교하여 정량적 개선 여부를 평가하는 데 사용됨.
    
    \item \textbf{자동 분석 단계 (Phase 1):} 모델 훈련 및 예측 실험 후, 결과 집계 시 \texttt{detect\_ddfm\_linearity()}와 \texttt{analyze\_ddfm\_prediction\_quality()} 함수가 자동으로 실행되어 다음 메트릭들을 계산함:
    \begin{itemize}
        \item 선형성 점수(linearity score): 0-1 범위, 0.95 이상이면 선형 관계만 학습 중
        \item 개선 비율(improvement ratio): DDFM이 DFM 대비 개선된 정도 (목표: > 10\%)
        \item 붕괴 위험 점수(collapse risk): 0-1 범위, 0.5 이상이면 선형 붕괴 위험 높음
        \item 일관성 메트릭(consistency): 시점 간 개선의 일관성 (목표: > 0.7)
        \item 오차 패턴 유사성(error pattern similarity): DFM과의 오차 패턴 유사도 (목표: < 0.6)
        \item 시점 간 오차 상관관계(horizon error correlation): DFM과의 오차 상관관계 (목표: < 0.5)
        \item 시점 가중 개선 비율(weighted improvement): 단기 예측에 가중치를 부여한 개선 비율 (목표: > 5\%)
        \item 개선 지속성 점수(improvement persistence): 개선이 일관적인지 일시적인지 평가 (목표: > 0.7)
    \end{itemize}
    
    \item \textbf{의사결정 단계:} 계산된 메트릭들을 기반으로 다음 단계를 결정함:
    \begin{itemize}
        \item \textbf{성공 (SUCCESS):} 선형성 < 0.95 AND 개선 비율 ≥ 10\% AND 붕괴 위험 < 0.5 → Phase 1.2 (활성화 함수별 비교 실험)로 진행
        \item \textbf{부분 성공 (PARTIAL):} 개선 비율 5-10\% OR 선형성 0.95-0.98 → 조사 후 Phase 1.2로 신중하게 진행
        \item \textbf{조사 필요 (NEEDS INVESTIGATION):} 개선 비율 < 10\% OR 선형성 ≥ 0.95 OR 붕괴 위험 ≥ 0.5 → 로그 확인, 설정 검증, Phase 2 (고급 개선)로 진행
        \item \textbf{실패 (FAILURE):} 개선 없음 또는 성능 저하 → 로그 확인, 원인 조사, Phase 2로 진행
    \end{itemize}
    
    \item \textbf{반복 개선 단계:} 각 실험 반복 후 모든 메트릭을 확인하고, 시간에 따른 개선 추세를 모니터링함. 메트릭들을 종합하여 다음 반복의 개선 방향을 결정하고, 결과를 보고서에 문서화함.
\end{enumerate}

이러한 메트릭 기반 방법론을 통해 DDFM 성능 개선을 체계적이고 정량적으로 수행할 수 있으며, 각 대상 변수별로 최적화된 하이퍼파라미터 설정을 결정할 수 있음. 특히 KOEQUIPTE와 같이 선형 붕괴 위험이 있는 경우, 이러한 메트릭들을 통해 문제를 조기에 감지하고 개선 방향을 제시할 수 있음.

\textbf{지속적인 개선을 위한 메트릭 활용:} 향후 실험에서는 구현된 DDFM 메트릭 분석 기능들을 활용하여 성능 개선을 체계적으로 모니터링하고 평가할 수 있음. 선형성 자동 감지, 예측 품질 분석, 오차 분포 메트릭, 시점 간 오차 상관관계 분석 등의 기능을 통해 DDFM의 성능 특성을 깊이 이해하고, 각 대상 변수별로 최적화된 하이퍼파라미터 설정을 결정할 수 있음. 구체적인 실행 워크플로우와 의사결정 기준은 ISSUES.md에 상세히 문서화되어 있으며, 이를 통해 실험 효율성을 높이고 체계적인 개선을 달성할 수 있음.

\subsection{원인 분석}

\subsubsection{모형별 제한사항}
\begin{itemize}
    \item \textbf{VAR:} 긴 시점(>7개월)에서 공분산 행렬 특이성으로 인한 수치적 불안정성 발생. 이는 다단계 예측에 VAR 사용을 제한하며, 정규화 기법이나 베이지안 VAR(BVAR) 등의 대안을 고려할 수 있음.
    \item \textbf{DFM:} EM 알고리즘 수렴 중 수치적 불안정성 발생, 수치 안정화 기법 적용으로 해결. Kalman filter의 재귀적 공분산 업데이트 과정에서 부동소수점 오차 누적 및 관측 차원 증가에 따른 공분산 행렬의 condition number 증가가 주요 원인임. Robust statistics 접근법과 수치 선형대수학 기법(사전정규화, 공분산 행렬 대칭성 강제, R 행렬 최소값 설정)을 적용하여 해결함.
\end{itemize}

\subsubsection{DDFM의 성능 특성 및 개선 사항}

DDFM은 KOIPALL.G와 KOWRCCNSE에서 우수한 성능을 보이며(sMAE 각각 0.69, 0.50), 특히 변동성이 큰 시계열에서 DFM 대비 현저히 낮은 오차를 보임. 그러나 KOEQUIPTE에서는 DFM과 동일한 성능(sMAE=1.14)을 보여, 비선형 인코더가 추가적인 이점을 제공하지 못함.

\textbf{KOEQUIPTE에서의 동일 성능 원인 분석:} KOEQUIPTE에서 DDFM과 DFM이 모든 시점(1-21개월)에서 거의 동일한 성능을 보이는 현상은 다음과 같은 원인들이 있을 수 있음:
\begin{itemize}
    \item \textbf{선형 관계의 우세:} KOEQUIPTE 시계열이 다른 시계열들과의 관계에서 주로 선형적 상관관계를 보일 가능성. 이 경우 비선형 인코더가 학습할 수 있는 비선형 패턴이 제한적임.
    \item \textbf{인코더 용량 부족:} 기본 인코더 구조([16, 4])가 KOEQUIPTE의 복잡한 비선형 관계를 포착하기에 용량이 부족할 가능성. 인코더가 선형 변환에 가까운 가중치를 학습하여 DFM과 유사한 요인 구조를 생성할 수 있음.
    \item \textbf{활성화 함수의 한계:} ReLU 활성화 함수가 음의 상관관계를 포착하지 못하거나, 학습 과정에서 일부 뉴런이 비활성화되어 선형적 동작을 할 수 있음.
    \item \textbf{요인 공간의 유사성:} 두 모형이 유사한 요인 공간을 학습하여, 비선형 인코더가 추가적인 차원 축소나 특징 추출을 제공하지 못할 수 있음.
\end{itemize}

이 문제를 해결하기 위해 다음과 같은 개선 사항을 구현함:
\begin{itemize}
    \item \textbf{대상 변수별 인코더 아키텍처:} KOEQUIPTE에 대해서는 기본 인코더([16, 4]) 대신 더 깊은 인코더([64, 32, 16])를 사용하여 더 복잡한 비선형 관계를 포착할 수 있도록 함. 또한 훈련 에포크를 100에서 150으로 증가시켜 충분한 학습을 보장함.
    \item \textbf{활성화 함수 선택:} KOEQUIPTE에 대해서는 기본 ReLU 활성화 함수 대신 tanh 활성화 함수를 사용함. ReLU는 음의 값을 0으로 만드는 특성으로 인해 음의 상관관계를 포착하기 어려울 수 있음. 반면 tanh는 대칭적인 출력 범위(-1, 1)를 가지므로 음의 요인 부하를 학습할 수 있어, KOEQUIPTE와 같은 시계열에서 음의 상관관계가 중요한 경우 더 적합함.
    \item \textbf{Huber 손실 함수:} 이상치에 더 강건한 Huber 손실 함수를 지원하여 변동성이 큰 시계열에서 예측 성능을 개선할 수 있도록 함. Huber 손실은 작은 오차에 대해서는 MSE와 유사하게 동작하지만, 큰 오차에 대해서는 선형적으로 증가하여 이상치의 영향을 완화함.
    \item \textbf{가중치 감쇠 (L2 정규화):} KOEQUIPTE에 대해서는 가중치 감쇠(weight decay, L2 정규화)를 자동으로 적용함(\texttt{weight\_decay=1e-4}). L2 정규화는 인코더가 선형 PCA와 유사한 해에 과적합되는 것을 방지하고, 다양한 비선형 특징을 학습하도록 장려함. 이는 인코더가 선형 변환에 가까운 가중치를 학습하여 DFM과 동일한 성능을 보이는 문제를 완화하기 위한 것임.
    \item \textbf{그래디언트 클리핑:} 훈련 안정성을 향상시키기 위해 그래디언트 클리핑을 지원함. 그래디언트 폭발을 방지하여 NaN 값이나 선형 붕괴를 유발할 수 있는 훈련 불안정성을 완화함. 이는 pre-training, MCMC 훈련, 그리고 Lightning training step에 모두 적용됨.
    \item \textbf{향상된 가중치 초기화:} 인코더 레이어에 대해 활성화 함수에 따라 적절한 가중치 초기화 방법을 적용함. ReLU 활성화 함수의 경우 Kaiming 초기화를 사용하고, tanh나 sigmoid와 같은 대칭 활성화 함수의 경우 Xavier 초기화를 사용함. 출력 레이어는 더 작은 초기화(gain=0.1)를 사용하여 초기 요인 값이 과도하게 크지 않도록 함. 이러한 개선은 특히 더 깊은 네트워크에서 훈련 안정성과 수렴 속도를 향상시킴.
    \item \textbf{요인 차수 설정:} 요인 동역학에 대한 VAR 차수를 설정할 수 있도록 \texttt{factor\_order} 파라미터를 추가함. 기본값은 1(VAR(1))이며, 2(VAR(2))로 설정할 수 있음. VAR(2)는 더 긴 기간의 의존성을 포착할 수 있으나 더 많은 데이터가 필요함. 일부 대상 변수는 복잡한 다기간 동역학을 가지므로 VAR(2)가 도움이 될 수 있음.
    \item \textbf{향상된 훈련 안정성:} 더 깊은 네트워크(레이어 수 > 2)에 대해서는 입력 클리핑 범위를 더 엄격하게 설정하여 극단값에 대한 민감도를 줄임. 또한 훈련 단계에서 수치적 안정성 처리를 개선하여 더 깊은 아키텍처에서의 훈련 안정성을 향상시킴.
    \item \textbf{증가된 사전 훈련:} KOEQUIPTE에 대해서는 사전 훈련 에포크 배수를 1에서 2로 증가시킴(\texttt{mult\_epoch\_pretrain=2}). 사전 훈련은 MCMC 훈련이 시작되기 전에 인코더가 비선형 특징을 학습하는 데 도움을 줌. 더 많은 사전 훈련 에포크는 인코더가 MCMC 반복 전에 비선형 특징을 학습할 시간을 더 제공하여, 인코더가 선형 동작으로 붕괴되는 것을 방지하는 데 도움이 됨.
    \item \textbf{배치 크기 최적화:} KOEQUIPTE에 대해서는 기본 배치 크기(100) 대신 더 작은 배치 크기(64)를 자동으로 사용하도록 구현함. 더 작은 배치 크기는 에포크당 더 다양한 그래디언트를 제공하여 인코더가 선형 PCA와 유사한 해에 수렴하는 것을 방지하고, 비선형 특징을 학습하도록 도울 수 있음.
\end{itemize}

이러한 개선 사항의 효과를 검증하기 위해서는 추가 실험 재실행이 필요하며, 특히 KOEQUIPTE에서의 성능 개선 여부를 확인해야 함. 

\textbf{사전 분석 (Phase 0):} 모델 훈련 전에 수행 가능한 상관관계 구조 분석을 통해 KOEQUIPTE의 선형적 특성을 이해할 수 있음. \texttt{src/evaluation/evaluation\_aggregation.py}에 구현된 \texttt{analyze\_correlation\_structure()} 함수를 사용하여 KOEQUIPTE와 다른 대상 변수(KOIPALL.G, KOWRCCNSE) 간의 상관관계 패턴을 비교 분석할 수 있음. 이 분석은 모델 훈련 없이도 수행 가능하며, 현재 구현되어 있으나 아직 실행되지 않았음. 주요 분석 지표는 다음과 같음:
\begin{itemize}
    \item \textbf{음의 상관관계 비율:} KOEQUIPTE가 다른 시계열들과 음의 상관관계를 보이는 정도. 만약 KOEQUIPTE가 KOIPALL.G나 KOWRCCNSE보다 높은 음의 상관관계 비율을 보인다면, tanh 활성화 함수가 도움이 될 것으로 예상됨. 이는 ReLU가 음의 값을 0으로 만들어 음의 상관관계를 포착하기 어렵기 때문임.
    \item \textbf{강한 음의 상관관계 개수:} 절댓값이 0.3 이상인 음의 상관관계의 개수. 이러한 강한 음의 상관관계는 ReLU 활성화 함수로는 포착하기 어려우나, tanh 활성화 함수로는 학습 가능함. tanh는 대칭적인 출력 범위(-1, 1)를 가지므로 음의 요인 부하를 학습할 수 있음.
    \item \textbf{평균 상관관계:} 대상 변수와 모든 입력 시계열 간의 평균 상관관계. 만약 KOEQUIPTE의 평균 상관관계가 다른 대상 변수와 크게 다르다면, 이는 데이터 구조적 차이를 시사함. 낮은 평균 상관관계는 약한 신호를 의미할 수 있으며, 이 경우 더 깊은 인코더나 더 많은 훈련 에포크가 필요할 수 있음.
    \item \textbf{상관관계 분포:} 상관관계 값의 분포(표준편차, 최소값, 최대값)를 분석하여 대상 변수 간 구조적 차이를 식별함. 예를 들어, KOEQUIPTE의 상관관계 분포가 다른 대상 변수와 크게 다르다면, 이는 해당 시계열이 다른 데이터 구조를 가지고 있음을 시사함.
\end{itemize}
이러한 사전 분석을 통해 모델 훈련 전에 활성화 함수 선택이나 인코더 아키텍처 결정에 대한 가설을 수립할 수 있으며, 실험 설계를 더 효율적으로 할 수 있음. 분석 결과는 JSON 형식으로 저장되며, 세 대상 변수 간 비교를 통해 구조적 차이를 정량적으로 평가할 수 있음. 이 분석은 모델 훈련 없이도 수행 가능하므로, 실험 비용을 절감하면서도 개선 전략을 수립할 수 있음.

\textbf{분석 함수 활용 방법:} 상관관계 구조 분석은 다음 명령어로 실행할 수 있음:
\begin{verbatim}
python3 -c "from src.evaluation.evaluation_aggregation import 
analyze_correlation_structure; import json; result = 
analyze_correlation_structure('data/data.csv', 'KOEQUIPTE', 
output_path='outputs/analysis/correlation_analysis_KOEQUIPTE.json'); 
print(json.dumps(result['summary'], indent=2))"
\end{verbatim}
세 대상 변수에 대해 비교 분석을 수행하면, KOEQUIPTE의 구조적 특성을 다른 대상 변수와 비교하여 tanh 활성화 함수의 효과를 예측할 수 있음. 분석 결과는 \texttt{outputs/analysis/correlation\_analysis\_\{target\}.json}에 저장되며, 음의 상관관계 비율, 강한 음의 상관관계 개수, 평균 상관관계 등의 지표를 포함함.

\textbf{연구 계획 및 검증 방법:}
\begin{itemize}
    \item \textbf{0단계 사전 분석 (Phase 0):} 모델 훈련 전에 상관관계 구조 분석을 수행하여 KOEQUIPTE의 데이터 특성을 이해함. 이 분석은 훈련 없이도 수행 가능하며, \texttt{data/data.csv} 파일만 있으면 됨. 분석 결과는 활성화 함수 선택 및 개선 전략 수립에 활용됨. \texttt{analyze\_correlation\_structure()} 함수를 사용하여 세 대상 변수에 대해 비교 분석을 수행하고, 결과를 \texttt{outputs/analysis/} 디렉토리에 저장함. 주요 의사결정 기준: KOEQUIPTE의 음의 상관관계 비율이 다른 대상 변수보다 높으면 tanh 활성화 함수가 유리함. 평균 상관관계가 낮으면 더 깊은 인코더나 더 많은 훈련 에포크가 필요함.
    \item \textbf{1단계 검증 (Phase 1):} 더 깊은 인코더([64, 32, 16]), tanh 활성화 함수, 가중치 감쇠(weight\_decay=1e-4), 증가된 사전 훈련(mult\_epoch\_pretrain=2), 배치 크기 최적화(batch\_size=64)를 사용한 재실험을 통해 성능 개선 여부를 확인함. 성공 기준은 sMAE가 1.14에서 1.03 이하로 개선되는 것(10\% 이상 개선)이며, DDFM이 DFM보다 최소 5\% 이상 우수해야 함. 검증 방법: \texttt{outputs/experiments/aggregated\_results.csv}의 결과를 기준선과 비교하여 개선 비율을 계산함. \texttt{analyze\_ddfm\_prediction\_quality()} 함수를 사용하여 시점별 성능 패턴, 불안정한 시점, 예측 안정성 메트릭을 분석함. 만약 개선이 관찰되면, 활성화 함수별 비교 실험(relu, tanh, sigmoid, leaky\_relu)을 수행하여 최적의 활성화 함수를 결정함.
    \item \textbf{2단계 연구 (Phase 2, 1단계 실패 시):} 만약 더 깊은 인코더와 tanh 활성화 함수로도 성능이 개선되지 않는다면, 다음과 같은 추가 연구를 수행함:
    \begin{itemize}
        \item \textbf{인코더 아키텍처 그리드 서치:} 다양한 인코더 구조([32, 16, 8], [128, 64, 32], [64, 32, 16, 8] 등)를 체계적으로 테스트하여 최적의 아키텍처를 찾음. 각 아키텍처에 대해 훈련 및 평가를 수행하고, 성능 메트릭을 비교함.
        \item \textbf{요인 부하 분석:} DFM과 DDFM이 학습한 요인 부하를 비교하여 DDFM 인코더가 선형 특징만 학습하는지 확인함. 만약 두 모형의 요인 부하가 매우 유사하다면, 인코더가 선형 변환에 가까운 가중치를 학습한 것으로 해석할 수 있음. 코사인 유사도나 상관관계를 사용하여 요인 부하의 유사성을 정량화함.
        \item \textbf{정규화 실험:} Dropout이나 L1/L2 정규화를 적용하여 선형 특징에 대한 과적합을 방지하고 비선형 특징 학습을 촉진함. 다양한 정규화 강도(weight\_decay 값: 1e-5, 1e-4, 1e-3)를 테스트하여 최적의 정규화 강도를 찾음.
    \end{itemize}
    \item \textbf{3단계 연구 (Phase 3, 2단계도 실패 시):} 만약 아키텍처와 정규화 개선으로도 성능이 개선되지 않는다면, 다음과 같은 고급 기법을 고려함:
    \begin{itemize}
        \item \textbf{앙상블 방법:} DFM과 DDFM 예측값의 가중 평균을 사용하여 분산을 줄임. 검증 세트에서 최적의 가중치를 학습하거나 그리드 서치를 통해 최적 가중치를 찾음.
        \item \textbf{특징 공학:} KOEQUIPTE 데이터에 대해 다른 변환 또는 상호작용 특징을 추가하여 비선형 신호를 강화함. 로그 변환, 차분, 이동평균 등의 변환을 테스트함.
        \item \textbf{하이브리드 접근:} KOEQUIPTE가 본질적으로 선형 관계가 강한 시계열이라면, KOEQUIPTE에는 DFM을 사용하고 다른 대상 변수에는 DDFM을 사용하는 하이브리드 접근을 고려함. 이는 각 대상 변수의 특성에 맞는 최적 모형을 선택하는 실용적인 접근임.
    \end{itemize}
\end{itemize}
각 단계에서의 결과는 \texttt{outputs/experiments/aggregated\_results.csv}에 저장되며, \texttt{detect\_ddfm\_linearity()} 및 \texttt{analyze\_ddfm\_prediction\_quality()} 함수를 사용하여 자동으로 분석됨. 분석 결과는 \texttt{outputs/experiments/ddfm\_linearity\_analysis.json} 및 예측 품질 분석 결과에 저장되며, 각 대상 변수에 대한 구체적인 개선 권장사항을 포함함.

만약 더 깊은 인코더와 증가된 에포크로도 성능이 개선되지 않는다면, KOEQUIPTE가 본질적으로 선형 관계가 강한 시계열이거나, 다른 활성화 함수나 정규화 기법이 필요할 수 있음. DDFM은 비선형 관계가 강하고 충분한 데이터가 있을 때 유리하나, 선형 관계가 강하거나 데이터가 제한적일 경우 단순 모델이 더 효과적일 수 있음 \cite{andreini2020deep}. 이러한 연구를 통해 DDFM의 성능 한계와 개선 방향을 명확히 할 수 있을 것으로 기대됨.

\subsection{Nowcasting 시점별 분석}

Nowcasting 실험 구성:
\begin{itemize}
    \item 모형: DFM, DDFM (2개) - ARIMA와 VAR은 release date 마스킹 처리의 구조적 한계로 인해 제외
    \item 대상 변수: 3개 (KOIPALL.G, KOEQUIPTE, KOWRCCNSE)
    \item 목표 월: 2024-01 ~ 2025-10 (22개월)
    \item 예측 시점: 4주 전, 1주 전
    \item 총 예상 결과 포인트: 2개 모형 × 3개 대상 변수 × 2개 시점 = 12개 모형-시점 조합
    \item \textbf{현재 상태:} Nowcasting 백테스트 실험이 CUDA 텐서 변환 오류로 인해 모든 시점에서 실패하여, 표~\ref{tab:nowcasting_backtest}의 모든 값이 N/A로 표시됨. 오류 원인은 예측값이 CUDA 디바이스에 있는 텐서인데 이를 numpy 배열로 변환할 때 CPU로 먼저 이동하지 않아 발생한 것으로 확인되었음. 이 문제는 \texttt{src/models/models\_utils.py}, \texttt{src/evaluation/evaluation\_forecaster.py}, \texttt{src/evaluation/evaluation\_metrics.py} 파일에서 텐서 변환 코드를 \texttt{.cpu().numpy()} 패턴으로 수정하여 해결되었음. 수정된 코드로 백테스트를 재실행하면 유효한 결과를 얻을 수 있을 것으로 예상됨. Forecasting 실험에서 DFM/DDFM이 세 대상 변수 모두에서 성공적으로 완료되었으므로, 코드 수정 후 nowcasting도 정상적으로 수행될 것으로 예상됨.
\end{itemize}

\textbf{시점별 성능 비교:} \cite{banbura2012nowcasting}
현재 Nowcasting 백테스트 실험이 CUDA 텐서 변환 오류로 인해 실패하여 표~\ref{tab:nowcasting_backtest}의 모든 값이 N/A로 표시됨. 코드 수정을 통해 오류가 해결되었으며, 현재 \texttt{checkpoint/} 디렉토리에는 12개의 모델 파일이 존재하므로, 모델 훈련 없이 바로 백테스트를 재실행할 수 있음. 현재 코드에는 최신 DDFM 개선사항(더 깊은 인코더, tanh 활성화 함수, 가중치 감쇠, 증가된 사전 훈련, 배치 크기 최적화 등)이 구현되어 있으며, 훈련된 모델에 이러한 개선사항이 반영되었을 것으로 예상됨. Forecasting과 nowcasting 실험을 재실행하면 다음과 같은 분석이 가능할 것으로 예상됨:
\begin{itemize}
    \item \textbf{시점별 정확도 향상:} 대부분의 경우 1주 전 예측이 4주 전 예측보다 더 정확할 것으로 예상됨. 이는 시간이 지날수록 더 많은 데이터가 사용 가능해지기 때문임. 4주 전 시점에서는 일부 고빈도 지표가 아직 발표되지 않은 상태이지만, 1주 전 시점에서는 더 많은 지표가 발표되어 예측 정확도가 향상될 것으로 예상됨.
    \item \textbf{모형별 성능 패턴:} DDFM이 DFM보다 전반적으로 우수한 성능을 보일 것으로 예상되며, 특히 forecasting 실험에서 DDFM이 KOIPALL.G(sMAE: 0.69 vs 14.97)와 KOWRCCNSE(sMAE: 0.50 vs 2.78)에서 현저히 우수한 성능을 보였으므로 nowcasting에서도 유사한 패턴이 관찰될 수 있음. KOEQUIPTE에서는 forecasting에서 DFM과 DDFM이 동일한 성능을 보였으므로, nowcasting에서도 유사한 패턴이 관찰될 가능성이 있음.
    \item \textbf{대상 변수별 특성:} 세 대상 변수 모두에 대해서는 forecasting이 성공적으로 완료되었으므로, 모델 훈련 후 코드 수정된 버전으로 nowcasting 백테스트를 재실행하면 정상적으로 수행될 것으로 예상됨. 특히 KOIPALL.G와 KOWRCCNSE에서는 DDFM이 우수한 성능을 보였으므로, nowcasting에서도 DDFM이 더 정확한 예측을 제공할 것으로 예상됨.
\end{itemize}

\textbf{Release date 마스킹의 효과:}
DFM과 DDFM은 요인 모형의 구조적 특성으로 인해 release date 기반 마스킹을 효과적으로 처리 가능함. Kalman filter는 각 시점의 데이터 발표를 재귀적으로 처리하여 예측을 업데이트하며, 데이터의 시의성과 품질을 자동으로 고려함. 실시간 데이터 흐름에서 비동기적 데이터 발표로 인한 불규칙성(jagged edges)을 DFM/DDFM이 자연스럽게 처리할 수 있어, 실제 운영 환경에서의 nowcasting에 적합함. 이는 FRB New York의 nowcasting 모형과 같은 실제 운영 환경에서의 활용 사례와 일치하며, 요인 모형이 nowcasting에 적합한 이유를 보여줌 \cite{banbura2012nowcasting}.

