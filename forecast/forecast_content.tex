\section{개요}
\label{sec:overview}

\subsection{연구 목적}
\label{sec:macro_forecast_necessity}

효과적인 거시경제변수 예측은 정책 수립 및 의사결정의 기본이 됨. \cite{stock2002forecasting, banbura2012nowcasting}. 본 연구에서는 한국 거시경제의 대표 변수인 생산, 투자, 소비에 대해 고빈도 정보를 활용한 예측(nowcasting/forecasting) 문제를 설정하고, 상태공간 모형과 딥러닝 모형의 성능을 동일한 데이터와 평가 기준으로 비교함 \cite{banbura2012nowcasting, bok2019frbny}.

\subsection{거시 경제 변수 예측 주요 이슈}
\label{sec:forecast_issues}

거시경제 nowcasting/forecasting에 대표적인 과제는 다음과 같음:
\begin{itemize}
    \item \textbf{고차원 공변량:} 많은 거시·금융·서베이 변수를 동시에 사용시 과적합과 계산 부담 증가\cite{stock2002forecasting}.
    \item \textbf{혼합 주기/비동기 발표:} 주·월·분기 데이터가 섞이고 발표시점이 달라(jagged edges) 결측이 구조적으로 발생 \cite{banbura2012nowcasting}.
    \item \textbf{비선형/구조변화:} 위기·팬데믹 구간 등에서 선형 가정이 성능을 제한할 수 있음 \cite{huber2020nowcasting, andreini2020deep}.
\end{itemize}

\section{데이터와 전처리}
\label{sec:data_introduction}

\subsubsection{기본 데이터 탐색}
\label{subsec:data_exploration}

\begin{itemize}
  \item 시계열 간 스케일 비율이 크게 달라 수치적 정밀도 문제를 야기.
  \item 일부 시계열이 매우 낮은 분산을 보여 수치적 불안정성을 유발할 수 있음.
  \item 완전한 관측값(complete cases)의 비율이 낮아 대부분의 관측값이 상당부분 결측치를 포함.
\end{itemize}

데이터 품질 및 통계량 대시보드는 그림~\ref{fig:data_quality_dashboard}에 제시됨.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{forecast/images/data_quality_dashboard.png}
    \caption{데이터 품질 및 통계량 대시보드}
    \label{fig:data_quality_dashboard}
\end{figure}

\subsubsection{목표 변수 및 설명변수 구성}
\label{subsec:key_variables}

본 파트에서는 세 가지 주요 거시경제 변수를 목표 변수로 설정함:
\begin{itemize}
    \item \textbf{생산:} 전산업생산지수(KOIPALL.G)
    \item \textbf{투자:} 설비투자지수(KOEQUIPTE)
    \item \textbf{소비:} 도소매판매액(KOWRCCNSE)
\end{itemize}

\begin{itemize}
  \item 세 부문 모형 모두 총 41개 변수로 구성됨.
  \item 포함 변수:
  \begin{itemize}
    \item 고용, 산업생산, 서베이(기업경기, 소비자 동향) 등 주요 월간 지수.
    \item 주간 데이터.
    \item 주가지수 등 금융변수, 뉴스심리지수, 미국 경제정책불확실성 지수.
  \end{itemize}
  \item 기업경기동향 조사는 해당월 중 발표되어 속보성이 높음.
\end{itemize}

\subsubsection{전처리}
\label{subsec:preprocessing}

본 연구에서는 모든 모형에 동일한 전처리 파이프라인을 적용하여 공정한 비교를 보장함.

\begin{itemize}
  \item \textbf{변환(Transformation):} 각 시계열의 특성에 맞는 변환을 적용함. 변환 유형: lin(수준값), log(로그), chg(전기대비 차분), ch1(전년동기대비 차분), pch(전기대비 성장률), pc1(전년동기대비 성장률), cha(연율화 차분), pca(연율화 성장률).
  \item \textbf{결측치 처리(Imputation):} 다음 순서로 처리함:
  \begin{enumerate}
    \item forward-fill: 이전 값으로 채움.
    \item backward-fill: 이후 값으로 채움.
    \item naive forecaster: 마지막 관측값으로 채움.
  \end{enumerate}
  \item \textbf{표준화(Scaling):} 모든 모형에 RobustScaler를 적용함. 중앙값(median)을 0으로, 사분위수 범위(IQR)를 1로 조정하여 이상치에 강건한 표준화를 수행함.
  \item \textbf{데이터 단위:} 원본 데이터는 주간 단위로 제공됨. 모든 모형은 주간 데이터로 학습하고, 동일한 단위(주간)로 예측을 생성함(리샘플링 없음).
\end{itemize} 

모형별 주간-월간 변환 방식은 다음과 같음:
\begin{itemize}
    \item \textbf{DFM/DDFM:} 주간 데이터를 기본으로 하며, 혼합주기 옵션을 통해 tent kernel이 자동으로 적용되어 주간/월간 데이터를 통합 처리함 \cite{mariano2003new}. 예측 생성 시 horizon은 개월 단위로 지정되며, 모형 내부에서 자동으로 주 단위로 변환됨(1개월 = 4주). 예측 결과는 주간 단위로 생성되며, 평가를 위해 월간으로 평균 집계함.
    
    \item \textbf{딥러닝 모형(TFT, Chronos, LSTM):} 모든 딥러닝 모형은 주간 데이터로 학습하고, 같은 단위(주간)로 예측을 생성함. 예측 생성 후 평가를 위해 주간 예측을 월간으로 변환하는데, 이는 월별로 주간 예측값을 평균 집계하는 방식으로 수행됨. 구체적으로, 각 월에 해당하는 주간 예측값들을 평균하여 월간 예측값을 생성함.
\end{itemize}

\begin{itemize}
  \item 예측 평가 시 모든 모형의 주간 예측을 월간으로 평균 집계한 후, 원본 목표 변수(월간 단위)와 비교함.
  \item 모든 모형을 동일한 기준으로 평가하기 위한 것으로, 주간 예측의 세부 패턴보다는 월간 집계 수준에서의 예측 정확도를 중시함.
\end{itemize}

세 대상 변수에 대한 전처리 결과는 그림~\ref{fig:preprocessed_targets}에 제시됨.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{forecast/images/preprocessed_targets.png}
    \caption{전처리된 목표 변수 시계열}
    \label{fig:preprocessed_targets}
\end{figure}

\section{모형과 실험 설계}
\label{sec:methodology}

\subsection{예측 모형}
\label{sec:forecasting_models}

\subsubsection{딥러닝 시계열 모형}
\label{subsec:deep_learning_models}

\begin{itemize}
  \item \textbf{예측 생성 방식:}
  \begin{itemize}
    \item 직접 장기 예측(direct long-horizon forecasting): 전체 예측 시점(88주 = 22개월)을 한 번에 예측.
    \item 재귀적 예측(recursive forecasting): 짧은 구간씩 예측을 반복하여 전체 시점에 도달.
  \end{itemize}
  \item \textbf{Temporal Fusion Transformer (TFT):}
  \begin{itemize}
    \item Attention 기반 아키텍처로, 다중 시점 예측과 해석 가능성을 결합한 모형 \cite{lim2021temporal}.
    \item LSTM을 지역 처리에 사용하고 self-attention을 장기 의존성에 사용.
    \item Variable Selection Networks를 통해 변수별 중요도를 해석할 수 있어 경제 예측에 유용 \cite{lim2021temporal}.
    \item 본 연구에서는 재귀적 예측 방식으로 사용하며, 24주 구간을 반복 예측하여 전체 88주(22개월) 예측을 생성. 모형은 50개의 공변량과 함께 학습되며, 예측 시에도 동일한 공변량을 제공하여 학습 시와 일관된 조건에서 예측을 수행.
  \end{itemize}
  \item \textbf{Chronos:}
  \begin{itemize}
    \item 사전 훈련된 foundation model로, 대규모 시계열 데이터로 사전 훈련되어 다양한 시계열 패턴을 학습함 \cite{ansari2024chronos}.
    \item Transformer 기반 아키텍처를 사용하여 장기 의존성을 포착함.
    \item 본 연구에서는 직접 장기 예측 방식으로 사용하며, 전체 88주(22개월)를 한 번에 예측함.
  \end{itemize}
  \item \textbf{LSTM:}
  \begin{itemize}
    \item 순환 신경망(RNN)의 변형으로, forget gate, input gate, output gate를 통해 정보의 흐름을 제어하며 장기 의존성을 학습할 수 있음 \cite{hochreiter1997long}.
    \item Gradient vanishing 문제를 완화하여 긴 시계열에서도 효과적으로 학습.
    \item 본 연구에서는 직접 장기 예측 방식으로 사용하며, 전체 88주(22개월)를 한 번에 예측함.
  \end{itemize}
\end{itemize}

\subsubsection{상태공간 모형}
\label{subsec:state_space_models}

\begin{itemize}
  \item \textbf{동적요인모형(DFM):}
  \begin{itemize}
    \item 많은 시계열에서 공통 요인을 추출해 소수의 동태적 요인으로 설명하는 차원축소 기법 \cite{stock2002forecasting}.
    \item 관측식과 상태식을 갖는 state-space 형태로 표현됨.
    \item EM 알고리즘으로 파라미터를 추정하고, Kalman filter를 통해 요인을 추정함 \cite{bok2019frbny}.
    \item 혼합주기 데이터와 비동기적 데이터 발표(jagged edges)를 처리하는 데 강점이 있음 \cite{banbura2012nowcasting, bok2019frbny}.
    \item EM 알고리즘의 수치적 안정성을 위해 적응적 정규화 기법을 적용함: 요인 공분산 행렬의 조건수가 $10^8$ 이상일 때 정규화 계수를 조건수에 비례하여 조정하여 ill-conditioned 행렬 역행렬 문제를 완화함.
    \item 전이 행렬의 스펙트럴 반경이 1보다 큰 경우 예측 발산이 발생할 수 있어, 본 실험에서는 재귀적 예측(6개월 구간 단위)을 적용하여 안정성을 확보함.
  \end{itemize}
  \item \textbf{심층 동적요인모형(DDFM):}
  \begin{itemize}
    \item 오토인코더 기반 비선형 인코더를 사용해 요인 구조를 학습함으로써 전통적 DFM의 선형 가정을 완화함 \cite{andreini2020deep}.
    \item 비선형 인코더는 고차원 거시 데이터의 복잡한 상호작용을 더 적은 요인으로 포착함.
    \item 요인층 뒤에는 선형 state-space를 두어 필터링·스무딩 안정성을 유지함.
    \item 학습은 두 단계로 구성됨:
    \begin{enumerate}
      \item 오토인코더를 통해 재구성 오차를 최소화하여 요인 구조를 학습.
      \item 학습된 요인을 사용하여 전이 행렬을 추정하고 Kalman filter를 통해 최종 스무딩을 수행함.
    \end{enumerate}
    \item 전통적 DFM의 요인 식별 제약 문제를 자연스럽게 해결하며, 혼합주기 데이터와 대규모 변수 집합을 효율적으로 처리할 수 있음.
  \end{itemize}
\end{itemize}

\subsection{실험 구성}
\label{sec:experiment_design}

\subsubsection{평가 기준}
\label{subsec:evaluation_criteria}

본 연구에서는 데이터를 세 구간으로 분할하여 모형 학습 및 평가를 수행함:

\begin{itemize}
    \item \textbf{훈련 기간(Train):} 1985년 1월부터 2019년 12월까지 (35년간). 모든 모형은 이 기간의 데이터를 사용하여 학습함. 이 기간은 충분히 긴 시계열을 제공하여 모형이 장기적 패턴과 계절성을 학습할 수 있도록 함.

    \item \textbf{테스트 기간(Test):} 2024년 1월부터 2025년 10월까지 (22개월). 모든 모형의 예측 성능을 평가하는 기간으로, 실제 예측 상황을 시뮬레이션. 각 모형은 훈련 기간 데이터로 학습한 후, 테스트 기간에 대해 예측을 생성함. 구체적으로, DFM은 발산 문제를 완화하기 위해 재귀적 예측(6개월 구간 단위)을 사용하며, DDFM은 발산 문제가 발생하지 않아 재귀적 예측 없이 한 번에 전체 22개월을 예측하는 일괄 예측 방식을 사용함.
\end{itemize}

\begin{itemize}
  \item 모든 모형은 주간 단위로 예측을 생성하며, 원본 목표 변수가 월간 단위이므로 주간 예측을 월간으로 평균 집계하여 비교함.
  \item 주간 예측을 월간으로 평균 집계한 후, 각 예측 시점(1--22개월)에 대한 지표를 평균하여 최종 성능 지표로 사용함.
\end{itemize}

\subsubsection{하이퍼 패러미터}
\label{subsec:hyperparameters}

\begin{itemize}
  \item \textbf{CHRONOS:} amazon/chronos-t5-tiny (pre-trained foundation model), prediction length 24 weeks, robust scaler.
  \item \textbf{DDFM:} encoder layers [64, 32], num factors 3, epochs 50, learning rate 0.005, batch size 100, factor order 2, robust scaler.
  \item \textbf{DFM:} max EM iterations 5000, convergence threshold $1.0 \times 10^{-5}$, 3 factors, AR lag 1, mixed frequency enabled, robust scaler.
  \item \textbf{LSTM:} input size 96 weeks, hidden size 64, 2 layers, learning rate 0.001, epochs 50, batch size 32, robust scaler.
  \item \textbf{TFT:} input size 96 weeks, hidden size 64, 4 attention heads, dropout 0.1, learning rate 0.001, max epochs 10, batch size 256, max covariates 50, robust scaler.
\end{itemize}

\subsubsection{성능 지표}
\label{subsec:performance_metrics}

\begin{itemize}
  \item \textbf{표준화된 지표:} sMAE, sMSE. 두 지표 모두 훈련 데이터의 표준편차로 정규화하여 계산함. 변수 간 스케일 차이를 제거하여 비교 가능하게 하며, 특히 거시경제 변수처럼 단위와 크기가 다른 변수들을 비교할 때 유용 \cite{stock2002forecasting}.
  \item \textbf{지표 정의:} 월간 실측값을 $y_{t+h}$, 월간 예측값을 $\hat{y}_{t+h}$로 두고, 훈련 구간 목표변수의 표준편차를 $\sigma_{\text{train}}$로 두면 각 시점(예측지평 $h$)에서의 지표는 다음과 같음:
  \begin{align}
    \mathrm{MAE}_h &= \frac{1}{T_h}\sum_{t \in \mathcal{T}_h} \left|y_{t+h} - \hat{y}_{t+h}\right|, \\
    \mathrm{MSE}_h &= \frac{1}{T_h}\sum_{t \in \mathcal{T}_h} \left(y_{t+h} - \hat{y}_{t+h}\right)^2, \\
    \mathrm{sMAE}_h &= \frac{\mathrm{MAE}_h}{\sigma_{\text{train}}}, \\
    \mathrm{sMSE}_h &= \frac{\mathrm{MSE}_h}{\sigma_{\text{train}}^2}.
  \end{align}
  여기서 $\mathcal{T}_h$는 예측지평 $h$에서 평가 가능한 시점들의 집합이며, $T_h = |\mathcal{T}_h|$임.
  \item \textbf{평가 절차:} 모든 모형은 주간 데이터로 학습하고 주간 단위로 예측을 생성함. 평가는 주간 예측을 월간 평균으로 집계한 뒤, 월간 실측치와 비교하여 수행함. 최종 성능 지표는 $h=1,\dots,22$에 대해 계산한 $\mathrm{sMAE}_h$, $\mathrm{sMSE}_h$를 평균하여 요약함.
\end{itemize}

\section{실험 결과}
\label{sec:experiment_result}

\subsection{예측 결과 요약}
\label{sec:forecasting_results_comparison}

\begin{itemize}
  \item 대상 변수: 생산(KOIPALL.G), 투자(KOEQUIPTE), 소비(KOWRCCNSE).
  \item 비교 모형: DFM, DDFM, TFT, Chronos, LSTM.
  \item 모든 모형은 주간 단위로 예측을 생성하며, 주간 예측을 월간으로 평균 집계한 후 1개월부터 22개월까지의 시점에 대해 평가함.
  \item 예측 결과는 아래 전체 시점 평균 성능 섹션에서 요약되며, 시점별 상세 결과는 부록 표들(표~\ref{tab:koipallg_forecasts}, 표~\ref{tab:koequipte_forecasts}, 표~\ref{tab:kowrccnse_forecasts})에 포함됨.
\end{itemize}

\subsubsection{전체 시점 평균 성능}

변수별로 최우수 모형이 다르게 나타났으며, 특히 예측 시점(단기 vs 장기)에 따라 강점이 달라지는 양상이 관찰됨. 이는 (i) 목표 변수의 변동성·구조변화 정도, (ii) 공변량의 정보량, (iii) 모형의 예측 방식(재귀 vs 일괄) 차이가 동시에 작용한 결과로 해석할 수 있음. 한편 DFM은 전이 행렬의 불안정성으로 인해 테스트 구간에서 오차가 크게 나타났음(논의 섹션 참조).

\begin{itemize}
  \item \textbf{KOIPALL.G(생산):} Chronos(sMAE=1.44) > LSTM(sMAE=1.87) > DDFM(sMAE=1.72) > TFT(sMAE=2.07) > DFM(sMAE=3.55). 단기 예측에서는 DDFM이 가장 우수하나, 장기 예측에서는 Chronos와 LSTM이 우수.
  
  \item \textbf{KOEQUIPTE(투자):} TFT(sMAE=0.53) > DDFM(sMAE=1.50) > Chronos(sMAE=2.60) > DFM(sMAE=3.99) > LSTM(sMAE=5.04). 단기 예측에서는 DDFM이 가장 우수하나, 장기 예측에서는 TFT가 크게 우수함.
  
  \item \textbf{KOWRCCNSE(소비):} DDFM(sMAE=0.32) > TFT(sMAE=1.48) > Chronos(sMAE=2.44) > LSTM(sMAE=2.87) > DFM(sMAE=3.82). 단기 및 장기 예측 모두에서 DDFM이 가장 우수함.
\end{itemize}

테스트 기간 동안의 예측값과 실제값 비교는 그림~\ref{fig:forecast_vs_actual_all}에 제시됨. KOIPALL.G에서는 Chronos와 LSTM이 실제값을 비교적 잘 추적하며, KOEQUIPTE에서는 TFT가 실제값을 가장 정확하게 추적함. KOWRCCNSE에서는 DDFM이 실제값을 가장 정확하게 추적함. DFM은 재귀적 예측으로 인해 예측값이 들쭉날쭉한 패턴을 보임.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{forecast/images/forecast_vs_actual_all.png}
    \caption{예측값 vs 실제값 비교: 목표 변수 월별 실제값과 모델 예측값}
    \label{fig:forecast_vs_actual_all}
\end{figure}

\subsubsection{시점별 성능 패턴}
\label{subsec:horizon_performance}

\begin{itemize}
  \item \textbf{단기(1--6개월):} 전반적으로 DDFM이 상대적으로 강한 경향이 관찰됨. 이는 고차원 공변량의 공통요인을 비선형 인코더로 압축한 뒤 상태공간 구조로 단기 변동을 안정적으로 추적하는 메커니즘이 단기 예측에서 유리하게 작동했을 가능성을 시사함.
  \item \textbf{중기(7--12개월):} 모형 간 격차가 점차 확대되는 구간으로, 목표 변수에 따라 ``단기 우위''가 유지되기도 하고 약화되기도 함. 특히 예측 방식(재귀 vs 일괄), 공변량 활용 방식(선택/가중 vs 요인 압축), 그리고 주간 예측을 월간 평균으로 집계하는 평가 방식이 결합되면서, 특정 모형의 상대적 장점이 중기부터 달라질 수 있음.
  \item \textbf{장기(13--22개월):} 생산·투자에서는 TFT/Chronos/LSTM이 상대적으로 안정적인 경우가 있었고, 소비에서는 DDFM 우위가 유지됨. 장기 예측에서는 잠재요인 동학의 단순화, 구조변화, 그리고 누적 오차가 더 크게 작용할 수 있으며, 이때 장기 의존성 학습(Transformer/RNN)이나 공변량 선택 구조(TFT)가 일부 변수에서 더 안정적으로 나타날 수 있음.
  \item \textbf{변수별 요약}: (i) 생산은 장기 구간에서 Chronos/LSTM이 상대적으로 강했고, (ii) 투자는 TFT가 전반적으로 우세했으며, (iii) 소비는 DDFM의 우위가 비교적 일관되게 관찰됨.
  \item 시점별 상세 수치는 부록 표(표~\ref{tab:koipallg_forecasts}--\ref{tab:kowrccnse_forecasts})에 제시됨.
\end{itemize}

\subsubsection{결과 해석(변수별)}

\begin{itemize}
  \item \textbf{생산(KOIPALL.G):} 생산지수는 비교적 완만한 추세·계절성이 존재하고, 다양한 공변량(서베이/금융/대외지표)이 광범위하게 연동되는 경향이 있어, 장기 의존성을 학습하거나(Transformer/RNN) 사전 학습 분포의 일반 패턴을 활용하는 모형(Chronos)이 유리할 수 있음.
  \item \textbf{투자(KOEQUIPTE):} 투자지수는 경기·금융여건 변화에 민감하고 변동성이 커서, 공변량의 단기 신호(금리/스프레드/서베이)를 잘 선택·가중하는 구조(TFT의 변수 선택/attention)가 유리할 수 있음.
  \item \textbf{소비(KOWRCCNSE):} 소비는 다변량 공통요인 구조의 영향이 비교적 뚜렷할 수 있어, 고차원 공변량을 잠재요인으로 압축하고 상태공간 업데이트로 노이즈를 완화하는 요인 모형 계열(DDFM)이 안정적으로 작동할 가능성이 있음.
\end{itemize}

\subsection{논의}
\label{sec:discussion}

\subsubsection{모형별 강점과 한계}

\begin{itemize}
  \item \textbf{DFM:} Kalman filter 기반 state-space 모형은 혼합주기/결측/비동기 발표를 구조적으로 처리할 수 있어 nowcasting에 적합함 \cite{banbura2012nowcasting, bok2019frbny}. 다만 본 실험에서는 전이 행렬 안정화가 충분하지 않아(스펙트럴 반경 $>1$) 예측 발산 또는 과도한 수렴이 관찰되었고, 이를 완화하기 위해 DFM에만 재귀 예측(구간 단위) 적용함. 이로 인해 예측 경로의 불연속/들쭉날쭉함이 나타날 수 있으며, 모형 간 비교의 정합성에도 영향.
  \item \textbf{DDFM:} 비선형 인코더로 잠재요인을 학습해 선형 가정의 한계를 일부 완화할 수 있으나 \cite{andreini2020deep}, 장기 예측에서는 잠재요인 동학(transition)의 단순화, 그리고 구조변화 구간에서의 일반화 한계가 성능 저하로 나타날 수 있음. 반대로 단기 예측에서는 요인 추출의 이점이 두드러질 수 있음.
  \item \textbf{TFT/LSTM/Chronos:} 딥러닝 계열은 비선형성과 장기 의존성을 직접 학습할 수 있으나, (i) 데이터 양/전처리, (ii) 공변량의 가용성(실시간 예측 시점에 관측 가능한지), (iii) 직접 장기 예측 vs 재귀 예측 선택에 따라 성능 변동이 커질 수 있음.
\end{itemize}

\subsubsection{DFM 선형 동학 수렴 이슈}

본 실험에서는 DFM에만 재귀적 예측(6개월 구간 단위)을 적용하여 발산을 완화했으나, 이는 예측 경로의 불연속성을 야기하고 모형 간 비교의 정합성을 저해함. 발견한 이슈는 다음과 같음:

\begin{itemize}
  \item 전이 행렬(transition matrix)의 스펙트럴 반경이 1보다 크면 상태 변수가 시간에 따라 기하급수적으로 발산하여 예측이 불안정.
  \item 이는 EM 알고리즘의 M-step에서 전이 행렬을 추정할 때 안정성 제약이 충분히 강화되지 않아 발생할 수 있음.
  \item EM 알고리즘의 M-step에서 요인 공분산 행렬($\sum E[Z_t Z_t']$)의 고유값이 반복에 따라 증가하면서 행렬 역행렬 계산 시 수치적 불안정성이 발생. 특히 고정 정규화 계수(예: $10^{-6}$)는 초기 반복에서는 충분하지만, 조건수가 $10^8$ 이상으로 증가하면 불충분해져서 ill-conditioned 행렬 역행렬로 인한 수치적 오차가 누적.
  \item 본 실험에서는 조건수에 비례하여 정규화 계수를 조정하는 적응적 정규화(adaptive regularization) 기법을 적용했으나, 일부 변수에서는 여전히 수렴 문제가 관찰.
  \item 결측치가 많은 경우 유효 관측값이 부족하여 요인 공분산 행렬 추정이 불안정해질 수 있음
  \item 선형 상태공간 모형의 구조적 한계로 인해 비선형 동학이나 구조변화를 포함한 데이터에서 근본적인 수렴 문제가 발생.
\end{itemize}


\subsubsection{평가 설계}

\begin{itemize}
  \item \textbf{주간→월간 평균 집계}: 모든 모형이 주간 단위로 예측을 생성한 뒤 월간 평균으로 평가되므로, 주간 내 변동을 잘 맞추는 모형의 이점이 평가에서 약화될 수 있음. 반대로 월간 평균 수준을 잘 맞추는 모형이 유리할 수 있음.
  \item \textbf{결측치 처리의 누수 가능성}: forward/backward fill 및 naive 채움은 구현 방식에 따라 미래 정보가 암묵적으로 섞일 수 있음. 특히 테스트 구간에서 backward-fill이 사용되었다면, 실시간 nowcasting 관점에서 부적절할 수 있으므로(미래값 사용) 추후 파이프라인 점검 필요.
  \item \textbf{재귀 vs 일괄 예측}: DFM은 구간 단위 재귀 예측, 다른 모형은 일괄 장기 예측 또는 다른 구간 길이로 운영되었기 때문에, ``모형 구조''뿐 아니라 ``예측 운영 방식''이 성능 차이의 일부를 설명할 수 있음. 후속 연구에서는 동일 모형에 대해 두 방식을 모두 비교하는 것이 바람직.
\end{itemize}

\subsection{의의 및 한계}
\label{sec:contribution_limitations}

\subsubsection{의의}
\begin{itemize}
  \item \textbf{동일 전처리 기반 비교}: state-space(DFM/DDFM)과 딥러닝(TFT/Chronos/LSTM)을 동일한 전처리 및 평가 방식 하에서 비교하여, 한국 거시변수 예측에서의 상대적 강점이 변수별로 달라질 수 있음을 제시함.
  \item \textbf{실용적 관찰 제공}: DFM의 수치적 불안정(전이행렬 안정성)과 같은 구현·운영 이슈가 실제 예측 성능을 크게 훼손할 수 있음을 확인하고, 안정화 강화 필요성 제기함.
  \item \textbf{변수별 모델 선택의 근거}: 생산/투자/소비의 성격 차이에 따라 (i) 사전학습 기반 일반화, (ii) 공변량 선택/가중 구조, (iii) 잠재요인 기반 다변량 압축이 각기 다른 성능을 낼 수 있음을 실증 결과와 함께 정리함.
\end{itemize}

\subsubsection{한계 및 개선 방향}
\begin{itemize}
  \item \textbf{실시간(nowcast) 설정의 불완전성}: 예측 시점별로 사용 가능한 정보집합(vintage)을 엄밀히 구성하지 못했으며, 공변량이 예측 시점에 관측 가능한지에 대한 검증이 충분하지 않음.
  \item \textbf{전처리·결측치 처리의 영향}: 결측치 채움 방식은 성능에 큰 영향을 줄 수 있으며, 실시간 예측 관점에서 허용되지 않는 정보 사용(backward-fill 등) 여부 점검 필요.
  \item \textbf{하이퍼파라미터 튜닝의 비대칭}: 모형별 튜닝 자원이 동일하지 않으면 성능 비교가 왜곡될 수 있음. 동일한 튜닝 예산(탐색 공간/반복/검증 프로토콜) 적용이 바람직함.
  \item \textbf{예측 방식 차이}: 재귀/일괄 예측의 차이는 장기 예측에서 성능과 안정성에 직접 영향 있음. 동일 모형에 대해 재귀 구간 길이와 업데이트 전략을 체계적으로 비교할 필요 있음.
  \item \textbf{DFM 수렴 안정성 개선}: 전이 행렬의 스펙트럴 반경 제약 강화, EM 알고리즘의 적응적 정규화 파라미터 튜닝, 그리고 데이터 품질 개선(결측 패턴 분석, 공선성 감소)을 통해 수렴 안정성을 향상시킬 수 있음. 또한 비선형 동학을 포착할 수 있는 확장 모형(예: 비선형 전이 함수, regime-switching)을 고려할 수 있음.
\end{itemize}

\section{결론}
\label{sec:conclusion}

본 파트의 비교 실험에서는 변수별로 우수한 모형이 달랐으며(생산: Chronos, 투자: TFT, 소비: DDFM), 시점(단기/장기)에 따라서도 상대적 우위가 달라질 수 있음을 확인함. 특히 단기(1--6개월)에서는 DDFM의 강점이 관찰된 반면, 장기(13--22개월)에서는 생산·투자에서 딥러닝 계열(TFT/Chronos/LSTM)이 상대적으로 안정적인 경우가 나타났고, 소비에서는 DDFM 우위가 비교적 유지되는 경향이 확인되었음. 다만 시간적 제약으로 인해 DDFM의 재귀적 예측을 구현하지 못했음을 감안하면 DDFM 역시 비슷하게 안정적인 결과가 기대됨.

이 결과는 ``어떤 모형이 절대적으로 우수함''이라기보다, (i) 목표 변수의 변동성·구조변화 정도, (ii) 공변량의 정보량과 발표 시차, (iii) 전처리 및 결측치 처리, (iv) 예측 운영 방식(재귀/일괄)과 같은 설정이 성능을 크게 좌우함을 시사함. 따라서 실시간 nowcasting 시스템 구축 관점에서는 모형 선택만큼이나 \emph{정보집합의 정의}, \emph{데이터 누수 방지}, \emph{예측 운영 방식 표준화}가 중요.

마지막으로 본 연구는 상태공간 모형이 데이터가 부족한 거시 금융 예측 환경에서 안정적으로 잠재 상태를 학습하고 예측에 활용될 수 있다는 가능성을 확인하였음. 다만 선형 상태 공간 모형은 비선형 동학에 의한 수렴 안정성 문제가 나타나 이를 보완할 수 있는 딥러닝 기반 상태 모형 구축이 권장.
